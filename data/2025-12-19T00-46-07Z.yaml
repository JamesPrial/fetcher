models:
- model_id: google/gemini-3-flash-preview
  name: 'Google: Gemini 3 Flash Preview'
  provider: openrouter
  description: 'Gemini 3 Flash Preview is a high speed, high value thinking model
    designed for agentic workflows, multi turn chat, and coding assistance. It delivers
    near Pro level reasoning and tool use performance with substantially lower latency
    than larger Gemini variants, making it well suited for interactive development,
    long running agent loops, and collaborative coding tasks. Compared to Gemini 2.5
    Flash, it provides broad quality improvements across reasoning, multimodal understanding,
    and reliability.


    The model supports a 1M token context window and multimodal inputs including text,
    images, audio, video, and PDFs, with text output. It includes configurable reasoning
    via thinking levels (minimal, low, medium, high), structured output, tool use,
    and automatic context caching. Gemini 3 Flash Preview is optimized for users who
    want strong reasoning and agentic behavior without the cost or latency of full
    scale frontier models.'
  context_length: 1048576
  pricing:
    prompt: 5.0e-07
    completion: 3.0e-06
    image: 0.0
    request: 0.0
    currency: USD
  capabilities:
    supports_vision: true
    supports_function_calling: true
    supports_streaming: true
    modalities:
    - text
    - image->text
  metadata:
    architecture: Gemini
  updated_at: 2025-12-19 00:46:07.736966+00:00
- model_id: mistralai/mistral-small-creative
  name: 'Mistral: Mistral Small Creative'
  provider: openrouter
  description: Mistral Small Creative is an experimental small model designed for
    creative writing, narrative generation, roleplay and character-driven dialogue,
    general-purpose instruction following, and conversational agents.
  context_length: 32768
  pricing:
    prompt: 1.0e-07
    completion: 3.0e-07
    image: 0.0
    request: 0.0
    currency: USD
  capabilities:
    supports_vision: false
    supports_function_calling: true
    supports_streaming: true
    modalities:
    - text
    - text->text
  metadata:
    architecture: Mistral
  updated_at: 2025-12-19 00:46:07.736995+00:00
- model_id: allenai/olmo-3.1-32b-think:free
  name: 'AllenAI: Olmo 3.1 32B Think (free)'
  provider: openrouter
  description: Olmo 3.1 32B Think is a large-scale, 32-billion-parameter model designed
    for deep reasoning, complex multi-step logic, and advanced instruction following.
    Building on the Olmo 3 series, version 3.1 delivers refined reasoning behavior
    and stronger performance across demanding evaluations and nuanced conversational
    tasks. Developed by Ai2 under the Apache 2.0 license, Olmo 3.1 32B Think continues
    the Olmo initiative’s commitment to openness, providing full transparency across
    model weights, code, and training methodology.
  context_length: 65536
  pricing:
    prompt: 0.0
    completion: 0.0
    image: 0.0
    request: 0.0
    currency: USD
  capabilities:
    supports_vision: false
    supports_function_calling: false
    supports_streaming: true
    modalities:
    - text
    - text->text
  metadata:
    architecture: Other
  updated_at: 2025-12-19 00:46:07.737011+00:00
- model_id: xiaomi/mimo-v2-flash:free
  name: 'Xiaomi: MiMo-V2-Flash (free)'
  provider: openrouter
  description: 'MiMo-V2-Flash is an open-source foundation language model developed
    by Xiaomi. It is a Mixture-of-Experts model with 309B total parameters and 15B
    active parameters, adopting hybrid attention architecture. MiMo-V2-Flash supports
    a hybrid-thinking toggle and a 256K context window, and excels at reasoning, coding,
    and agent scenarios. On SWE-bench Verified and SWE-bench Multilingual, MiMo-V2-Flash
    ranks as the top #1 open-source model globally, delivering performance comparable
    to Claude Sonnet 4.5 while costing only about 3.5% as much.


    Note: when integrating with agentic tools such as Claude Code, Cline, or Roo Code,
    **turn off reasoning mode** for the best and fastest performance—this model is
    deeply optimized for this scenario.


    Users can control the reasoning behaviour with the `reasoning` `enabled` boolean.
    [Learn more in our docs](https://openrouter.ai/docs/use-cases/reasoning-tokens#enable-reasoning-with-default-config).'
  context_length: 262144
  pricing:
    prompt: 0.0
    completion: 0.0
    image: 0.0
    request: 0.0
    currency: USD
  capabilities:
    supports_vision: false
    supports_function_calling: true
    supports_streaming: true
    modalities:
    - text
    - text->text
  metadata:
    architecture: Other
  updated_at: 2025-12-19 00:46:07.737031+00:00
- model_id: nvidia/nemotron-3-nano-30b-a3b:free
  name: 'NVIDIA: Nemotron 3 Nano 30B A3B (free)'
  provider: openrouter
  description: 'NVIDIA Nemotron 3 Nano 30B A3B is a small language MoE model with
    highest compute efficiency and accuracy for developers to build specialized agentic
    AI systems.


    The model is fully open with open-weights, datasets and recipes so developers
    can easily

    customize, optimize, and deploy the model on their infrastructure for maximum
    privacy and

    security.


    Note: For the free endpoint, all prompts and output are logged to improve the
    provider''s model and its product and services. Please do not upload any personal,
    confidential, or otherwise sensitive information. This is a trial use only. Do
    not use for production or business-critical systems.'
  context_length: 256000
  pricing:
    prompt: 0.0
    completion: 0.0
    image: 0.0
    request: 0.0
    currency: USD
  capabilities:
    supports_vision: false
    supports_function_calling: true
    supports_streaming: true
    modalities:
    - text
    - text->text
  metadata:
    architecture: Other
  updated_at: 2025-12-19 00:46:07.737047+00:00
- model_id: nvidia/nemotron-3-nano-30b-a3b
  name: 'NVIDIA: Nemotron 3 Nano 30B A3B'
  provider: openrouter
  description: 'NVIDIA Nemotron 3 Nano 30B A3B is a small language MoE model with
    highest compute efficiency and accuracy for developers to build specialized agentic
    AI systems.


    The model is fully open with open-weights, datasets and recipes so developers
    can easily

    customize, optimize, and deploy the model on their infrastructure for maximum
    privacy and

    security.


    Note: For the free endpoint, all prompts and output are logged to improve the
    provider''s model and its product and services. Please do not upload any personal,
    confidential, or otherwise sensitive information. This is a trial use only. Do
    not use for production or business-critical systems.'
  context_length: 262144
  pricing:
    prompt: 6.0e-08
    completion: 2.4e-07
    image: 0.0
    request: 0.0
    currency: USD
  capabilities:
    supports_vision: false
    supports_function_calling: true
    supports_streaming: true
    modalities:
    - text
    - text->text
  metadata:
    architecture: Other
  updated_at: 2025-12-19 00:46:07.737061+00:00
- model_id: openai/gpt-5.2-chat
  name: 'OpenAI: GPT-5.2 Chat'
  provider: openrouter
  description: GPT-5.2 Chat (AKA Instant) is the fast, lightweight member of the 5.2
    family, optimized for low-latency chat while retaining strong general intelligence.
    It uses adaptive reasoning to selectively “think” on harder queries, improving
    accuracy on math, coding, and multi-step tasks without slowing down typical conversations.
    The model is warmer and more conversational by default, with better instruction
    following and more stable short-form reasoning. GPT-5.2 Chat is designed for high-throughput,
    interactive workloads where responsiveness and consistency matter more than deep
    deliberation.
  context_length: 128000
  pricing:
    prompt: 1.75e-06
    completion: 1.4e-05
    image: 0.0
    request: 0.0
    currency: USD
  capabilities:
    supports_vision: true
    supports_function_calling: true
    supports_streaming: true
    modalities:
    - text
    - image->text
  metadata:
    architecture: GPT
  updated_at: 2025-12-19 00:46:07.737072+00:00
- model_id: openai/gpt-5.2-pro
  name: 'OpenAI: GPT-5.2 Pro'
  provider: openrouter
  description: GPT-5.2 Pro is OpenAI’s most advanced model, offering major improvements
    in agentic coding and long context performance over GPT-5 Pro. It is optimized
    for complex tasks that require step-by-step reasoning, instruction following,
    and accuracy in high-stakes use cases. It supports test-time routing features
    and advanced prompt understanding, including user-specified intent like "think
    hard about this." Improvements include reductions in hallucination, sycophancy,
    and better performance in coding, writing, and health-related tasks.
  context_length: 400000
  pricing:
    prompt: 2.1e-05
    completion: 0.000168
    image: 0.0
    request: 0.0
    currency: USD
  capabilities:
    supports_vision: true
    supports_function_calling: true
    supports_streaming: true
    modalities:
    - text
    - image->text
  metadata:
    architecture: GPT
  updated_at: 2025-12-19 00:46:07.737090+00:00
- model_id: openai/gpt-5.2
  name: 'OpenAI: GPT-5.2'
  provider: openrouter
  description: 'GPT-5.2 is the latest frontier-grade model in the GPT-5 series, offering
    stronger agentic and long context perfomance compared to GPT-5.1. It uses adaptive
    reasoning to allocate computation dynamically, responding quickly to simple queries
    while spending more depth on complex tasks.


    Built for broad task coverage, GPT-5.2 delivers consistent gains across math,
    coding, sciende, and tool calling workloads, with more coherent long-form answers
    and improved tool-use reliability.'
  context_length: 400000
  pricing:
    prompt: 1.75e-06
    completion: 1.4e-05
    image: 0.0
    request: 0.0
    currency: USD
  capabilities:
    supports_vision: true
    supports_function_calling: true
    supports_streaming: true
    modalities:
    - text
    - image->text
  metadata:
    architecture: GPT
  updated_at: 2025-12-19 00:46:07.737102+00:00
- model_id: mistralai/devstral-2512:free
  name: 'Mistral: Devstral 2 2512 (free)'
  provider: openrouter
  description: 'Devstral 2 is a state-of-the-art open-source model by Mistral AI specializing
    in agentic coding. It is a 123B-parameter dense transformer model supporting a
    256K context window.


    Devstral 2 supports exploring codebases and orchestrating changes across multiple
    files while maintaining architecture-level context. It tracks framework dependencies,
    detects failures, and retries with corrections—solving challenges like bug fixing
    and modernizing legacy systems. The model can be fine-tuned to prioritize specific
    languages or optimize for large enterprise codebases. It is available under a
    modified MIT license.'
  context_length: 262144
  pricing:
    prompt: 0.0
    completion: 0.0
    image: 0.0
    request: 0.0
    currency: USD
  capabilities:
    supports_vision: false
    supports_function_calling: true
    supports_streaming: true
    modalities:
    - text
    - text->text
  metadata:
    architecture: Mistral
  updated_at: 2025-12-19 00:46:07.737115+00:00
- model_id: mistralai/devstral-2512
  name: 'Mistral: Devstral 2 2512'
  provider: openrouter
  description: 'Devstral 2 is a state-of-the-art open-source model by Mistral AI specializing
    in agentic coding. It is a 123B-parameter dense transformer model supporting a
    256K context window.


    Devstral 2 supports exploring codebases and orchestrating changes across multiple
    files while maintaining architecture-level context. It tracks framework dependencies,
    detects failures, and retries with corrections—solving challenges like bug fixing
    and modernizing legacy systems. The model can be fine-tuned to prioritize specific
    languages or optimize for large enterprise codebases. It is available under a
    modified MIT license.'
  context_length: 262144
  pricing:
    prompt: 1.5e-07
    completion: 6.0e-07
    image: 0.0
    request: 0.0
    currency: USD
  capabilities:
    supports_vision: false
    supports_function_calling: true
    supports_streaming: true
    modalities:
    - text
    - text->text
  metadata:
    architecture: Mistral
  updated_at: 2025-12-19 00:46:07.737127+00:00
- model_id: relace/relace-search
  name: 'Relace: Relace Search'
  provider: openrouter
  description: "The relace-search model uses 4-12 `view_file` and `grep` tools in\
    \ parallel to explore a codebase and return relevant files to the user request.\
    \ \n\nIn contrast to RAG, relace-search performs agentic multi-step reasoning\
    \ to produce highly precise results 4x faster than any frontier model. It's designed\
    \ to serve as a subagent that passes its findings to an \"oracle\" coding agent,\
    \ who orchestrates/performs the rest of the coding task.\n\nTo use relace-search\
    \ you need to build an appropriate agent harness, and parse the response for relevant\
    \ information to hand off to the oracle. Read more about it in the [Relace documentation](https://docs.relace.ai/docs/fast-agentic-search/agent)."
  context_length: 256000
  pricing:
    prompt: 1.0e-06
    completion: 3.0e-06
    image: 0.0
    request: 0.0
    currency: USD
  capabilities:
    supports_vision: false
    supports_function_calling: true
    supports_streaming: true
    modalities:
    - text
    - text->text
  metadata:
    architecture: Other
  updated_at: 2025-12-19 00:46:07.737140+00:00
- model_id: z-ai/glm-4.6v
  name: 'Z.AI: GLM 4.6V'
  provider: openrouter
  description: GLM-4.6V is a large multimodal model designed for high-fidelity visual
    understanding and long-context reasoning across images, documents, and mixed media.
    It supports up to 128K tokens, processes complex page layouts and charts directly
    as visual inputs, and integrates native multimodal function calling to connect
    perception with downstream tool execution. The model also enables interleaved
    image-text generation and UI reconstruction workflows, including screenshot-to-HTML
    synthesis and iterative visual editing.
  context_length: 131072
  pricing:
    prompt: 3.0e-07
    completion: 9.0e-07
    image: 0.0
    request: 0.0
    currency: USD
  capabilities:
    supports_vision: true
    supports_function_calling: true
    supports_streaming: true
    modalities:
    - text
    - image->text
  metadata:
    architecture: Other
  updated_at: 2025-12-19 00:46:07.737150+00:00
- model_id: nex-agi/deepseek-v3.1-nex-n1:free
  name: 'Nex AGI: DeepSeek V3.1 Nex N1 (free)'
  provider: openrouter
  description: "DeepSeek V3.1 Nex-N1 is the flagship release of the Nex-N1 series\
    \ — a post-trained model designed to highlight agent autonomy, tool use, and real-world\
    \ productivity. \n\nNex-N1 demonstrates competitive performance across all evaluation\
    \ scenarios, showing particularly strong results in practical coding and HTML\
    \ generation tasks."
  context_length: 131072
  pricing:
    prompt: 0.0
    completion: 0.0
    image: 0.0
    request: 0.0
    currency: USD
  capabilities:
    supports_vision: false
    supports_function_calling: true
    supports_streaming: true
    modalities:
    - text
    - text->text
  metadata:
    architecture: DeepSeek
  updated_at: 2025-12-19 00:46:07.737158+00:00
- model_id: essentialai/rnj-1-instruct
  name: 'EssentialAI: Rnj 1 Instruct'
  provider: openrouter
  description: 'Rnj-1 is an 8B-parameter, dense, open-weight model family developed
    by Essential AI and trained from scratch with a focus on programming, math, and
    scientific reasoning. The model demonstrates strong performance across multiple
    programming languages, tool-use workflows, and agentic execution environments
    (e.g., mini-SWE-agent). '
  context_length: 32768
  pricing:
    prompt: 1.5e-07
    completion: 1.5e-07
    image: 0.0
    request: 0.0
    currency: USD
  capabilities:
    supports_vision: false
    supports_function_calling: false
    supports_streaming: true
    modalities:
    - text
    - text->text
  metadata:
    architecture: Other
  updated_at: 2025-12-19 00:46:07.737167+00:00
- model_id: openrouter/bodybuilder
  name: Body Builder (beta)
  provider: openrouter
  description: 'Transform your natural language requests into structured OpenRouter
    API request objects. Describe what you want to accomplish with AI models, and
    Body Builder will construct the appropriate API calls. Example: "count to 10 using
    gemini and opus."


    This is useful for creating multi-model requests, custom model routers, or programmatic
    generation of API calls from human descriptions.


    **BETA NOTICE**: Body Builder is in beta, and currently free. Pricing and functionality
    may change in the future.'
  context_length: 128000
  pricing:
    prompt: -1.0
    completion: -1.0
    image: null
    request: null
    currency: USD
  capabilities:
    supports_vision: false
    supports_function_calling: false
    supports_streaming: true
    modalities:
    - text
    - text->text
  metadata:
    architecture: Router
  updated_at: 2025-12-19 00:46:07.737179+00:00
- model_id: openai/gpt-5.1-codex-max
  name: 'OpenAI: GPT-5.1-Codex-Max'
  provider: openrouter
  description: "GPT-5.1-Codex-Max is OpenAI’s latest agentic coding model, designed\
    \ for long-running, high-context software development tasks. It is based on an\
    \ updated version of the 5.1 reasoning stack and trained on agentic workflows\
    \ spanning software engineering, mathematics, and research. \nGPT-5.1-Codex-Max\
    \ delivers faster performance, improved reasoning, and higher token efficiency\
    \ across the development lifecycle. "
  context_length: 400000
  pricing:
    prompt: 1.25e-06
    completion: 1.0e-05
    image: 0.0
    request: 0.0
    currency: USD
  capabilities:
    supports_vision: true
    supports_function_calling: true
    supports_streaming: true
    modalities:
    - text
    - image->text
  metadata:
    architecture: GPT
  updated_at: 2025-12-19 00:46:07.737188+00:00
- model_id: amazon/nova-2-lite-v1
  name: 'Amazon: Nova 2 Lite'
  provider: openrouter
  description: "Nova 2 Lite is a fast, cost-effective reasoning model for everyday\
    \ workloads that can process text, images, and videos to generate text. \n\nNova\
    \ 2 Lite demonstrates standout capabilities in processing documents, extracting\
    \ information from videos, generating code, providing accurate grounded answers,\
    \ and automating multi-step agentic workflows."
  context_length: 1000000
  pricing:
    prompt: 3.0e-07
    completion: 2.5e-06
    image: 0.0
    request: 0.0
    currency: USD
  capabilities:
    supports_vision: true
    supports_function_calling: true
    supports_streaming: true
    modalities:
    - text
    - image->text
  metadata:
    architecture: Nova
  updated_at: 2025-12-19 00:46:07.737200+00:00
- model_id: mistralai/ministral-14b-2512
  name: 'Mistral: Ministral 3 14B 2512'
  provider: openrouter
  description: The largest model in the Ministral 3 family, Ministral 3 14B offers
    frontier capabilities and performance comparable to its larger Mistral Small 3.2
    24B counterpart. A powerful and efficient language model with vision capabilities.
  context_length: 262144
  pricing:
    prompt: 2.0e-07
    completion: 2.0e-07
    image: 0.0
    request: 0.0
    currency: USD
  capabilities:
    supports_vision: true
    supports_function_calling: true
    supports_streaming: true
    modalities:
    - text
    - image->text
  metadata:
    architecture: Mistral
  updated_at: 2025-12-19 00:46:07.737212+00:00
- model_id: mistralai/ministral-8b-2512
  name: 'Mistral: Ministral 3 8B 2512'
  provider: openrouter
  description: A balanced model in the Ministral 3 family, Ministral 3 8B is a powerful,
    efficient tiny language model with vision capabilities.
  context_length: 262144
  pricing:
    prompt: 1.5e-07
    completion: 1.5e-07
    image: 0.0
    request: 0.0
    currency: USD
  capabilities:
    supports_vision: true
    supports_function_calling: true
    supports_streaming: true
    modalities:
    - text
    - image->text
  metadata:
    architecture: Mistral
  updated_at: 2025-12-19 00:46:07.737233+00:00
- model_id: mistralai/ministral-3b-2512
  name: 'Mistral: Ministral 3 3B 2512'
  provider: openrouter
  description: The smallest model in the Ministral 3 family, Ministral 3 3B is a powerful,
    efficient tiny language model with vision capabilities.
  context_length: 131072
  pricing:
    prompt: 1.0e-07
    completion: 1.0e-07
    image: 0.0
    request: 0.0
    currency: USD
  capabilities:
    supports_vision: true
    supports_function_calling: true
    supports_streaming: true
    modalities:
    - text
    - image->text
  metadata:
    architecture: Mistral
  updated_at: 2025-12-19 00:46:07.737248+00:00
- model_id: mistralai/mistral-large-2512
  name: 'Mistral: Mistral Large 3 2512'
  provider: openrouter
  description: Mistral Large 3 2512 is Mistral’s most capable model to date, featuring
    a sparse mixture-of-experts architecture with 41B active parameters (675B total),
    and released under the Apache 2.0 license.
  context_length: 262144
  pricing:
    prompt: 5.0e-07
    completion: 1.5e-06
    image: 0.0
    request: 0.0
    currency: USD
  capabilities:
    supports_vision: true
    supports_function_calling: true
    supports_streaming: true
    modalities:
    - text
    - image->text
  metadata:
    architecture: Mistral
  updated_at: 2025-12-19 00:46:07.737257+00:00
- model_id: arcee-ai/trinity-mini:free
  name: 'Arcee AI: Trinity Mini (free)'
  provider: openrouter
  description: Trinity Mini is a 26B-parameter (3B active) sparse mixture-of-experts
    language model featuring 128 experts with 8 active per token. Engineered for efficient
    reasoning over long contexts (131k) with robust function calling and multi-step
    agent workflows.
  context_length: 131072
  pricing:
    prompt: 0.0
    completion: 0.0
    image: 0.0
    request: 0.0
    currency: USD
  capabilities:
    supports_vision: false
    supports_function_calling: true
    supports_streaming: true
    modalities:
    - text
    - text->text
  metadata:
    architecture: Other
  updated_at: 2025-12-19 00:46:07.737266+00:00
- model_id: arcee-ai/trinity-mini
  name: 'Arcee AI: Trinity Mini'
  provider: openrouter
  description: Trinity Mini is a 26B-parameter (3B active) sparse mixture-of-experts
    language model featuring 128 experts with 8 active per token. Engineered for efficient
    reasoning over long contexts (131k) with robust function calling and multi-step
    agent workflows.
  context_length: 131072
  pricing:
    prompt: 4.5e-08
    completion: 1.5e-07
    image: 0.0
    request: 0.0
    currency: USD
  capabilities:
    supports_vision: false
    supports_function_calling: true
    supports_streaming: true
    modalities:
    - text
    - text->text
  metadata:
    architecture: Other
  updated_at: 2025-12-19 00:46:07.737281+00:00
- model_id: deepseek/deepseek-v3.2-speciale
  name: 'DeepSeek: DeepSeek V3.2 Speciale'
  provider: openrouter
  description: DeepSeek-V3.2-Speciale is a high-compute variant of DeepSeek-V3.2 optimized
    for maximum reasoning and agentic performance. It builds on DeepSeek Sparse Attention
    (DSA) for efficient long-context processing, then scales post-training reinforcement
    learning to push capability beyond the base model. Reported evaluations place
    Speciale ahead of GPT-5 on difficult reasoning workloads, with proficiency comparable
    to Gemini-3.0-Pro, while retaining strong coding and tool-use reliability. Like
    V3.2, it benefits from a large-scale agentic task synthesis pipeline that improves
    compliance and generalization in interactive environments.
  context_length: 163840
  pricing:
    prompt: 2.7e-07
    completion: 4.1e-07
    image: 0.0
    request: 0.0
    currency: USD
  capabilities:
    supports_vision: false
    supports_function_calling: false
    supports_streaming: true
    modalities:
    - text
    - text->text
  metadata:
    architecture: DeepSeek
  updated_at: 2025-12-19 00:46:07.737290+00:00
- model_id: deepseek/deepseek-v3.2
  name: 'DeepSeek: DeepSeek V3.2'
  provider: openrouter
  description: 'DeepSeek-V3.2 is a large language model designed to harmonize high
    computational efficiency with strong reasoning and agentic tool-use performance.
    It introduces DeepSeek Sparse Attention (DSA), a fine-grained sparse attention
    mechanism that reduces training and inference cost while preserving quality in
    long-context scenarios. A scalable reinforcement learning post-training framework
    further improves reasoning, with reported performance in the GPT-5 class, and
    the model has demonstrated gold-medal results on the 2025 IMO and IOI. V3.2 also
    uses a large-scale agentic task synthesis pipeline to better integrate reasoning
    into tool-use settings, boosting compliance and generalization in interactive
    environments.


    Users can control the reasoning behaviour with the `reasoning` `enabled` boolean.
    [Learn more in our docs](https://openrouter.ai/docs/use-cases/reasoning-tokens#enable-reasoning-with-default-config)'
  context_length: 163840
  pricing:
    prompt: 2.4e-07
    completion: 3.8e-07
    image: 0.0
    request: 0.0
    currency: USD
  capabilities:
    supports_vision: false
    supports_function_calling: true
    supports_streaming: true
    modalities:
    - text
    - text->text
  metadata:
    architecture: DeepSeek
  updated_at: 2025-12-19 00:46:07.737299+00:00
- model_id: prime-intellect/intellect-3
  name: 'Prime Intellect: INTELLECT-3'
  provider: openrouter
  description: INTELLECT-3 is a 106B-parameter Mixture-of-Experts model (12B active)
    post-trained from GLM-4.5-Air-Base using supervised fine-tuning (SFT) followed
    by large-scale reinforcement learning (RL). It offers state-of-the-art performance
    for its size across math, code, science, and general reasoning, consistently outperforming
    many larger frontier models. Designed for strong multi-step problem solving, it
    maintains high accuracy on structured tasks while remaining efficient at inference
    thanks to its MoE architecture.
  context_length: 131072
  pricing:
    prompt: 2.0e-07
    completion: 1.1e-06
    image: 0.0
    request: 0.0
    currency: USD
  capabilities:
    supports_vision: false
    supports_function_calling: true
    supports_streaming: true
    modalities:
    - text
    - text->text
  metadata:
    architecture: Other
  updated_at: 2025-12-19 00:46:07.737310+00:00
- model_id: tngtech/tng-r1t-chimera:free
  name: 'TNG: R1T Chimera (free)'
  provider: openrouter
  description: 'TNG-R1T-Chimera is an experimental LLM with a faible for creative
    storytelling and character interaction. It is a derivate of the original TNG/DeepSeek-R1T-Chimera
    released in April 2025 and is available exclusively via Chutes and OpenRouter.


    Characteristics and improvements include:


    We think that it has a creative and pleasant personality.

    It has a preliminary EQ-Bench3 value of about 1305.

    It is quite a bit more intelligent than the original, albeit a slightly slower.

    It is much more think-token consistent, i.e. reasoning and answer blocks are properly
    delineated.

    Tool calling is much improved.


    TNG Tech, the model authors, ask that users follow the careful guidelines that
    Microsoft has created for their "MAI-DS-R1" DeepSeek-based model. These guidelines
    are available on Hugging Face (https://huggingface.co/microsoft/MAI-DS-R1).'
  context_length: 163840
  pricing:
    prompt: 0.0
    completion: 0.0
    image: 0.0
    request: 0.0
    currency: USD
  capabilities:
    supports_vision: false
    supports_function_calling: true
    supports_streaming: true
    modalities:
    - text
    - text->text
  metadata:
    architecture: Other
  updated_at: 2025-12-19 00:46:07.737318+00:00
- model_id: tngtech/tng-r1t-chimera
  name: 'TNG: R1T Chimera'
  provider: openrouter
  description: 'TNG-R1T-Chimera is an experimental LLM with a faible for creative
    storytelling and character interaction. It is a derivate of the original TNG/DeepSeek-R1T-Chimera
    released in April 2025 and is available exclusively via Chutes and OpenRouter.


    Characteristics and improvements include:


    We think that it has a creative and pleasant personality.

    It has a preliminary EQ-Bench3 value of about 1305.

    It is quite a bit more intelligent than the original, albeit a slightly slower.

    It is much more think-token consistent, i.e. reasoning and answer blocks are properly
    delineated.

    Tool calling is much improved.


    TNG Tech, the model authors, ask that users follow the careful guidelines that
    Microsoft has created for their "MAI-DS-R1" DeepSeek-based model. These guidelines
    are available on Hugging Face (https://huggingface.co/microsoft/MAI-DS-R1).'
  context_length: 163840
  pricing:
    prompt: 3.0e-07
    completion: 1.2e-06
    image: 0.0
    request: 0.0
    currency: USD
  capabilities:
    supports_vision: false
    supports_function_calling: true
    supports_streaming: true
    modalities:
    - text
    - text->text
  metadata:
    architecture: Other
  updated_at: 2025-12-19 00:46:07.737327+00:00
- model_id: anthropic/claude-opus-4.5
  name: 'Anthropic: Claude Opus 4.5'
  provider: openrouter
  description: 'Claude Opus 4.5 is Anthropic’s frontier reasoning model optimized
    for complex software engineering, agentic workflows, and long-horizon computer
    use. It offers strong multimodal capabilities, competitive performance across
    real-world coding and reasoning benchmarks, and improved robustness to prompt
    injection. The model is designed to operate efficiently across varied effort levels,
    enabling developers to trade off speed, depth, and token usage depending on task
    requirements. It comes with a new parameter to control token efficiency, which
    can be accessed using the OpenRouter Verbosity parameter with low, medium, or
    high.


    Opus 4.5 supports advanced tool use, extended context management, and coordinated
    multi-agent setups, making it well-suited for autonomous research, debugging,
    multi-step planning, and spreadsheet/browser manipulation. It delivers substantial
    gains in structured reasoning, execution reliability, and alignment compared to
    prior Opus generations, while reducing token overhead and improving performance
    on long-running tasks.'
  context_length: 200000
  pricing:
    prompt: 5.0e-06
    completion: 2.5e-05
    image: 0.0
    request: 0.0
    currency: USD
  capabilities:
    supports_vision: true
    supports_function_calling: true
    supports_streaming: true
    modalities:
    - text
    - image->text
  metadata:
    architecture: Claude
  updated_at: 2025-12-19 00:46:07.737337+00:00
- model_id: allenai/olmo-3-32b-think:free
  name: 'AllenAI: Olmo 3 32B Think (free)'
  provider: openrouter
  description: Olmo 3 32B Think is a large-scale, 32-billion-parameter model purpose-built
    for deep reasoning, complex logic chains and advanced instruction-following scenarios.
    Its capacity enables strong performance on demanding evaluation tasks and highly
    nuanced conversational reasoning. Developed by Ai2 under the Apache 2.0 license,
    Olmo 3 32B Think embodies the Olmo initiative’s commitment to openness, offering
    full transparency across weights, code and training methodology.
  context_length: 65536
  pricing:
    prompt: 0.0
    completion: 0.0
    image: 0.0
    request: 0.0
    currency: USD
  capabilities:
    supports_vision: false
    supports_function_calling: false
    supports_streaming: true
    modalities:
    - text
    - text->text
  metadata:
    architecture: Other
  updated_at: 2025-12-19 00:46:07.737352+00:00
- model_id: allenai/olmo-3-7b-instruct
  name: 'AllenAI: Olmo 3 7B Instruct'
  provider: openrouter
  description: Olmo 3 7B Instruct is a supervised instruction-fine-tuned variant of
    the Olmo 3 7B base model, optimized for instruction-following, question-answering,
    and natural conversational dialogue. By leveraging high-quality instruction data
    and an open training pipeline, it delivers strong performance across everyday
    NLP tasks while remaining accessible and easy to integrate. Developed by Ai2 under
    the Apache 2.0 license, the model offers a transparent, community-friendly option
    for instruction-driven applications.
  context_length: 65536
  pricing:
    prompt: 1.0e-07
    completion: 2.0e-07
    image: 0.0
    request: 0.0
    currency: USD
  capabilities:
    supports_vision: false
    supports_function_calling: true
    supports_streaming: true
    modalities:
    - text
    - text->text
  metadata:
    architecture: Other
  updated_at: 2025-12-19 00:46:07.737361+00:00
- model_id: allenai/olmo-3-7b-think
  name: 'AllenAI: Olmo 3 7B Think'
  provider: openrouter
  description: Olmo 3 7B Think is a research-oriented language model in the Olmo family
    designed for advanced reasoning and instruction-driven tasks. It excels at multi-step
    problem solving, logical inference, and maintaining coherent conversational context.
    Developed by Ai2 under the Apache 2.0 license, Olmo 3 7B Think supports transparent,
    fully open experimentation and provides a lightweight yet capable foundation for
    academic research and practical NLP workflows.
  context_length: 65536
  pricing:
    prompt: 1.2e-07
    completion: 2.0e-07
    image: 0.0
    request: 0.0
    currency: USD
  capabilities:
    supports_vision: false
    supports_function_calling: false
    supports_streaming: true
    modalities:
    - text
    - text->text
  metadata:
    architecture: Other
  updated_at: 2025-12-19 00:46:07.737369+00:00
- model_id: google/gemini-3-pro-image-preview
  name: 'Google: Nano Banana Pro (Gemini 3 Pro Image Preview)'
  provider: openrouter
  description: 'Nano Banana Pro is Google’s most advanced image-generation and editing
    model, built on Gemini 3 Pro. It extends the original Nano Banana with significantly
    improved multimodal reasoning, real-world grounding, and high-fidelity visual
    synthesis. The model generates context-rich graphics, from infographics and diagrams
    to cinematic composites, and can incorporate real-time information via Search
    grounding.


    It offers industry-leading text rendering in images (including long passages and
    multilingual layouts), consistent multi-image blending, and accurate identity
    preservation across up to five subjects. Nano Banana Pro adds fine-grained creative
    controls such as localized edits, lighting and focus adjustments, camera transformations,
    and support for 2K/4K outputs and flexible aspect ratios. It is designed for professional-grade
    design, product visualization, storyboarding, and complex multi-element compositions
    while remaining efficient for general image creation workflows.'
  context_length: 65536
  pricing:
    prompt: 2.0e-06
    completion: 1.2e-05
    image: 0.067
    request: 0.0
    currency: USD
  capabilities:
    supports_vision: true
    supports_function_calling: false
    supports_streaming: true
    modalities:
    - text
    - image->text
    - image
  metadata:
    architecture: Gemini
  updated_at: 2025-12-19 00:46:07.737379+00:00
- model_id: x-ai/grok-4.1-fast
  name: 'xAI: Grok 4.1 Fast'
  provider: openrouter
  description: 'Grok 4.1 Fast is xAI''s best agentic tool calling model that shines
    in real-world use cases like customer support and deep research. 2M context window.


    Reasoning can be enabled/disabled using the `reasoning` `enabled` parameter in
    the API. [Learn more in our docs](https://openrouter.ai/docs/use-cases/reasoning-tokens#controlling-reasoning-tokens)'
  context_length: 2000000
  pricing:
    prompt: 2.0e-07
    completion: 5.0e-07
    image: 0.0
    request: 0.0
    currency: USD
  capabilities:
    supports_vision: true
    supports_function_calling: true
    supports_streaming: true
    modalities:
    - text
    - image->text
  metadata:
    architecture: Grok
  updated_at: 2025-12-19 00:46:07.737390+00:00
- model_id: google/gemini-3-pro-preview
  name: 'Google: Gemini 3 Pro Preview'
  provider: openrouter
  description: 'Gemini 3 Pro is Google’s flagship frontier model for high-precision
    multimodal reasoning, combining strong performance across text, image, video,
    audio, and code with a 1M-token context window. Reasoning Details must be preserved
    when using multi-turn tool calling, see our docs here: https://openrouter.ai/docs/use-cases/reasoning-tokens#preserving-reasoning-blocks.
    It delivers state-of-the-art benchmark results in general reasoning, STEM problem
    solving, factual QA, and multimodal understanding, including leading scores on
    LMArena, GPQA Diamond, MathArena Apex, MMMU-Pro, and Video-MMMU. Interactions
    emphasize depth and interpretability: the model is designed to infer intent with
    minimal prompting and produce direct, insight-focused responses.


    Built for advanced development and agentic workflows, Gemini 3 Pro provides robust
    tool-calling, long-horizon planning stability, and strong zero-shot generation
    for complex UI, visualization, and coding tasks. It excels at agentic coding (SWE-Bench
    Verified, Terminal-Bench 2.0), multimodal analysis, and structured long-form tasks
    such as research synthesis, planning, and interactive learning experiences. Suitable
    applications include autonomous agents, coding assistants, multimodal analytics,
    scientific reasoning, and high-context information processing.'
  context_length: 1048576
  pricing:
    prompt: 2.0e-06
    completion: 1.2e-05
    image: 0.008256
    request: 0.0
    currency: USD
  capabilities:
    supports_vision: true
    supports_function_calling: true
    supports_streaming: true
    modalities:
    - text
    - image->text
  metadata:
    architecture: Gemini
  updated_at: 2025-12-19 00:46:07.737401+00:00
- model_id: deepcogito/cogito-v2.1-671b
  name: 'Deep Cogito: Cogito v2.1 671B'
  provider: openrouter
  description: Cogito v2.1 671B MoE represents one of the strongest open models globally,
    matching performance of frontier closed and open models. This model is trained
    using self play with reinforcement learning to reach state-of-the-art performance
    on multiple categories (instruction following, coding, longer queries and creative
    writing). This advanced system demonstrates significant progress toward scalable
    superintelligence through policy improvement.
  context_length: 128000
  pricing:
    prompt: 1.25e-06
    completion: 1.25e-06
    image: 0.0
    request: 0.0
    currency: USD
  capabilities:
    supports_vision: false
    supports_function_calling: false
    supports_streaming: true
    modalities:
    - text
    - text->text
  metadata:
    architecture: Other
  updated_at: 2025-12-19 00:46:07.737412+00:00
- model_id: openai/gpt-5.1
  name: 'OpenAI: GPT-5.1'
  provider: openrouter
  description: 'GPT-5.1 is the latest frontier-grade model in the GPT-5 series, offering
    stronger general-purpose reasoning, improved instruction adherence, and a more
    natural conversational style compared to GPT-5. It uses adaptive reasoning to
    allocate computation dynamically, responding quickly to simple queries while spending
    more depth on complex tasks. The model produces clearer, more grounded explanations
    with reduced jargon, making it easier to follow even on technical or multi-step
    problems.


    Built for broad task coverage, GPT-5.1 delivers consistent gains across math,
    coding, and structured analysis workloads, with more coherent long-form answers
    and improved tool-use reliability. It also features refined conversational alignment,
    enabling warmer, more intuitive responses without compromising precision. GPT-5.1
    serves as the primary full-capability successor to GPT-5'
  context_length: 400000
  pricing:
    prompt: 1.25e-06
    completion: 1.0e-05
    image: 0.0
    request: 0.0
    currency: USD
  capabilities:
    supports_vision: true
    supports_function_calling: true
    supports_streaming: true
    modalities:
    - text
    - image->text
  metadata:
    architecture: GPT
  updated_at: 2025-12-19 00:46:07.737422+00:00
- model_id: openai/gpt-5.1-chat
  name: 'OpenAI: GPT-5.1 Chat'
  provider: openrouter
  description: 'GPT-5.1 Chat (AKA Instant is the fast, lightweight member of the 5.1
    family, optimized for low-latency chat while retaining strong general intelligence.
    It uses adaptive reasoning to selectively “think” on harder queries, improving
    accuracy on math, coding, and multi-step tasks without slowing down typical conversations.
    The model is warmer and more conversational by default, with better instruction
    following and more stable short-form reasoning. GPT-5.1 Chat is designed for high-throughput,
    interactive workloads where responsiveness and consistency matter more than deep
    deliberation.

    '
  context_length: 128000
  pricing:
    prompt: 1.25e-06
    completion: 1.0e-05
    image: 0.0
    request: 0.0
    currency: USD
  capabilities:
    supports_vision: true
    supports_function_calling: true
    supports_streaming: true
    modalities:
    - text
    - image->text
  metadata:
    architecture: GPT
  updated_at: 2025-12-19 00:46:07.737433+00:00
- model_id: openai/gpt-5.1-codex
  name: 'OpenAI: GPT-5.1-Codex'
  provider: openrouter
  description: 'GPT-5.1-Codex is a specialized version of GPT-5.1 optimized for software
    engineering and coding workflows. It is designed for both interactive development
    sessions and long, independent execution of complex engineering tasks. The model
    supports building projects from scratch, feature development, debugging, large-scale
    refactoring, and code review. Compared to GPT-5.1, Codex is more steerable, adheres
    closely to developer instructions, and produces cleaner, higher-quality code outputs.
    Reasoning effort can be adjusted with the `reasoning.effort` parameter. Read the
    [docs here](https://openrouter.ai/docs/use-cases/reasoning-tokens#reasoning-effort-level)


    Codex integrates into developer environments including the CLI, IDE extensions,
    GitHub, and cloud tasks. It adapts reasoning effort dynamically—providing fast
    responses for small tasks while sustaining extended multi-hour runs for large
    projects. The model is trained to perform structured code reviews, catching critical
    flaws by reasoning over dependencies and validating behavior against tests. It
    also supports multimodal inputs such as images or screenshots for UI development
    and integrates tool use for search, dependency installation, and environment setup.
    Codex is intended specifically for agentic coding applications.'
  context_length: 400000
  pricing:
    prompt: 1.25e-06
    completion: 1.0e-05
    image: 0.0
    request: 0.0
    currency: USD
  capabilities:
    supports_vision: true
    supports_function_calling: true
    supports_streaming: true
    modalities:
    - text
    - image->text
  metadata:
    architecture: GPT
  updated_at: 2025-12-19 00:46:07.737447+00:00
- model_id: openai/gpt-5.1-codex-mini
  name: 'OpenAI: GPT-5.1-Codex-Mini'
  provider: openrouter
  description: GPT-5.1-Codex-Mini is a smaller and faster version of GPT-5.1-Codex
  context_length: 400000
  pricing:
    prompt: 2.5e-07
    completion: 2.0e-06
    image: 0.0
    request: 0.0
    currency: USD
  capabilities:
    supports_vision: true
    supports_function_calling: true
    supports_streaming: true
    modalities:
    - text
    - image->text
  metadata:
    architecture: GPT
  updated_at: 2025-12-19 00:46:07.737456+00:00
- model_id: kwaipilot/kat-coder-pro:free
  name: 'Kwaipilot: KAT-Coder-Pro V1 (free)'
  provider: openrouter
  description: "KAT-Coder-Pro V1 is KwaiKAT's most advanced agentic coding model in\
    \ the KAT-Coder series. Designed specifically for agentic coding tasks, it excels\
    \ in real-world software engineering scenarios, achieving 73.4% solve rate on\
    \ the SWE-Bench Verified benchmark. \n\nThe model has been optimized for tool-use\
    \ capability, multi-turn interaction, instruction following, generalization, and\
    \ comprehensive capabilities through a multi-stage training process, including\
    \ mid-training, supervised fine-tuning (SFT), reinforcement fine-tuning (RFT),\
    \ and scalable agentic RL."
  context_length: 256000
  pricing:
    prompt: 0.0
    completion: 0.0
    image: 0.0
    request: 0.0
    currency: USD
  capabilities:
    supports_vision: false
    supports_function_calling: true
    supports_streaming: true
    modalities:
    - text
    - text->text
  metadata:
    architecture: Other
  updated_at: 2025-12-19 00:46:07.737469+00:00
- model_id: moonshotai/kimi-k2-thinking
  name: 'MoonshotAI: Kimi K2 Thinking'
  provider: openrouter
  description: 'Kimi K2 Thinking is Moonshot AI’s most advanced open reasoning model
    to date, extending the K2 series into agentic, long-horizon reasoning. Built on
    the trillion-parameter Mixture-of-Experts (MoE) architecture introduced in Kimi
    K2, it activates 32 billion parameters per forward pass and supports 256 k-token
    context windows. The model is optimized for persistent step-by-step thought, dynamic
    tool invocation, and complex reasoning workflows that span hundreds of turns.
    It interleaves step-by-step reasoning with tool use, enabling autonomous research,
    coding, and writing that can persist for hundreds of sequential actions without
    drift.


    It sets new open-source benchmarks on HLE, BrowseComp, SWE-Multilingual, and LiveCodeBench,
    while maintaining stable multi-agent behavior through 200–300 tool calls. Built
    on a large-scale MoE architecture with MuonClip optimization, it combines strong
    reasoning depth with high inference efficiency for demanding agentic and analytical
    tasks.'
  context_length: 262144
  pricing:
    prompt: 4.5e-07
    completion: 2.35e-06
    image: 0.0
    request: 0.0
    currency: USD
  capabilities:
    supports_vision: false
    supports_function_calling: true
    supports_streaming: true
    modalities:
    - text
    - text->text
  metadata:
    architecture: Other
  updated_at: 2025-12-19 00:46:07.737480+00:00
- model_id: amazon/nova-premier-v1
  name: 'Amazon: Nova Premier 1.0'
  provider: openrouter
  description: Amazon Nova Premier is the most capable of Amazon’s multimodal models
    for complex reasoning tasks and for use as the best teacher for distilling custom
    models.
  context_length: 1000000
  pricing:
    prompt: 2.5e-06
    completion: 1.25e-05
    image: 0.0
    request: 0.0
    currency: USD
  capabilities:
    supports_vision: true
    supports_function_calling: true
    supports_streaming: true
    modalities:
    - text
    - image->text
  metadata:
    architecture: Nova
  updated_at: 2025-12-19 00:46:07.737490+00:00
- model_id: perplexity/sonar-pro-search
  name: 'Perplexity: Sonar Pro Search'
  provider: openrouter
  description: 'Exclusively available on the OpenRouter API, Sonar Pro''s new Pro
    Search mode is Perplexity''s most advanced agentic search system. It is designed
    for deeper reasoning and analysis. Pricing is based on tokens plus $18 per thousand
    requests. This model powers the Pro Search mode on the Perplexity platform.


    Sonar Pro Search adds autonomous, multi-step reasoning to Sonar Pro. So, instead
    of just one query + synthesis, it plans and executes entire research workflows
    using tools.'
  context_length: 200000
  pricing:
    prompt: 3.0e-06
    completion: 1.5e-05
    image: 0.0
    request: 0.018
    currency: USD
  capabilities:
    supports_vision: true
    supports_function_calling: false
    supports_streaming: true
    modalities:
    - text
    - image->text
  metadata:
    architecture: Other
  updated_at: 2025-12-19 00:46:07.737500+00:00
- model_id: mistralai/voxtral-small-24b-2507
  name: 'Mistral: Voxtral Small 24B 2507'
  provider: openrouter
  description: Voxtral Small is an enhancement of Mistral Small 3, incorporating state-of-the-art
    audio input capabilities while retaining best-in-class text performance. It excels
    at speech transcription, translation and audio understanding. Input audio is priced
    at $100 per million seconds.
  context_length: 32000
  pricing:
    prompt: 1.0e-07
    completion: 3.0e-07
    image: 0.0
    request: 0.0
    currency: USD
  capabilities:
    supports_vision: false
    supports_function_calling: true
    supports_streaming: true
    modalities:
    - text
    - text->text
  metadata:
    architecture: Mistral
  updated_at: 2025-12-19 00:46:07.737508+00:00
- model_id: openai/gpt-oss-safeguard-20b
  name: 'OpenAI: gpt-oss-safeguard-20b'
  provider: openrouter
  description: 'gpt-oss-safeguard-20b is a safety reasoning model from OpenAI built
    upon gpt-oss-20b. This open-weight, 21B-parameter Mixture-of-Experts (MoE) model
    offers lower latency for safety tasks like content classification, LLM filtering,
    and trust & safety labeling.


    Learn more about this model in OpenAI''s gpt-oss-safeguard [user guide](https://cookbook.openai.com/articles/gpt-oss-safeguard-guide).'
  context_length: 131072
  pricing:
    prompt: 7.5e-08
    completion: 3.0e-07
    image: 0.0
    request: 0.0
    currency: USD
  capabilities:
    supports_vision: false
    supports_function_calling: true
    supports_streaming: true
    modalities:
    - text
    - text->text
  metadata:
    architecture: GPT
  updated_at: 2025-12-19 00:46:07.737518+00:00
- model_id: nvidia/nemotron-nano-12b-v2-vl:free
  name: 'NVIDIA: Nemotron Nano 12B 2 VL (free)'
  provider: openrouter
  description: 'NVIDIA Nemotron Nano 2 VL is a 12-billion-parameter open multimodal
    reasoning model designed for video understanding and document intelligence. It
    introduces a hybrid Transformer-Mamba architecture, combining transformer-level
    accuracy with Mamba’s memory-efficient sequence modeling for significantly higher
    throughput and lower latency.


    The model supports inputs of text and multi-image documents, producing natural-language
    outputs. It is trained on high-quality NVIDIA-curated synthetic datasets optimized
    for optical-character recognition, chart reasoning, and multimodal comprehension.


    Nemotron Nano 2 VL achieves leading results on OCRBench v2 and scores ≈ 74 average
    across MMMU, MathVista, AI2D, OCRBench, OCR-Reasoning, ChartQA, DocVQA, and Video-MME—surpassing
    prior open VL baselines. With Efficient Video Sampling (EVS), it handles long-form
    videos while reducing inference cost.


    Open-weights, training data, and fine-tuning recipes are released under a permissive
    NVIDIA open license, with deployment supported across NeMo, NIM, and major inference
    runtimes.'
  context_length: 128000
  pricing:
    prompt: 0.0
    completion: 0.0
    image: 0.0
    request: 0.0
    currency: USD
  capabilities:
    supports_vision: true
    supports_function_calling: true
    supports_streaming: true
    modalities:
    - text
    - image->text
  metadata:
    architecture: Other
  updated_at: 2025-12-19 00:46:07.738399+00:00
- model_id: nvidia/nemotron-nano-12b-v2-vl
  name: 'NVIDIA: Nemotron Nano 12B 2 VL'
  provider: openrouter
  description: 'NVIDIA Nemotron Nano 2 VL is a 12-billion-parameter open multimodal
    reasoning model designed for video understanding and document intelligence. It
    introduces a hybrid Transformer-Mamba architecture, combining transformer-level
    accuracy with Mamba’s memory-efficient sequence modeling for significantly higher
    throughput and lower latency.


    The model supports inputs of text and multi-image documents, producing natural-language
    outputs. It is trained on high-quality NVIDIA-curated synthetic datasets optimized
    for optical-character recognition, chart reasoning, and multimodal comprehension.


    Nemotron Nano 2 VL achieves leading results on OCRBench v2 and scores ≈ 74 average
    across MMMU, MathVista, AI2D, OCRBench, OCR-Reasoning, ChartQA, DocVQA, and Video-MME—surpassing
    prior open VL baselines. With Efficient Video Sampling (EVS), it handles long-form
    videos while reducing inference cost.


    Open-weights, training data, and fine-tuning recipes are released under a permissive
    NVIDIA open license, with deployment supported across NeMo, NIM, and major inference
    runtimes.'
  context_length: 131072
  pricing:
    prompt: 2.0e-07
    completion: 6.0e-07
    image: 0.0
    request: 0.0
    currency: USD
  capabilities:
    supports_vision: true
    supports_function_calling: false
    supports_streaming: true
    modalities:
    - text
    - image->text
  metadata:
    architecture: Other
  updated_at: 2025-12-19 00:46:07.738413+00:00
- model_id: minimax/minimax-m2
  name: 'MiniMax: MiniMax M2'
  provider: openrouter
  description: 'MiniMax-M2 is a compact, high-efficiency large language model optimized
    for end-to-end coding and agentic workflows. With 10 billion activated parameters
    (230 billion total), it delivers near-frontier intelligence across general reasoning,
    tool use, and multi-step task execution while maintaining low latency and deployment
    efficiency.


    The model excels in code generation, multi-file editing, compile-run-fix loops,
    and test-validated repair, showing strong results on SWE-Bench Verified, Multi-SWE-Bench,
    and Terminal-Bench. It also performs competitively in agentic evaluations such
    as BrowseComp and GAIA, effectively handling long-horizon planning, retrieval,
    and recovery from execution errors.


    Benchmarked by [Artificial Analysis](https://artificialanalysis.ai/models/minimax-m2),
    MiniMax-M2 ranks among the top open-source models for composite intelligence,
    spanning mathematics, science, and instruction-following. Its small activation
    footprint enables fast inference, high concurrency, and improved unit economics,
    making it well-suited for large-scale agents, developer assistants, and reasoning-driven
    applications that require responsiveness and cost efficiency.


    To avoid degrading this model''s performance, MiniMax highly recommends preserving
    reasoning between turns. Learn more about using reasoning_details to pass back
    reasoning in our [docs](https://openrouter.ai/docs/use-cases/reasoning-tokens#preserving-reasoning-blocks).'
  context_length: 196608
  pricing:
    prompt: 2.0e-07
    completion: 1.0e-06
    image: 0.0
    request: 0.0
    currency: USD
  capabilities:
    supports_vision: false
    supports_function_calling: true
    supports_streaming: true
    modalities:
    - text
    - text->text
  metadata:
    architecture: Other
  updated_at: 2025-12-19 00:46:07.738427+00:00
- model_id: qwen/qwen3-vl-32b-instruct
  name: 'Qwen: Qwen3 VL 32B Instruct'
  provider: openrouter
  description: Qwen3-VL-32B-Instruct is a large-scale multimodal vision-language model
    designed for high-precision understanding and reasoning across text, images, and
    video. With 32 billion parameters, it combines deep visual perception with advanced
    text comprehension, enabling fine-grained spatial reasoning, document and scene
    analysis, and long-horizon video understanding.Robust OCR in 32 languages, and
    enhanced multimodal fusion through Interleaved-MRoPE and DeepStack architectures.
    Optimized for agentic interaction and visual tool use, Qwen3-VL-32B delivers state-of-the-art
    performance for complex real-world multimodal tasks.
  context_length: 262144
  pricing:
    prompt: 5.0e-07
    completion: 1.5e-06
    image: 0.0
    request: 0.0
    currency: USD
  capabilities:
    supports_vision: true
    supports_function_calling: false
    supports_streaming: true
    modalities:
    - text
    - image->text
  metadata:
    architecture: Qwen
  updated_at: 2025-12-19 00:46:07.738439+00:00
- model_id: liquid/lfm2-8b-a1b
  name: LiquidAI/LFM2-8B-A1B
  provider: openrouter
  description: Model created via inbox interface
  context_length: 32768
  pricing:
    prompt: 5.0e-08
    completion: 1.0e-07
    image: 0.0
    request: 0.0
    currency: USD
  capabilities:
    supports_vision: false
    supports_function_calling: false
    supports_streaming: true
    modalities:
    - text
    - text->text
  metadata:
    architecture: Other
  updated_at: 2025-12-19 00:46:07.738450+00:00
- model_id: liquid/lfm-2.2-6b
  name: LiquidAI/LFM2-2.6B
  provider: openrouter
  description: LFM2 is a new generation of hybrid models developed by Liquid AI, specifically
    designed for edge AI and on-device deployment. It sets a new standard in terms
    of quality, speed, and memory efficiency.
  context_length: 32768
  pricing:
    prompt: 5.0e-08
    completion: 1.0e-07
    image: 0.0
    request: 0.0
    currency: USD
  capabilities:
    supports_vision: false
    supports_function_calling: false
    supports_streaming: true
    modalities:
    - text
    - text->text
  metadata:
    architecture: Other
  updated_at: 2025-12-19 00:46:07.738459+00:00
- model_id: ibm-granite/granite-4.0-h-micro
  name: 'IBM: Granite 4.0 Micro'
  provider: openrouter
  description: 'Granite-4.0-H-Micro is a 3B parameter from the Granite 4 family of
    models. These models are the latest in a series of models released by IBM. They
    are fine-tuned for long context tool calling. '
  context_length: 131000
  pricing:
    prompt: 1.7e-08
    completion: 1.1e-07
    image: 0.0
    request: 0.0
    currency: USD
  capabilities:
    supports_vision: false
    supports_function_calling: false
    supports_streaming: true
    modalities:
    - text
    - text->text
  metadata:
    architecture: Other
  updated_at: 2025-12-19 00:46:07.738471+00:00
- model_id: deepcogito/cogito-v2-preview-llama-405b
  name: 'Deep Cogito: Cogito V2 Preview Llama 405B'
  provider: openrouter
  description: 'Cogito v2 405B is a dense hybrid reasoning model that combines direct
    answering capabilities with advanced self-reflection. It represents a significant
    step toward frontier intelligence with dense architecture delivering performance
    competitive with leading closed models. This advanced reasoning system combines
    policy improvement with massive scale for exceptional capabilities.

    '
  context_length: 32768
  pricing:
    prompt: 3.5e-06
    completion: 3.5e-06
    image: 0.0
    request: 0.0
    currency: USD
  capabilities:
    supports_vision: false
    supports_function_calling: true
    supports_streaming: true
    modalities:
    - text
    - text->text
  metadata:
    architecture: Llama3
  updated_at: 2025-12-19 00:46:07.738482+00:00
- model_id: openai/gpt-5-image-mini
  name: 'OpenAI: GPT-5 Image Mini'
  provider: openrouter
  description: GPT-5 Image Mini combines OpenAI's advanced language capabilities,
    powered by [GPT-5 Mini](https://openrouter.ai/openai/gpt-5-mini), with GPT Image
    1 Mini for efficient image generation. This natively multimodal model features
    superior instruction following, text rendering, and detailed image editing with
    reduced latency and cost. It excels at high-quality visual creation while maintaining
    strong text understanding, making it ideal for applications that require both
    efficient image generation and text processing at scale.
  context_length: 400000
  pricing:
    prompt: 2.5e-06
    completion: 2.0e-06
    image: 2.5e-06
    request: 0.0
    currency: USD
  capabilities:
    supports_vision: true
    supports_function_calling: true
    supports_streaming: true
    modalities:
    - text
    - image->text
    - image
  metadata:
    architecture: GPT
  updated_at: 2025-12-19 00:46:07.738491+00:00
- model_id: anthropic/claude-haiku-4.5
  name: 'Anthropic: Claude Haiku 4.5'
  provider: openrouter
  description: 'Claude Haiku 4.5 is Anthropic’s fastest and most efficient model,
    delivering near-frontier intelligence at a fraction of the cost and latency of
    larger Claude models. Matching Claude Sonnet 4’s performance across reasoning,
    coding, and computer-use tasks, Haiku 4.5 brings frontier-level capability to
    real-time and high-volume applications.


    It introduces extended thinking to the Haiku line; enabling controllable reasoning
    depth, summarized or interleaved thought output, and tool-assisted workflows with
    full support for coding, bash, web search, and computer-use tools. Scoring >73%
    on SWE-bench Verified, Haiku 4.5 ranks among the world’s best coding models while
    maintaining exceptional responsiveness for sub-agents, parallelized execution,
    and scaled deployment.'
  context_length: 200000
  pricing:
    prompt: 1.0e-06
    completion: 5.0e-06
    image: 0.0
    request: 0.0
    currency: USD
  capabilities:
    supports_vision: true
    supports_function_calling: true
    supports_streaming: true
    modalities:
    - text
    - image->text
  metadata:
    architecture: Claude
  updated_at: 2025-12-19 00:46:07.738500+00:00
- model_id: qwen/qwen3-vl-8b-thinking
  name: 'Qwen: Qwen3 VL 8B Thinking'
  provider: openrouter
  description: 'Qwen3-VL-8B-Thinking is the reasoning-optimized variant of the Qwen3-VL-8B
    multimodal model, designed for advanced visual and textual reasoning across complex
    scenes, documents, and temporal sequences. It integrates enhanced multimodal alignment
    and long-context processing (native 256K, expandable to 1M tokens) for tasks such
    as scientific visual analysis, causal inference, and mathematical reasoning over
    image or video inputs.


    Compared to the Instruct edition, the Thinking version introduces deeper visual-language
    fusion and deliberate reasoning pathways that improve performance on long-chain
    logic tasks, STEM problem-solving, and multi-step video understanding. It achieves
    stronger temporal grounding via Interleaved-MRoPE and timestamp-aware embeddings,
    while maintaining robust OCR, multilingual comprehension, and text generation
    on par with large text-only LLMs.'
  context_length: 256000
  pricing:
    prompt: 1.8e-07
    completion: 2.1e-06
    image: 0.0
    request: 0.0
    currency: USD
  capabilities:
    supports_vision: true
    supports_function_calling: true
    supports_streaming: true
    modalities:
    - text
    - image->text
  metadata:
    architecture: Qwen3
  updated_at: 2025-12-19 00:46:07.738511+00:00
- model_id: qwen/qwen3-vl-8b-instruct
  name: 'Qwen: Qwen3 VL 8B Instruct'
  provider: openrouter
  description: 'Qwen3-VL-8B-Instruct is a multimodal vision-language model from the
    Qwen3-VL series, built for high-fidelity understanding and reasoning across text,
    images, and video. It features improved multimodal fusion with Interleaved-MRoPE
    for long-horizon temporal reasoning, DeepStack for fine-grained visual-text alignment,
    and text-timestamp alignment for precise event localization.


    The model supports a native 256K-token context window, extensible to 1M tokens,
    and handles both static and dynamic media inputs for tasks like document parsing,
    visual question answering, spatial reasoning, and GUI control. It achieves text
    understanding comparable to leading LLMs while expanding OCR coverage to 32 languages
    and enhancing robustness under varied visual conditions.'
  context_length: 131072
  pricing:
    prompt: 6.4e-08
    completion: 4.0e-07
    image: 0.0
    request: 0.0
    currency: USD
  capabilities:
    supports_vision: true
    supports_function_calling: true
    supports_streaming: true
    modalities:
    - text
    - image->text
  metadata:
    architecture: Qwen3
  updated_at: 2025-12-19 00:46:07.738519+00:00
- model_id: openai/gpt-5-image
  name: 'OpenAI: GPT-5 Image'
  provider: openrouter
  description: '[GPT-5](https://openrouter.ai/openai/gpt-5) Image combines OpenAI''s
    GPT-5 model with state-of-the-art image generation capabilities. It offers major
    improvements in reasoning, code quality, and user experience while incorporating
    GPT Image 1''s superior instruction following, text rendering, and detailed image
    editing.'
  context_length: 400000
  pricing:
    prompt: 1.0e-05
    completion: 1.0e-05
    image: 1.0e-05
    request: 0.0
    currency: USD
  capabilities:
    supports_vision: true
    supports_function_calling: true
    supports_streaming: true
    modalities:
    - text
    - image->text
    - image
  metadata:
    architecture: GPT
  updated_at: 2025-12-19 00:46:07.738532+00:00
- model_id: openai/o3-deep-research
  name: 'OpenAI: o3 Deep Research'
  provider: openrouter
  description: 'o3-deep-research is OpenAI''s advanced model for deep research, designed
    to tackle complex, multi-step research tasks.


    Note: This model always uses the ''web_search'' tool which adds additional cost.'
  context_length: 200000
  pricing:
    prompt: 1.0e-05
    completion: 4.0e-05
    image: 0.00765
    request: 0.0
    currency: USD
  capabilities:
    supports_vision: true
    supports_function_calling: true
    supports_streaming: true
    modalities:
    - text
    - image->text
  metadata:
    architecture: GPT
  updated_at: 2025-12-19 00:46:07.738541+00:00
- model_id: openai/o4-mini-deep-research
  name: 'OpenAI: o4 Mini Deep Research'
  provider: openrouter
  description: 'o4-mini-deep-research is OpenAI''s faster, more affordable deep research
    model—ideal for tackling complex, multi-step research tasks.


    Note: This model always uses the ''web_search'' tool which adds additional cost.'
  context_length: 200000
  pricing:
    prompt: 2.0e-06
    completion: 8.0e-06
    image: 0.00153
    request: 0.0
    currency: USD
  capabilities:
    supports_vision: true
    supports_function_calling: true
    supports_streaming: true
    modalities:
    - text
    - image->text
  metadata:
    architecture: GPT
  updated_at: 2025-12-19 00:46:07.738551+00:00
- model_id: nvidia/llama-3.3-nemotron-super-49b-v1.5
  name: 'NVIDIA: Llama 3.3 Nemotron Super 49B V1.5'
  provider: openrouter
  description: 'Llama-3.3-Nemotron-Super-49B-v1.5 is a 49B-parameter, English-centric
    reasoning/chat model derived from Meta’s Llama-3.3-70B-Instruct with a 128K context.
    It’s post-trained for agentic workflows (RAG, tool calling) via SFT across math,
    code, science, and multi-turn chat, followed by multiple RL stages; Reward-aware
    Preference Optimization (RPO) for alignment, RL with Verifiable Rewards (RLVR)
    for step-wise reasoning, and iterative DPO to refine tool-use behavior. A distillation-driven
    Neural Architecture Search (“Puzzle”) replaces some attention blocks and varies
    FFN widths to shrink memory footprint and improve throughput, enabling single-GPU
    (H100/H200) deployment while preserving instruction following and CoT quality.


    In internal evaluations (NeMo-Skills, up to 16 runs, temp = 0.6, top_p = 0.95),
    the model reports strong reasoning/coding results, e.g., MATH500 pass@1 = 97.4,
    AIME-2024 = 87.5, AIME-2025 = 82.71, GPQA = 71.97, LiveCodeBench (24.10–25.02)
    = 73.58, and MMLU-Pro (CoT) = 79.53. The model targets practical inference efficiency
    (high tokens/s, reduced VRAM) with Transformers/vLLM support and explicit “reasoning
    on/off” modes (chat-first defaults, greedy recommended when disabled). Suitable
    for building agents, assistants, and long-context retrieval systems where balanced
    accuracy-to-cost and reliable tool use matter.

    '
  context_length: 131072
  pricing:
    prompt: 1.0e-07
    completion: 4.0e-07
    image: 0.0
    request: 0.0
    currency: USD
  capabilities:
    supports_vision: false
    supports_function_calling: true
    supports_streaming: true
    modalities:
    - text
    - text->text
  metadata:
    architecture: Llama3
  updated_at: 2025-12-19 00:46:07.738564+00:00
- model_id: baidu/ernie-4.5-21b-a3b-thinking
  name: 'Baidu: ERNIE 4.5 21B A3B Thinking'
  provider: openrouter
  description: ERNIE-4.5-21B-A3B-Thinking is Baidu's upgraded lightweight MoE model,
    refined to boost reasoning depth and quality for top-tier performance in logical
    puzzles, math, science, coding, text generation, and expert-level academic benchmarks.
  context_length: 131072
  pricing:
    prompt: 5.6e-08
    completion: 2.24e-07
    image: 0.0
    request: 0.0
    currency: USD
  capabilities:
    supports_vision: false
    supports_function_calling: false
    supports_streaming: true
    modalities:
    - text
    - text->text
  metadata:
    architecture: Other
  updated_at: 2025-12-19 00:46:07.738573+00:00
- model_id: google/gemini-2.5-flash-image
  name: 'Google: Gemini 2.5 Flash Image (Nano Banana)'
  provider: openrouter
  description: Gemini 2.5 Flash Image, a.k.a. "Nano Banana," is now generally available.
    It is a state of the art image generation model with contextual understanding.
    It is capable of image generation, edits, and multi-turn conversations. Aspect
    ratios can be controlled with the [image_config API Parameter](https://openrouter.ai/docs/features/multimodal/image-generation#image-aspect-ratio-configuration)
  context_length: 32768
  pricing:
    prompt: 3.0e-07
    completion: 2.5e-06
    image: 0.001238
    request: 0.0
    currency: USD
  capabilities:
    supports_vision: true
    supports_function_calling: false
    supports_streaming: true
    modalities:
    - text
    - image->text
    - image
  metadata:
    architecture: Gemini
  updated_at: 2025-12-19 00:46:07.738583+00:00
- model_id: qwen/qwen3-vl-30b-a3b-thinking
  name: 'Qwen: Qwen3 VL 30B A3B Thinking'
  provider: openrouter
  description: Qwen3-VL-30B-A3B-Thinking is a multimodal model that unifies strong
    text generation with visual understanding for images and videos. Its Thinking
    variant enhances reasoning in STEM, math, and complex tasks. It excels in perception
    of real-world/synthetic categories, 2D/3D spatial grounding, and long-form visual
    comprehension, achieving competitive multimodal benchmark results. For agentic
    use, it handles multi-image multi-turn instructions, video timeline alignments,
    GUI automation, and visual coding from sketches to debugged UI. Text performance
    matches flagship Qwen3 models, suiting document AI, OCR, UI assistance, spatial
    tasks, and agent research.
  context_length: 131072
  pricing:
    prompt: 1.6e-07
    completion: 8.0e-07
    image: 0.0
    request: 0.0
    currency: USD
  capabilities:
    supports_vision: true
    supports_function_calling: true
    supports_streaming: true
    modalities:
    - text
    - image->text
  metadata:
    architecture: Qwen3
  updated_at: 2025-12-19 00:46:07.738596+00:00
- model_id: qwen/qwen3-vl-30b-a3b-instruct
  name: 'Qwen: Qwen3 VL 30B A3B Instruct'
  provider: openrouter
  description: Qwen3-VL-30B-A3B-Instruct is a multimodal model that unifies strong
    text generation with visual understanding for images and videos. Its Instruct
    variant optimizes instruction-following for general multimodal tasks. It excels
    in perception of real-world/synthetic categories, 2D/3D spatial grounding, and
    long-form visual comprehension, achieving competitive multimodal benchmark results.
    For agentic use, it handles multi-image multi-turn instructions, video timeline
    alignments, GUI automation, and visual coding from sketches to debugged UI. Text
    performance matches flagship Qwen3 models, suiting document AI, OCR, UI assistance,
    spatial tasks, and agent research.
  context_length: 262144
  pricing:
    prompt: 1.5e-07
    completion: 6.0e-07
    image: 0.0
    request: 0.0
    currency: USD
  capabilities:
    supports_vision: true
    supports_function_calling: true
    supports_streaming: true
    modalities:
    - text
    - image->text
  metadata:
    architecture: Qwen3
  updated_at: 2025-12-19 00:46:07.738604+00:00
- model_id: openai/gpt-5-pro
  name: 'OpenAI: GPT-5 Pro'
  provider: openrouter
  description: GPT-5 Pro is OpenAI’s most advanced model, offering major improvements
    in reasoning, code quality, and user experience. It is optimized for complex tasks
    that require step-by-step reasoning, instruction following, and accuracy in high-stakes
    use cases. It supports test-time routing features and advanced prompt understanding,
    including user-specified intent like "think hard about this." Improvements include
    reductions in hallucination, sycophancy, and better performance in coding, writing,
    and health-related tasks.
  context_length: 400000
  pricing:
    prompt: 1.5e-05
    completion: 0.00012
    image: 0.0
    request: 0.0
    currency: USD
  capabilities:
    supports_vision: true
    supports_function_calling: true
    supports_streaming: true
    modalities:
    - text
    - image->text
  metadata:
    architecture: GPT
  updated_at: 2025-12-19 00:46:07.738615+00:00
- model_id: z-ai/glm-4.6
  name: 'Z.AI: GLM 4.6'
  provider: openrouter
  description: 'Compared with GLM-4.5, this generation brings several key improvements:


    Longer context window: The context window has been expanded from 128K to 200K
    tokens, enabling the model to handle more complex agentic tasks.

    Superior coding performance: The model achieves higher scores on code benchmarks
    and demonstrates better real-world performance in applications such as Claude
    Code、Cline、Roo Code and Kilo Code, including improvements in generating visually
    polished front-end pages.

    Advanced reasoning: GLM-4.6 shows a clear improvement in reasoning performance
    and supports tool use during inference, leading to stronger overall capability.

    More capable agents: GLM-4.6 exhibits stronger performance in tool using and search-based
    agents, and integrates more effectively within agent frameworks.

    Refined writing: Better aligns with human preferences in style and readability,
    and performs more naturally in role-playing scenarios.'
  context_length: 204800
  pricing:
    prompt: 3.9e-07
    completion: 1.9e-06
    image: 0.0
    request: 0.0
    currency: USD
  capabilities:
    supports_vision: false
    supports_function_calling: true
    supports_streaming: true
    modalities:
    - text
    - text->text
  metadata:
    architecture: Other
  updated_at: 2025-12-19 00:46:07.738625+00:00
- model_id: z-ai/glm-4.6:exacto
  name: 'Z.AI: GLM 4.6 (exacto)'
  provider: openrouter
  description: 'Compared with GLM-4.5, this generation brings several key improvements:


    Longer context window: The context window has been expanded from 128K to 200K
    tokens, enabling the model to handle more complex agentic tasks.

    Superior coding performance: The model achieves higher scores on code benchmarks
    and demonstrates better real-world performance in applications such as Claude
    Code、Cline、Roo Code and Kilo Code, including improvements in generating visually
    polished front-end pages.

    Advanced reasoning: GLM-4.6 shows a clear improvement in reasoning performance
    and supports tool use during inference, leading to stronger overall capability.

    More capable agents: GLM-4.6 exhibits stronger performance in tool using and search-based
    agents, and integrates more effectively within agent frameworks.

    Refined writing: Better aligns with human preferences in style and readability,
    and performs more naturally in role-playing scenarios.'
  context_length: 204800
  pricing:
    prompt: 4.4e-07
    completion: 1.76e-06
    image: 0.0
    request: 0.0
    currency: USD
  capabilities:
    supports_vision: false
    supports_function_calling: true
    supports_streaming: true
    modalities:
    - text
    - text->text
  metadata:
    architecture: Other
  updated_at: 2025-12-19 00:46:07.738635+00:00
- model_id: anthropic/claude-sonnet-4.5
  name: 'Anthropic: Claude Sonnet 4.5'
  provider: openrouter
  description: 'Claude Sonnet 4.5 is Anthropic’s most advanced Sonnet model to date,
    optimized for real-world agents and coding workflows. It delivers state-of-the-art
    performance on coding benchmarks such as SWE-bench Verified, with improvements
    across system design, code security, and specification adherence. The model is
    designed for extended autonomous operation, maintaining task continuity across
    sessions and providing fact-based progress tracking.


    Sonnet 4.5 also introduces stronger agentic capabilities, including improved tool
    orchestration, speculative parallel execution, and more efficient context and
    memory management. With enhanced context tracking and awareness of token usage
    across tool calls, it is particularly well-suited for multi-context and long-running
    workflows. Use cases span software engineering, cybersecurity, financial analysis,
    research agents, and other domains requiring sustained reasoning and tool use.'
  context_length: 1000000
  pricing:
    prompt: 3.0e-06
    completion: 1.5e-05
    image: 0.0
    request: 0.0
    currency: USD
  capabilities:
    supports_vision: true
    supports_function_calling: true
    supports_streaming: true
    modalities:
    - text
    - image->text
  metadata:
    architecture: Claude
  updated_at: 2025-12-19 00:46:07.738643+00:00
- model_id: deepseek/deepseek-v3.2-exp
  name: 'DeepSeek: DeepSeek V3.2 Exp'
  provider: openrouter
  description: 'DeepSeek-V3.2-Exp is an experimental large language model released
    by DeepSeek as an intermediate step between V3.1 and future architectures. It
    introduces DeepSeek Sparse Attention (DSA), a fine-grained sparse attention mechanism
    designed to improve training and inference efficiency in long-context scenarios
    while maintaining output quality. Users can control the reasoning behaviour with
    the `reasoning` `enabled` boolean. [Learn more in our docs](https://openrouter.ai/docs/use-cases/reasoning-tokens#enable-reasoning-with-default-config)


    The model was trained under conditions aligned with V3.1-Terminus to enable direct
    comparison. Benchmarking shows performance roughly on par with V3.1 across reasoning,
    coding, and agentic tool-use tasks, with minor tradeoffs and gains depending on
    the domain. This release focuses on validating architectural optimizations for
    extended context lengths rather than advancing raw task accuracy, making it primarily
    a research-oriented model for exploring efficient transformer designs.'
  context_length: 163840
  pricing:
    prompt: 2.1e-07
    completion: 3.2e-07
    image: 0.0
    request: 0.0
    currency: USD
  capabilities:
    supports_vision: false
    supports_function_calling: true
    supports_streaming: true
    modalities:
    - text
    - text->text
  metadata:
    architecture: DeepSeek
  updated_at: 2025-12-19 00:46:07.738656+00:00
- model_id: thedrummer/cydonia-24b-v4.1
  name: 'TheDrummer: Cydonia 24B V4.1'
  provider: openrouter
  description: Uncensored and creative writing model based on Mistral Small 3.2 24B
    with good recall, prompt adherence, and intelligence.
  context_length: 131072
  pricing:
    prompt: 3.0e-07
    completion: 5.0e-07
    image: 0.0
    request: 0.0
    currency: USD
  capabilities:
    supports_vision: false
    supports_function_calling: false
    supports_streaming: true
    modalities:
    - text
    - text->text
  metadata:
    architecture: Other
  updated_at: 2025-12-19 00:46:07.738666+00:00
- model_id: relace/relace-apply-3
  name: 'Relace: Relace Apply 3'
  provider: openrouter
  description: "Relace Apply 3 is a specialized code-patching LLM that merges AI-suggested\
    \ edits straight into your source files. It can apply updates from GPT-4o, Claude,\
    \ and others into your files at 10,000 tokens/sec on average.\n\nThe model requires\
    \ the prompt to be in the following format: \n<instruction>{instruction}</instruction>\n\
    <code>{initial_code}</code>\n<update>{edit_snippet}</update>\n\nZero Data Retention\
    \ is enabled for Relace. Learn more about this model in their [documentation](https://docs.relace.ai/api-reference/instant-apply/apply)"
  context_length: 256000
  pricing:
    prompt: 8.5e-07
    completion: 1.25e-06
    image: 0.0
    request: 0.0
    currency: USD
  capabilities:
    supports_vision: false
    supports_function_calling: false
    supports_streaming: true
    modalities:
    - text
    - text->text
  metadata:
    architecture: Other
  updated_at: 2025-12-19 00:46:07.738676+00:00
- model_id: google/gemini-2.5-flash-preview-09-2025
  name: 'Google: Gemini 2.5 Flash Preview 09-2025'
  provider: openrouter
  description: "Gemini 2.5 Flash Preview September 2025 Checkpoint is Google's state-of-the-art\
    \ workhorse model, specifically designed for advanced reasoning, coding, mathematics,\
    \ and scientific tasks. It includes built-in \"thinking\" capabilities, enabling\
    \ it to provide responses with greater accuracy and nuanced context handling.\
    \ \n\nAdditionally, Gemini 2.5 Flash is configurable through the \"max tokens\
    \ for reasoning\" parameter, as described in the documentation (https://openrouter.ai/docs/use-cases/reasoning-tokens#max-tokens-for-reasoning)."
  context_length: 1048576
  pricing:
    prompt: 3.0e-07
    completion: 2.5e-06
    image: 0.001238
    request: 0.0
    currency: USD
  capabilities:
    supports_vision: true
    supports_function_calling: true
    supports_streaming: true
    modalities:
    - text
    - image->text
  metadata:
    architecture: Gemini
  updated_at: 2025-12-19 00:46:07.738685+00:00
- model_id: google/gemini-2.5-flash-lite-preview-09-2025
  name: 'Google: Gemini 2.5 Flash Lite Preview 09-2025'
  provider: openrouter
  description: 'Gemini 2.5 Flash-Lite is a lightweight reasoning model in the Gemini
    2.5 family, optimized for ultra-low latency and cost efficiency. It offers improved
    throughput, faster token generation, and better performance across common benchmarks
    compared to earlier Flash models. By default, "thinking" (i.e. multi-pass reasoning)
    is disabled to prioritize speed, but developers can enable it via the [Reasoning
    API parameter](https://openrouter.ai/docs/use-cases/reasoning-tokens) to selectively
    trade off cost for intelligence. '
  context_length: 1048576
  pricing:
    prompt: 1.0e-07
    completion: 4.0e-07
    image: 0.0
    request: 0.0
    currency: USD
  capabilities:
    supports_vision: true
    supports_function_calling: true
    supports_streaming: true
    modalities:
    - text
    - image->text
  metadata:
    architecture: Gemini
  updated_at: 2025-12-19 00:46:07.738693+00:00
- model_id: qwen/qwen3-vl-235b-a22b-thinking
  name: 'Qwen: Qwen3 VL 235B A22B Thinking'
  provider: openrouter
  description: 'Qwen3-VL-235B-A22B Thinking is a multimodal model that unifies strong
    text generation with visual understanding across images and video. The Thinking
    model is optimized for multimodal reasoning in STEM and math. The series emphasizes
    robust perception (recognition of diverse real-world and synthetic categories),
    spatial understanding (2D/3D grounding), and long-form visual comprehension, with
    competitive results on public multimodal benchmarks for both perception and reasoning.


    Beyond analysis, Qwen3-VL supports agentic interaction and tool use: it can follow
    complex instructions over multi-image, multi-turn dialogues; align text to video
    timelines for precise temporal queries; and operate GUI elements for automation
    tasks. The models also enable visual coding workflows, turning sketches or mockups
    into code and assisting with UI debugging, while maintaining strong text-only
    performance comparable to the flagship Qwen3 language models. This makes Qwen3-VL
    suitable for production scenarios spanning document AI, multilingual OCR, software/UI
    assistance, spatial/embodied tasks, and research on vision-language agents.'
  context_length: 262144
  pricing:
    prompt: 3.0e-07
    completion: 1.2e-06
    image: 0.0
    request: 0.0
    currency: USD
  capabilities:
    supports_vision: true
    supports_function_calling: true
    supports_streaming: true
    modalities:
    - text
    - image->text
  metadata:
    architecture: Qwen3
  updated_at: 2025-12-19 00:46:07.738701+00:00
- model_id: qwen/qwen3-vl-235b-a22b-instruct
  name: 'Qwen: Qwen3 VL 235B A22B Instruct'
  provider: openrouter
  description: 'Qwen3-VL-235B-A22B Instruct is an open-weight multimodal model that
    unifies strong text generation with visual understanding across images and video.
    The Instruct model targets general vision-language use (VQA, document parsing,
    chart/table extraction, multilingual OCR). The series emphasizes robust perception
    (recognition of diverse real-world and synthetic categories), spatial understanding
    (2D/3D grounding), and long-form visual comprehension, with competitive results
    on public multimodal benchmarks for both perception and reasoning.


    Beyond analysis, Qwen3-VL supports agentic interaction and tool use: it can follow
    complex instructions over multi-image, multi-turn dialogues; align text to video
    timelines for precise temporal queries; and operate GUI elements for automation
    tasks. The models also enable visual coding workflows—turning sketches or mockups
    into code and assisting with UI debugging—while maintaining strong text-only performance
    comparable to the flagship Qwen3 language models. This makes Qwen3-VL suitable
    for production scenarios spanning document AI, multilingual OCR, software/UI assistance,
    spatial/embodied tasks, and research on vision-language agents.'
  context_length: 262144
  pricing:
    prompt: 2.0e-07
    completion: 1.2e-06
    image: 0.0
    request: 0.0
    currency: USD
  capabilities:
    supports_vision: true
    supports_function_calling: true
    supports_streaming: true
    modalities:
    - text
    - image->text
  metadata:
    architecture: Qwen3
  updated_at: 2025-12-19 00:46:07.738714+00:00
- model_id: qwen/qwen3-max
  name: 'Qwen: Qwen3 Max'
  provider: openrouter
  description: Qwen3-Max is an updated release built on the Qwen3 series, offering
    major improvements in reasoning, instruction following, multilingual support,
    and long-tail knowledge coverage compared to the January 2025 version. It delivers
    higher accuracy in math, coding, logic, and science tasks, follows complex instructions
    in Chinese and English more reliably, reduces hallucinations, and produces higher-quality
    responses for open-ended Q&A, writing, and conversation. The model supports over
    100 languages with stronger translation and commonsense reasoning, and is optimized
    for retrieval-augmented generation (RAG) and tool calling, though it does not
    include a dedicated “thinking” mode.
  context_length: 256000
  pricing:
    prompt: 1.2e-06
    completion: 6.0e-06
    image: 0.0
    request: 0.0
    currency: USD
  capabilities:
    supports_vision: false
    supports_function_calling: true
    supports_streaming: true
    modalities:
    - text
    - text->text
  metadata:
    architecture: Qwen3
  updated_at: 2025-12-19 00:46:07.738725+00:00
- model_id: qwen/qwen3-coder-plus
  name: 'Qwen: Qwen3 Coder Plus'
  provider: openrouter
  description: Qwen3 Coder Plus is Alibaba's proprietary version of the Open Source
    Qwen3 Coder 480B A35B. It is a powerful coding agent model specializing in autonomous
    programming via tool calling and environment interaction, combining coding proficiency
    with versatile general-purpose abilities.
  context_length: 128000
  pricing:
    prompt: 1.0e-06
    completion: 5.0e-06
    image: 0.0
    request: 0.0
    currency: USD
  capabilities:
    supports_vision: false
    supports_function_calling: true
    supports_streaming: true
    modalities:
    - text
    - text->text
  metadata:
    architecture: Qwen3
  updated_at: 2025-12-19 00:46:07.738733+00:00
- model_id: openai/gpt-5-codex
  name: 'OpenAI: GPT-5 Codex'
  provider: openrouter
  description: 'GPT-5-Codex is a specialized version of GPT-5 optimized for software
    engineering and coding workflows. It is designed for both interactive development
    sessions and long, independent execution of complex engineering tasks. The model
    supports building projects from scratch, feature development, debugging, large-scale
    refactoring, and code review. Compared to GPT-5, Codex is more steerable, adheres
    closely to developer instructions, and produces cleaner, higher-quality code outputs.
    Reasoning effort can be adjusted with the `reasoning.effort` parameter. Read the
    [docs here](https://openrouter.ai/docs/use-cases/reasoning-tokens#reasoning-effort-level)


    Codex integrates into developer environments including the CLI, IDE extensions,
    GitHub, and cloud tasks. It adapts reasoning effort dynamically—providing fast
    responses for small tasks while sustaining extended multi-hour runs for large
    projects. The model is trained to perform structured code reviews, catching critical
    flaws by reasoning over dependencies and validating behavior against tests. It
    also supports multimodal inputs such as images or screenshots for UI development
    and integrates tool use for search, dependency installation, and environment setup.
    Codex is intended specifically for agentic coding applications.'
  context_length: 400000
  pricing:
    prompt: 1.25e-06
    completion: 1.0e-05
    image: 0.0
    request: 0.0
    currency: USD
  capabilities:
    supports_vision: true
    supports_function_calling: true
    supports_streaming: true
    modalities:
    - text
    - image->text
  metadata:
    architecture: GPT
  updated_at: 2025-12-19 00:46:07.738741+00:00
- model_id: deepseek/deepseek-v3.1-terminus:exacto
  name: 'DeepSeek: DeepSeek V3.1 Terminus (exacto)'
  provider: openrouter
  description: 'DeepSeek-V3.1 Terminus is an update to [DeepSeek V3.1](/deepseek/deepseek-chat-v3.1)
    that maintains the model''s original capabilities while addressing issues reported
    by users, including language consistency and agent capabilities, further optimizing
    the model''s performance in coding and search agents. It is a large hybrid reasoning
    model (671B parameters, 37B active) that supports both thinking and non-thinking
    modes. It extends the DeepSeek-V3 base with a two-phase long-context training
    process, reaching up to 128K tokens, and uses FP8 microscaling for efficient inference.
    Users can control the reasoning behaviour with the `reasoning` `enabled` boolean.
    [Learn more in our docs](https://openrouter.ai/docs/use-cases/reasoning-tokens#enable-reasoning-with-default-config)


    The model improves tool use, code generation, and reasoning efficiency, achieving
    performance comparable to DeepSeek-R1 on difficult benchmarks while responding
    more quickly. It supports structured tool calling, code agents, and search agents,
    making it suitable for research, coding, and agentic workflows. '
  context_length: 163840
  pricing:
    prompt: 2.1e-07
    completion: 7.9e-07
    image: 0.0
    request: 0.0
    currency: USD
  capabilities:
    supports_vision: false
    supports_function_calling: true
    supports_streaming: true
    modalities:
    - text
    - text->text
  metadata:
    architecture: DeepSeek
  updated_at: 2025-12-19 00:46:07.738774+00:00
- model_id: deepseek/deepseek-v3.1-terminus
  name: 'DeepSeek: DeepSeek V3.1 Terminus'
  provider: openrouter
  description: 'DeepSeek-V3.1 Terminus is an update to [DeepSeek V3.1](/deepseek/deepseek-chat-v3.1)
    that maintains the model''s original capabilities while addressing issues reported
    by users, including language consistency and agent capabilities, further optimizing
    the model''s performance in coding and search agents. It is a large hybrid reasoning
    model (671B parameters, 37B active) that supports both thinking and non-thinking
    modes. It extends the DeepSeek-V3 base with a two-phase long-context training
    process, reaching up to 128K tokens, and uses FP8 microscaling for efficient inference.
    Users can control the reasoning behaviour with the `reasoning` `enabled` boolean.
    [Learn more in our docs](https://openrouter.ai/docs/use-cases/reasoning-tokens#enable-reasoning-with-default-config)


    The model improves tool use, code generation, and reasoning efficiency, achieving
    performance comparable to DeepSeek-R1 on difficult benchmarks while responding
    more quickly. It supports structured tool calling, code agents, and search agents,
    making it suitable for research, coding, and agentic workflows. '
  context_length: 163840
  pricing:
    prompt: 2.1e-07
    completion: 7.9e-07
    image: 0.0
    request: 0.0
    currency: USD
  capabilities:
    supports_vision: false
    supports_function_calling: true
    supports_streaming: true
    modalities:
    - text
    - text->text
  metadata:
    architecture: DeepSeek
  updated_at: 2025-12-19 00:46:07.738787+00:00
- model_id: x-ai/grok-4-fast
  name: 'xAI: Grok 4 Fast'
  provider: openrouter
  description: 'Grok 4 Fast is xAI''s latest multimodal model with SOTA cost-efficiency
    and a 2M token context window. It comes in two flavors: non-reasoning and reasoning.
    Read more about the model on xAI''s [news post](http://x.ai/news/grok-4-fast).


    Reasoning can be enabled/disabled using the `reasoning` `enabled` parameter in
    the API. [Learn more in our docs](https://openrouter.ai/docs/use-cases/reasoning-tokens#controlling-reasoning-tokens)'
  context_length: 2000000
  pricing:
    prompt: 2.0e-07
    completion: 5.0e-07
    image: 0.0
    request: 0.0
    currency: USD
  capabilities:
    supports_vision: true
    supports_function_calling: true
    supports_streaming: true
    modalities:
    - text
    - image->text
  metadata:
    architecture: Grok
  updated_at: 2025-12-19 00:46:07.738801+00:00
- model_id: alibaba/tongyi-deepresearch-30b-a3b:free
  name: Tongyi DeepResearch 30B A3B (free)
  provider: openrouter
  description: 'Tongyi DeepResearch is an agentic large language model developed by
    Tongyi Lab, with 30 billion total parameters activating only 3 billion per token.
    It''s optimized for long-horizon, deep information-seeking tasks and delivers
    state-of-the-art performance on benchmarks like Humanity''s Last Exam, BrowserComp,
    BrowserComp-ZH, WebWalkerQA, GAIA, xbench-DeepSearch, and FRAMES. This makes it
    superior for complex agentic search, reasoning, and multi-step problem-solving
    compared to prior models.


    The model includes a fully automated synthetic data pipeline for scalable pre-training,
    fine-tuning, and reinforcement learning. It uses large-scale continual pre-training
    on diverse agentic data to boost reasoning and stay fresh. It also features end-to-end
    on-policy RL with a customized Group Relative Policy Optimization, including token-level
    gradients and negative sample filtering for stable training. The model supports
    ReAct for core ability checks and an IterResearch-based ''Heavy'' mode for max
    performance through test-time scaling. It''s ideal for advanced research agents,
    tool use, and heavy inference workflows.'
  context_length: 131072
  pricing:
    prompt: 0.0
    completion: 0.0
    image: 0.0
    request: 0.0
    currency: USD
  capabilities:
    supports_vision: false
    supports_function_calling: true
    supports_streaming: true
    modalities:
    - text
    - text->text
  metadata:
    architecture: Other
  updated_at: 2025-12-19 00:46:07.738810+00:00
- model_id: alibaba/tongyi-deepresearch-30b-a3b
  name: Tongyi DeepResearch 30B A3B
  provider: openrouter
  description: 'Tongyi DeepResearch is an agentic large language model developed by
    Tongyi Lab, with 30 billion total parameters activating only 3 billion per token.
    It''s optimized for long-horizon, deep information-seeking tasks and delivers
    state-of-the-art performance on benchmarks like Humanity''s Last Exam, BrowserComp,
    BrowserComp-ZH, WebWalkerQA, GAIA, xbench-DeepSearch, and FRAMES. This makes it
    superior for complex agentic search, reasoning, and multi-step problem-solving
    compared to prior models.


    The model includes a fully automated synthetic data pipeline for scalable pre-training,
    fine-tuning, and reinforcement learning. It uses large-scale continual pre-training
    on diverse agentic data to boost reasoning and stay fresh. It also features end-to-end
    on-policy RL with a customized Group Relative Policy Optimization, including token-level
    gradients and negative sample filtering for stable training. The model supports
    ReAct for core ability checks and an IterResearch-based ''Heavy'' mode for max
    performance through test-time scaling. It''s ideal for advanced research agents,
    tool use, and heavy inference workflows.'
  context_length: 131072
  pricing:
    prompt: 9.0e-08
    completion: 4.0e-07
    image: 0.0
    request: 0.0
    currency: USD
  capabilities:
    supports_vision: false
    supports_function_calling: true
    supports_streaming: true
    modalities:
    - text
    - text->text
  metadata:
    architecture: Other
  updated_at: 2025-12-19 00:46:07.738821+00:00
- model_id: qwen/qwen3-coder-flash
  name: 'Qwen: Qwen3 Coder Flash'
  provider: openrouter
  description: Qwen3 Coder Flash is Alibaba's fast and cost efficient version of their
    proprietary Qwen3 Coder Plus. It is a powerful coding agent model specializing
    in autonomous programming via tool calling and environment interaction, combining
    coding proficiency with versatile general-purpose abilities.
  context_length: 128000
  pricing:
    prompt: 3.0e-07
    completion: 1.5e-06
    image: 0.0
    request: 0.0
    currency: USD
  capabilities:
    supports_vision: false
    supports_function_calling: true
    supports_streaming: true
    modalities:
    - text
    - text->text
  metadata:
    architecture: Qwen3
  updated_at: 2025-12-19 00:46:07.738829+00:00
- model_id: opengvlab/internvl3-78b
  name: 'OpenGVLab: InternVL3 78B'
  provider: openrouter
  description: "The InternVL3 series is an advanced multimodal large language model\
    \ (MLLM). Compared to InternVL 2.5, InternVL3 demonstrates stronger multimodal\
    \ perception and reasoning capabilities. \n\nIn addition, InternVL3 is benchmarked\
    \ against the Qwen2.5 Chat models, whose pre-trained base models serve as the\
    \ initialization for its language component. Benefiting from Native Multimodal\
    \ Pre-Training, the InternVL3 series surpasses the Qwen2.5 series in overall text\
    \ performance."
  context_length: 32768
  pricing:
    prompt: 1.0e-07
    completion: 3.9e-07
    image: 0.0
    request: 0.0
    currency: USD
  capabilities:
    supports_vision: true
    supports_function_calling: false
    supports_streaming: true
    modalities:
    - text
    - image->text
  metadata:
    architecture: Other
  updated_at: 2025-12-19 00:46:07.738838+00:00
- model_id: qwen/qwen3-next-80b-a3b-thinking
  name: 'Qwen: Qwen3 Next 80B A3B Thinking'
  provider: openrouter
  description: 'Qwen3-Next-80B-A3B-Thinking is a reasoning-first chat model in the
    Qwen3-Next line that outputs structured “thinking” traces by default. It’s designed
    for hard multi-step problems; math proofs, code synthesis/debugging, logic, and
    agentic planning, and reports strong results across knowledge, reasoning, coding,
    alignment, and multilingual evaluations. Compared with prior Qwen3 variants, it
    emphasizes stability under long chains of thought and efficient scaling during
    inference, and it is tuned to follow complex instructions while reducing repetitive
    or off-task behavior.


    The model is suitable for agent frameworks and tool use (function calling), retrieval-heavy
    workflows, and standardized benchmarking where step-by-step solutions are required.
    It supports long, detailed completions and leverages throughput-oriented techniques
    (e.g., multi-token prediction) for faster generation. Note that it operates in
    thinking-only mode.'
  context_length: 131072
  pricing:
    prompt: 1.2e-07
    completion: 1.2e-06
    image: 0.0
    request: 0.0
    currency: USD
  capabilities:
    supports_vision: false
    supports_function_calling: true
    supports_streaming: true
    modalities:
    - text
    - text->text
  metadata:
    architecture: Qwen3
  updated_at: 2025-12-19 00:46:07.738852+00:00
- model_id: qwen/qwen3-next-80b-a3b-instruct
  name: 'Qwen: Qwen3 Next 80B A3B Instruct'
  provider: openrouter
  description: 'Qwen3-Next-80B-A3B-Instruct is an instruction-tuned chat model in
    the Qwen3-Next series optimized for fast, stable responses without “thinking”
    traces. It targets complex tasks across reasoning, code generation, knowledge
    QA, and multilingual use, while remaining robust on alignment and formatting.
    Compared with prior Qwen3 instruct variants, it focuses on higher throughput and
    stability on ultra-long inputs and multi-turn dialogues, making it well-suited
    for RAG, tool use, and agentic workflows that require consistent final answers
    rather than visible chain-of-thought.


    The model employs scaling-efficient training and decoding to improve parameter
    efficiency and inference speed, and has been validated on a broad set of public
    benchmarks where it reaches or approaches larger Qwen3 systems in several categories
    while outperforming earlier mid-sized baselines. It is best used as a general
    assistant, code helper, and long-context task solver in production settings where
    deterministic, instruction-following outputs are preferred.'
  context_length: 262144
  pricing:
    prompt: 9.0e-08
    completion: 1.1e-06
    image: 0.0
    request: 0.0
    currency: USD
  capabilities:
    supports_vision: false
    supports_function_calling: true
    supports_streaming: true
    modalities:
    - text
    - text->text
  metadata:
    architecture: Qwen3
  updated_at: 2025-12-19 00:46:07.738863+00:00
- model_id: meituan/longcat-flash-chat
  name: 'Meituan: LongCat Flash Chat'
  provider: openrouter
  description: 'LongCat-Flash-Chat is a large-scale Mixture-of-Experts (MoE) model
    with 560B total parameters, of which 18.6B–31.3B (≈27B on average) are dynamically
    activated per input. It introduces a shortcut-connected MoE design to reduce communication
    overhead and achieve high throughput while maintaining training stability through
    advanced scaling strategies such as hyperparameter transfer, deterministic computation,
    and multi-stage optimization.


    This release, LongCat-Flash-Chat, is a non-thinking foundation model optimized
    for conversational and agentic tasks. It supports long context windows up to 128K
    tokens and shows competitive performance across reasoning, coding, instruction
    following, and domain benchmarks, with particular strengths in tool use and complex
    multi-step interactions.'
  context_length: 131072
  pricing:
    prompt: 1.5e-07
    completion: 7.5e-07
    image: 0.0
    request: 0.0
    currency: USD
  capabilities:
    supports_vision: false
    supports_function_calling: false
    supports_streaming: true
    modalities:
    - text
    - text->text
  metadata:
    architecture: Other
  updated_at: 2025-12-19 00:46:07.738871+00:00
- model_id: qwen/qwen-plus-2025-07-28
  name: 'Qwen: Qwen Plus 0728'
  provider: openrouter
  description: Qwen Plus 0728, based on the Qwen3 foundation model, is a 1 million
    context hybrid reasoning model with a balanced performance, speed, and cost combination.
  context_length: 1000000
  pricing:
    prompt: 4.0e-07
    completion: 1.2e-06
    image: 0.0
    request: 0.0
    currency: USD
  capabilities:
    supports_vision: false
    supports_function_calling: true
    supports_streaming: true
    modalities:
    - text
    - text->text
  metadata:
    architecture: Qwen3
  updated_at: 2025-12-19 00:46:07.738879+00:00
- model_id: qwen/qwen-plus-2025-07-28:thinking
  name: 'Qwen: Qwen Plus 0728 (thinking)'
  provider: openrouter
  description: Qwen Plus 0728, based on the Qwen3 foundation model, is a 1 million
    context hybrid reasoning model with a balanced performance, speed, and cost combination.
  context_length: 1000000
  pricing:
    prompt: 4.0e-07
    completion: 4.0e-06
    image: 0.0
    request: 0.0
    currency: USD
  capabilities:
    supports_vision: false
    supports_function_calling: true
    supports_streaming: true
    modalities:
    - text
    - text->text
  metadata:
    architecture: Qwen3
  updated_at: 2025-12-19 00:46:07.738889+00:00
- model_id: nvidia/nemotron-nano-9b-v2:free
  name: 'NVIDIA: Nemotron Nano 9B V2 (free)'
  provider: openrouter
  description: "NVIDIA-Nemotron-Nano-9B-v2 is a large language model (LLM) trained\
    \ from scratch by NVIDIA, and designed as a unified model for both reasoning and\
    \ non-reasoning tasks. It responds to user queries and tasks by first generating\
    \ a reasoning trace and then concluding with a final response. \n\nThe model's\
    \ reasoning capabilities can be controlled via a system prompt. If the user prefers\
    \ the model to provide its final answer without intermediate reasoning traces,\
    \ it can be configured to do so."
  context_length: 128000
  pricing:
    prompt: 0.0
    completion: 0.0
    image: 0.0
    request: 0.0
    currency: USD
  capabilities:
    supports_vision: false
    supports_function_calling: true
    supports_streaming: true
    modalities:
    - text
    - text->text
  metadata:
    architecture: Other
  updated_at: 2025-12-19 00:46:07.738901+00:00
- model_id: nvidia/nemotron-nano-9b-v2
  name: 'NVIDIA: Nemotron Nano 9B V2'
  provider: openrouter
  description: "NVIDIA-Nemotron-Nano-9B-v2 is a large language model (LLM) trained\
    \ from scratch by NVIDIA, and designed as a unified model for both reasoning and\
    \ non-reasoning tasks. It responds to user queries and tasks by first generating\
    \ a reasoning trace and then concluding with a final response. \n\nThe model's\
    \ reasoning capabilities can be controlled via a system prompt. If the user prefers\
    \ the model to provide its final answer without intermediate reasoning traces,\
    \ it can be configured to do so."
  context_length: 131072
  pricing:
    prompt: 4.0e-08
    completion: 1.6e-07
    image: 0.0
    request: 0.0
    currency: USD
  capabilities:
    supports_vision: false
    supports_function_calling: true
    supports_streaming: true
    modalities:
    - text
    - text->text
  metadata:
    architecture: Other
  updated_at: 2025-12-19 00:46:07.738910+00:00
- model_id: moonshotai/kimi-k2-0905
  name: 'MoonshotAI: Kimi K2 0905'
  provider: openrouter
  description: 'Kimi K2 0905 is the September update of [Kimi K2 0711](moonshotai/kimi-k2).
    It is a large-scale Mixture-of-Experts (MoE) language model developed by Moonshot
    AI, featuring 1 trillion total parameters with 32 billion active per forward pass.
    It supports long-context inference up to 256k tokens, extended from the previous
    128k.


    This update improves agentic coding with higher accuracy and better generalization
    across scaffolds, and enhances frontend coding with more aesthetic and functional
    outputs for web, 3D, and related tasks. Kimi K2 is optimized for agentic capabilities,
    including advanced tool use, reasoning, and code synthesis. It excels across coding
    (LiveCodeBench, SWE-bench), reasoning (ZebraLogic, GPQA), and tool-use (Tau2,
    AceBench) benchmarks. The model is trained with a novel stack incorporating the
    MuonClip optimizer for stable large-scale MoE training.'
  context_length: 262144
  pricing:
    prompt: 3.9e-07
    completion: 1.9e-06
    image: 0.0
    request: 0.0
    currency: USD
  capabilities:
    supports_vision: false
    supports_function_calling: true
    supports_streaming: true
    modalities:
    - text
    - text->text
  metadata:
    architecture: Other
  updated_at: 2025-12-19 00:46:07.738920+00:00
- model_id: moonshotai/kimi-k2-0905:exacto
  name: 'MoonshotAI: Kimi K2 0905 (exacto)'
  provider: openrouter
  description: 'Kimi K2 0905 is the September update of [Kimi K2 0711](moonshotai/kimi-k2).
    It is a large-scale Mixture-of-Experts (MoE) language model developed by Moonshot
    AI, featuring 1 trillion total parameters with 32 billion active per forward pass.
    It supports long-context inference up to 256k tokens, extended from the previous
    128k.


    This update improves agentic coding with higher accuracy and better generalization
    across scaffolds, and enhances frontend coding with more aesthetic and functional
    outputs for web, 3D, and related tasks. Kimi K2 is optimized for agentic capabilities,
    including advanced tool use, reasoning, and code synthesis. It excels across coding
    (LiveCodeBench, SWE-bench), reasoning (ZebraLogic, GPQA), and tool-use (Tau2,
    AceBench) benchmarks. The model is trained with a novel stack incorporating the
    MuonClip optimizer for stable large-scale MoE training.'
  context_length: 262144
  pricing:
    prompt: 6.0e-07
    completion: 2.5e-06
    image: 0.0
    request: 0.0
    currency: USD
  capabilities:
    supports_vision: false
    supports_function_calling: true
    supports_streaming: true
    modalities:
    - text
    - text->text
  metadata:
    architecture: Other
  updated_at: 2025-12-19 00:46:07.738930+00:00
- model_id: deepcogito/cogito-v2-preview-llama-70b
  name: 'Deep Cogito: Cogito V2 Preview Llama 70B'
  provider: openrouter
  description: Cogito v2 70B is a dense hybrid reasoning model that combines direct
    answering capabilities with advanced self-reflection. Built with iterative policy
    improvement, it delivers strong performance across reasoning tasks while maintaining
    efficiency through shorter reasoning chains and improved intuition.
  context_length: 32768
  pricing:
    prompt: 8.8e-07
    completion: 8.8e-07
    image: 0.0
    request: 0.0
    currency: USD
  capabilities:
    supports_vision: false
    supports_function_calling: true
    supports_streaming: true
    modalities:
    - text
    - text->text
  metadata:
    architecture: Llama3
  updated_at: 2025-12-19 00:46:07.738939+00:00
- model_id: deepcogito/cogito-v2-preview-llama-109b-moe
  name: Cogito V2 Preview Llama 109B
  provider: openrouter
  description: An instruction-tuned, hybrid-reasoning Mixture-of-Experts model built
    on Llama-4-Scout-17B-16E. Cogito v2 can answer directly or engage an extended
    “thinking” phase, with alignment guided by Iterated Distillation & Amplification
    (IDA). It targets coding, STEM, instruction following, and general helpfulness,
    with stronger multilingual, tool-calling, and reasoning performance than size-equivalent
    baselines. The model supports long-context use (up to 10M tokens) and standard
    Transformers workflows. Users can control the reasoning behaviour with the `reasoning`
    `enabled` boolean. [Learn more in our docs](https://openrouter.ai/docs/use-cases/reasoning-tokens#enable-reasoning-with-default-config)
  context_length: 32767
  pricing:
    prompt: 1.8e-07
    completion: 5.9e-07
    image: 0.0
    request: 0.0
    currency: USD
  capabilities:
    supports_vision: true
    supports_function_calling: true
    supports_streaming: true
    modalities:
    - text
    - image->text
  metadata:
    architecture: Llama4
  updated_at: 2025-12-19 00:46:07.738949+00:00
- model_id: stepfun-ai/step3
  name: 'StepFun: Step3'
  provider: openrouter
  description: Step3 is a cutting-edge multimodal reasoning model—built on a Mixture-of-Experts
    architecture with 321B total parameters and 38B active. It is designed end-to-end
    to minimize decoding costs while delivering top-tier performance in vision–language
    reasoning. Through the co-design of Multi-Matrix Factorization Attention (MFA)
    and Attention-FFN Disaggregation (AFD), Step3 maintains exceptional efficiency
    across both flagship and low-end accelerators.
  context_length: 65536
  pricing:
    prompt: 5.7e-07
    completion: 1.42e-06
    image: 0.0
    request: 0.0
    currency: USD
  capabilities:
    supports_vision: true
    supports_function_calling: true
    supports_streaming: true
    modalities:
    - text
    - image->text
  metadata:
    architecture: Other
  updated_at: 2025-12-19 00:46:07.738960+00:00
- model_id: qwen/qwen3-30b-a3b-thinking-2507
  name: 'Qwen: Qwen3 30B A3B Thinking 2507'
  provider: openrouter
  description: 'Qwen3-30B-A3B-Thinking-2507 is a 30B parameter Mixture-of-Experts
    reasoning model optimized for complex tasks requiring extended multi-step thinking.
    The model is designed specifically for “thinking mode,” where internal reasoning
    traces are separated from final answers.


    Compared to earlier Qwen3-30B releases, this version improves performance across
    logical reasoning, mathematics, science, coding, and multilingual benchmarks.
    It also demonstrates stronger instruction following, tool use, and alignment with
    human preferences. With higher reasoning efficiency and extended output budgets,
    it is best suited for advanced research, competitive problem solving, and agentic
    applications requiring structured long-context reasoning.'
  context_length: 32768
  pricing:
    prompt: 5.1e-08
    completion: 3.4e-07
    image: 0.0
    request: 0.0
    currency: USD
  capabilities:
    supports_vision: false
    supports_function_calling: true
    supports_streaming: true
    modalities:
    - text
    - text->text
  metadata:
    architecture: Qwen3
  updated_at: 2025-12-19 00:46:07.738970+00:00
- model_id: x-ai/grok-code-fast-1
  name: 'xAI: Grok Code Fast 1'
  provider: openrouter
  description: Grok Code Fast 1 is a speedy and economical reasoning model that excels
    at agentic coding. With reasoning traces visible in the response, developers can
    steer Grok Code for high-quality work flows.
  context_length: 256000
  pricing:
    prompt: 2.0e-07
    completion: 1.5e-06
    image: 0.0
    request: 0.0
    currency: USD
  capabilities:
    supports_vision: false
    supports_function_calling: true
    supports_streaming: true
    modalities:
    - text
    - text->text
  metadata:
    architecture: Grok
  updated_at: 2025-12-19 00:46:07.738982+00:00
- model_id: nousresearch/hermes-4-70b
  name: 'Nous: Hermes 4 70B'
  provider: openrouter
  description: 'Hermes 4 70B is a hybrid reasoning model from Nous Research, built
    on Meta-Llama-3.1-70B. It introduces the same hybrid mode as the larger 405B release,
    allowing the model to either respond directly or generate explicit <think>...</think>
    reasoning traces before answering. Users can control the reasoning behaviour with
    the `reasoning` `enabled` boolean. [Learn more in our docs](https://openrouter.ai/docs/use-cases/reasoning-tokens#enable-reasoning-with-default-config)


    This 70B variant is trained with the expanded post-training corpus (~60B tokens)
    emphasizing verified reasoning data, leading to improvements in mathematics, coding,
    STEM, logic, and structured outputs while maintaining general assistant performance.
    It supports JSON mode, schema adherence, function calling, and tool use, and is
    designed for greater steerability with reduced refusal rates.'
  context_length: 131072
  pricing:
    prompt: 1.1e-07
    completion: 3.8e-07
    image: 0.0
    request: 0.0
    currency: USD
  capabilities:
    supports_vision: false
    supports_function_calling: true
    supports_streaming: true
    modalities:
    - text
    - text->text
  metadata:
    architecture: Llama3
  updated_at: 2025-12-19 00:46:07.738991+00:00
- model_id: nousresearch/hermes-4-405b
  name: 'Nous: Hermes 4 405B'
  provider: openrouter
  description: 'Hermes 4 is a large-scale reasoning model built on Meta-Llama-3.1-405B
    and released by Nous Research. It introduces a hybrid reasoning mode, where the
    model can choose to deliberate internally with <think>...</think> traces or respond
    directly, offering flexibility between speed and depth. Users can control the
    reasoning behaviour with the `reasoning` `enabled` boolean. [Learn more in our
    docs](https://openrouter.ai/docs/use-cases/reasoning-tokens#enable-reasoning-with-default-config)


    The model is instruction-tuned with an expanded post-training corpus (~60B tokens)
    emphasizing reasoning traces, improving performance in math, code, STEM, and logical
    reasoning, while retaining broad assistant utility. It also supports structured
    outputs, including JSON mode, schema adherence, function calling, and tool use.
    Hermes 4 is trained for steerability, lower refusal rates, and alignment toward
    neutral, user-directed behavior.'
  context_length: 131072
  pricing:
    prompt: 3.0e-07
    completion: 1.2e-06
    image: 0.0
    request: 0.0
    currency: USD
  capabilities:
    supports_vision: false
    supports_function_calling: true
    supports_streaming: true
    modalities:
    - text
    - text->text
  metadata:
    architecture: Other
  updated_at: 2025-12-19 00:46:07.738999+00:00
- model_id: google/gemini-2.5-flash-image-preview
  name: 'Google: Gemini 2.5 Flash Image Preview (Nano Banana)'
  provider: openrouter
  description: Gemini 2.5 Flash Image Preview, a.k.a. "Nano Banana," is a state of
    the art image generation model with contextual understanding. It is capable of
    image generation, edits, and multi-turn conversations.
  context_length: 32768
  pricing:
    prompt: 3.0e-07
    completion: 2.5e-06
    image: 0.001238
    request: 0.0
    currency: USD
  capabilities:
    supports_vision: true
    supports_function_calling: false
    supports_streaming: true
    modalities:
    - text
    - image->text
    - image
  metadata:
    architecture: Gemini
  updated_at: 2025-12-19 00:46:07.739012+00:00
- model_id: deepseek/deepseek-chat-v3.1
  name: 'DeepSeek: DeepSeek V3.1'
  provider: openrouter
  description: "DeepSeek-V3.1 is a large hybrid reasoning model (671B parameters,\
    \ 37B active) that supports both thinking and non-thinking modes via prompt templates.\
    \ It extends the DeepSeek-V3 base with a two-phase long-context training process,\
    \ reaching up to 128K tokens, and uses FP8 microscaling for efficient inference.\
    \ Users can control the reasoning behaviour with the `reasoning` `enabled` boolean.\
    \ [Learn more in our docs](https://openrouter.ai/docs/use-cases/reasoning-tokens#enable-reasoning-with-default-config)\n\
    \nThe model improves tool use, code generation, and reasoning efficiency, achieving\
    \ performance comparable to DeepSeek-R1 on difficult benchmarks while responding\
    \ more quickly. It supports structured tool calling, code agents, and search agents,\
    \ making it suitable for research, coding, and agentic workflows. \n\nIt succeeds\
    \ the [DeepSeek V3-0324](/deepseek/deepseek-chat-v3-0324) model and performs well\
    \ on a variety of tasks."
  context_length: 8192
  pricing:
    prompt: 1.5e-07
    completion: 7.5e-07
    image: 0.0
    request: 0.0
    currency: USD
  capabilities:
    supports_vision: false
    supports_function_calling: true
    supports_streaming: true
    modalities:
    - text
    - text->text
  metadata:
    architecture: DeepSeek
  updated_at: 2025-12-19 00:46:07.739022+00:00
- model_id: openai/gpt-4o-audio-preview
  name: 'OpenAI: GPT-4o Audio'
  provider: openrouter
  description: The gpt-4o-audio-preview model adds support for audio inputs as prompts.
    This enhancement allows the model to detect nuances within audio recordings and
    add depth to generated user experiences. Audio outputs are currently not supported.
    Audio tokens are priced at $40 per million input audio tokens.
  context_length: 128000
  pricing:
    prompt: 2.5e-06
    completion: 1.0e-05
    image: 0.0
    request: 0.0
    currency: USD
  capabilities:
    supports_vision: false
    supports_function_calling: true
    supports_streaming: true
    modalities:
    - text
    - text->text
  metadata:
    architecture: GPT
  updated_at: 2025-12-19 00:46:07.739031+00:00
- model_id: mistralai/mistral-medium-3.1
  name: 'Mistral: Mistral Medium 3.1'
  provider: openrouter
  description: 'Mistral Medium 3.1 is an updated version of Mistral Medium 3, which
    is a high-performance enterprise-grade language model designed to deliver frontier-level
    capabilities at significantly reduced operational cost. It balances state-of-the-art
    reasoning and multimodal performance with 8× lower cost compared to traditional
    large models, making it suitable for scalable deployments across professional
    and industrial use cases.


    The model excels in domains such as coding, STEM reasoning, and enterprise adaptation.
    It supports hybrid, on-prem, and in-VPC deployments and is optimized for integration
    into custom workflows. Mistral Medium 3.1 offers competitive accuracy relative
    to larger models like Claude Sonnet 3.5/3.7, Llama 4 Maverick, and Command R+,
    while maintaining broad compatibility across cloud environments.'
  context_length: 131072
  pricing:
    prompt: 4.0e-07
    completion: 2.0e-06
    image: 0.0
    request: 0.0
    currency: USD
  capabilities:
    supports_vision: true
    supports_function_calling: true
    supports_streaming: true
    modalities:
    - text
    - image->text
  metadata:
    architecture: Mistral
  updated_at: 2025-12-19 00:46:07.739042+00:00
- model_id: baidu/ernie-4.5-21b-a3b
  name: 'Baidu: ERNIE 4.5 21B A3B'
  provider: openrouter
  description: A sophisticated text-based Mixture-of-Experts (MoE) model featuring
    21B total parameters with 3B activated per token, delivering exceptional multimodal
    understanding and generation through heterogeneous MoE structures and modality-isolated
    routing. Supporting an extensive 131K token context length, the model achieves
    efficient inference via multi-expert parallel collaboration and quantization,
    while advanced post-training techniques including SFT, DPO, and UPO ensure optimized
    performance across diverse applications with specialized routing and balancing
    losses for superior task handling.
  context_length: 120000
  pricing:
    prompt: 5.6e-08
    completion: 2.24e-07
    image: 0.0
    request: 0.0
    currency: USD
  capabilities:
    supports_vision: false
    supports_function_calling: true
    supports_streaming: true
    modalities:
    - text
    - text->text
  metadata:
    architecture: Other
  updated_at: 2025-12-19 00:46:07.739054+00:00
- model_id: baidu/ernie-4.5-vl-28b-a3b
  name: 'Baidu: ERNIE 4.5 VL 28B A3B'
  provider: openrouter
  description: A powerful multimodal Mixture-of-Experts chat model featuring 28B total
    parameters with 3B activated per token, delivering exceptional text and vision
    understanding through its innovative heterogeneous MoE structure with modality-isolated
    routing. Built with scaling-efficient infrastructure for high-throughput training
    and inference, the model leverages advanced post-training techniques including
    SFT, DPO, and UPO for optimized performance, while supporting an impressive 131K
    context length and RLVR alignment for superior cross-modal reasoning and generation
    capabilities.
  context_length: 30000
  pricing:
    prompt: 1.12e-07
    completion: 4.48e-07
    image: 0.0
    request: 0.0
    currency: USD
  capabilities:
    supports_vision: true
    supports_function_calling: true
    supports_streaming: true
    modalities:
    - text
    - image->text
  metadata:
    architecture: Other
  updated_at: 2025-12-19 00:46:07.739063+00:00
- model_id: z-ai/glm-4.5v
  name: 'Z.AI: GLM 4.5V'
  provider: openrouter
  description: 'GLM-4.5V is a vision-language foundation model for multimodal agent
    applications. Built on a Mixture-of-Experts (MoE) architecture with 106B parameters
    and 12B activated parameters, it achieves state-of-the-art results in video understanding,
    image Q&A, OCR, and document parsing, with strong gains in front-end web coding,
    grounding, and spatial reasoning. It offers a hybrid inference mode: a "thinking
    mode" for deep reasoning and a "non-thinking mode" for fast responses. Reasoning
    behavior can be toggled via the `reasoning` `enabled` boolean. [Learn more in
    our docs](https://openrouter.ai/docs/use-cases/reasoning-tokens#enable-reasoning-with-default-config)'
  context_length: 65536
  pricing:
    prompt: 4.8e-07
    completion: 1.44e-06
    image: 0.0
    request: 0.0
    currency: USD
  capabilities:
    supports_vision: true
    supports_function_calling: true
    supports_streaming: true
    modalities:
    - text
    - image->text
  metadata:
    architecture: Other
  updated_at: 2025-12-19 00:46:07.739104+00:00
- model_id: ai21/jamba-mini-1.7
  name: 'AI21: Jamba Mini 1.7'
  provider: openrouter
  description: Jamba Mini 1.7 is a compact and efficient member of the Jamba open
    model family, incorporating key improvements in grounding and instruction-following
    while maintaining the benefits of the SSM-Transformer hybrid architecture and
    256K context window. Despite its compact size, it delivers accurate, contextually
    grounded responses and improved steerability.
  context_length: 256000
  pricing:
    prompt: 2.0e-07
    completion: 4.0e-07
    image: 0.0
    request: 0.0
    currency: USD
  capabilities:
    supports_vision: false
    supports_function_calling: true
    supports_streaming: true
    modalities:
    - text
    - text->text
  metadata:
    architecture: Other
  updated_at: 2025-12-19 00:46:07.739115+00:00
- model_id: ai21/jamba-large-1.7
  name: 'AI21: Jamba Large 1.7'
  provider: openrouter
  description: Jamba Large 1.7 is the latest model in the Jamba open family, offering
    improvements in grounding, instruction-following, and overall efficiency. Built
    on a hybrid SSM-Transformer architecture with a 256K context window, it delivers
    more accurate, contextually grounded responses and better steerability than previous
    versions.
  context_length: 256000
  pricing:
    prompt: 2.0e-06
    completion: 8.0e-06
    image: 0.0
    request: 0.0
    currency: USD
  capabilities:
    supports_vision: false
    supports_function_calling: true
    supports_streaming: true
    modalities:
    - text
    - text->text
  metadata:
    architecture: Other
  updated_at: 2025-12-19 00:46:07.739126+00:00
- model_id: openai/gpt-5-chat
  name: 'OpenAI: GPT-5 Chat'
  provider: openrouter
  description: GPT-5 Chat is designed for advanced, natural, multimodal, and context-aware
    conversations for enterprise applications.
  context_length: 128000
  pricing:
    prompt: 1.25e-06
    completion: 1.0e-05
    image: 0.0
    request: 0.0
    currency: USD
  capabilities:
    supports_vision: true
    supports_function_calling: false
    supports_streaming: true
    modalities:
    - text
    - image->text
  metadata:
    architecture: GPT
  updated_at: 2025-12-19 00:46:07.739137+00:00
- model_id: openai/gpt-5
  name: 'OpenAI: GPT-5'
  provider: openrouter
  description: GPT-5 is OpenAI’s most advanced model, offering major improvements
    in reasoning, code quality, and user experience. It is optimized for complex tasks
    that require step-by-step reasoning, instruction following, and accuracy in high-stakes
    use cases. It supports test-time routing features and advanced prompt understanding,
    including user-specified intent like "think hard about this." Improvements include
    reductions in hallucination, sycophancy, and better performance in coding, writing,
    and health-related tasks.
  context_length: 400000
  pricing:
    prompt: 1.25e-06
    completion: 1.0e-05
    image: 0.0
    request: 0.0
    currency: USD
  capabilities:
    supports_vision: true
    supports_function_calling: true
    supports_streaming: true
    modalities:
    - text
    - image->text
  metadata:
    architecture: GPT
  updated_at: 2025-12-19 00:46:07.739145+00:00
- model_id: openai/gpt-5-mini
  name: 'OpenAI: GPT-5 Mini'
  provider: openrouter
  description: GPT-5 Mini is a compact version of GPT-5, designed to handle lighter-weight
    reasoning tasks. It provides the same instruction-following and safety-tuning
    benefits as GPT-5, but with reduced latency and cost. GPT-5 Mini is the successor
    to OpenAI's o4-mini model.
  context_length: 400000
  pricing:
    prompt: 2.5e-07
    completion: 2.0e-06
    image: 0.0
    request: 0.0
    currency: USD
  capabilities:
    supports_vision: true
    supports_function_calling: true
    supports_streaming: true
    modalities:
    - text
    - image->text
  metadata:
    architecture: GPT
  updated_at: 2025-12-19 00:46:07.739157+00:00
- model_id: openai/gpt-5-nano
  name: 'OpenAI: GPT-5 Nano'
  provider: openrouter
  description: GPT-5-Nano is the smallest and fastest variant in the GPT-5 system,
    optimized for developer tools, rapid interactions, and ultra-low latency environments.
    While limited in reasoning depth compared to its larger counterparts, it retains
    key instruction-following and safety features. It is the successor to GPT-4.1-nano
    and offers a lightweight option for cost-sensitive or real-time applications.
  context_length: 400000
  pricing:
    prompt: 5.0e-08
    completion: 4.0e-07
    image: 0.0
    request: 0.0
    currency: USD
  capabilities:
    supports_vision: true
    supports_function_calling: true
    supports_streaming: true
    modalities:
    - text
    - image->text
  metadata:
    architecture: GPT
  updated_at: 2025-12-19 00:46:07.739167+00:00
- model_id: openai/gpt-oss-120b:free
  name: 'OpenAI: gpt-oss-120b (free)'
  provider: openrouter
  description: gpt-oss-120b is an open-weight, 117B-parameter Mixture-of-Experts (MoE)
    language model from OpenAI designed for high-reasoning, agentic, and general-purpose
    production use cases. It activates 5.1B parameters per forward pass and is optimized
    to run on a single H100 GPU with native MXFP4 quantization. The model supports
    configurable reasoning depth, full chain-of-thought access, and native tool use,
    including function calling, browsing, and structured output generation.
  context_length: 131072
  pricing:
    prompt: 0.0
    completion: 0.0
    image: 0.0
    request: 0.0
    currency: USD
  capabilities:
    supports_vision: false
    supports_function_calling: true
    supports_streaming: true
    modalities:
    - text
    - text->text
  metadata:
    architecture: GPT
  updated_at: 2025-12-19 00:46:07.739175+00:00
- model_id: openai/gpt-oss-120b
  name: 'OpenAI: gpt-oss-120b'
  provider: openrouter
  description: gpt-oss-120b is an open-weight, 117B-parameter Mixture-of-Experts (MoE)
    language model from OpenAI designed for high-reasoning, agentic, and general-purpose
    production use cases. It activates 5.1B parameters per forward pass and is optimized
    to run on a single H100 GPU with native MXFP4 quantization. The model supports
    configurable reasoning depth, full chain-of-thought access, and native tool use,
    including function calling, browsing, and structured output generation.
  context_length: 131072
  pricing:
    prompt: 3.9e-08
    completion: 1.9e-07
    image: 0.0
    request: 0.0
    currency: USD
  capabilities:
    supports_vision: false
    supports_function_calling: true
    supports_streaming: true
    modalities:
    - text
    - text->text
  metadata:
    architecture: GPT
  updated_at: 2025-12-19 00:46:07.739186+00:00
- model_id: openai/gpt-oss-120b:exacto
  name: 'OpenAI: gpt-oss-120b (exacto)'
  provider: openrouter
  description: gpt-oss-120b is an open-weight, 117B-parameter Mixture-of-Experts (MoE)
    language model from OpenAI designed for high-reasoning, agentic, and general-purpose
    production use cases. It activates 5.1B parameters per forward pass and is optimized
    to run on a single H100 GPU with native MXFP4 quantization. The model supports
    configurable reasoning depth, full chain-of-thought access, and native tool use,
    including function calling, browsing, and structured output generation.
  context_length: 131072
  pricing:
    prompt: 3.9e-08
    completion: 1.9e-07
    image: 0.0
    request: 0.0
    currency: USD
  capabilities:
    supports_vision: false
    supports_function_calling: true
    supports_streaming: true
    modalities:
    - text
    - text->text
  metadata:
    architecture: GPT
  updated_at: 2025-12-19 00:46:07.739198+00:00
- model_id: openai/gpt-oss-20b:free
  name: 'OpenAI: gpt-oss-20b (free)'
  provider: openrouter
  description: gpt-oss-20b is an open-weight 21B parameter model released by OpenAI
    under the Apache 2.0 license. It uses a Mixture-of-Experts (MoE) architecture
    with 3.6B active parameters per forward pass, optimized for lower-latency inference
    and deployability on consumer or single-GPU hardware. The model is trained in
    OpenAI’s Harmony response format and supports reasoning level configuration, fine-tuning,
    and agentic capabilities including function calling, tool use, and structured
    outputs.
  context_length: 131072
  pricing:
    prompt: 0.0
    completion: 0.0
    image: 0.0
    request: 0.0
    currency: USD
  capabilities:
    supports_vision: false
    supports_function_calling: true
    supports_streaming: true
    modalities:
    - text
    - text->text
  metadata:
    architecture: GPT
  updated_at: 2025-12-19 00:46:07.739206+00:00
- model_id: openai/gpt-oss-20b
  name: 'OpenAI: gpt-oss-20b'
  provider: openrouter
  description: gpt-oss-20b is an open-weight 21B parameter model released by OpenAI
    under the Apache 2.0 license. It uses a Mixture-of-Experts (MoE) architecture
    with 3.6B active parameters per forward pass, optimized for lower-latency inference
    and deployability on consumer or single-GPU hardware. The model is trained in
    OpenAI’s Harmony response format and supports reasoning level configuration, fine-tuning,
    and agentic capabilities including function calling, tool use, and structured
    outputs.
  context_length: 131072
  pricing:
    prompt: 3.0e-08
    completion: 1.4e-07
    image: 0.0
    request: 0.0
    currency: USD
  capabilities:
    supports_vision: false
    supports_function_calling: true
    supports_streaming: true
    modalities:
    - text
    - text->text
  metadata:
    architecture: GPT
  updated_at: 2025-12-19 00:46:07.739220+00:00
- model_id: anthropic/claude-opus-4.1
  name: 'Anthropic: Claude Opus 4.1'
  provider: openrouter
  description: Claude Opus 4.1 is an updated version of Anthropic’s flagship model,
    offering improved performance in coding, reasoning, and agentic tasks. It achieves
    74.5% on SWE-bench Verified and shows notable gains in multi-file code refactoring,
    debugging precision, and detail-oriented reasoning. The model supports extended
    thinking up to 64K tokens and is optimized for tasks involving research, data
    analysis, and tool-assisted reasoning.
  context_length: 200000
  pricing:
    prompt: 1.5e-05
    completion: 7.5e-05
    image: 0.024
    request: 0.0
    currency: USD
  capabilities:
    supports_vision: true
    supports_function_calling: true
    supports_streaming: true
    modalities:
    - text
    - image->text
  metadata:
    architecture: Claude
  updated_at: 2025-12-19 00:46:07.739230+00:00
- model_id: mistralai/codestral-2508
  name: 'Mistral: Codestral 2508'
  provider: openrouter
  description: 'Mistral''s cutting-edge language model for coding released end of
    July 2025. Codestral specializes in low-latency, high-frequency tasks such as
    fill-in-the-middle (FIM), code correction and test generation.


    [Blog Post](https://mistral.ai/news/codestral-25-08)'
  context_length: 256000
  pricing:
    prompt: 3.0e-07
    completion: 9.0e-07
    image: 0.0
    request: 0.0
    currency: USD
  capabilities:
    supports_vision: false
    supports_function_calling: true
    supports_streaming: true
    modalities:
    - text
    - text->text
  metadata:
    architecture: Mistral
  updated_at: 2025-12-19 00:46:07.739241+00:00
- model_id: qwen/qwen3-coder-30b-a3b-instruct
  name: 'Qwen: Qwen3 Coder 30B A3B Instruct'
  provider: openrouter
  description: 'Qwen3-Coder-30B-A3B-Instruct is a 30.5B parameter Mixture-of-Experts
    (MoE) model with 128 experts (8 active per forward pass), designed for advanced
    code generation, repository-scale understanding, and agentic tool use. Built on
    the Qwen3 architecture, it supports a native context length of 256K tokens (extendable
    to 1M with Yarn) and performs strongly in tasks involving function calls, browser
    use, and structured code completion.


    This model is optimized for instruction-following without “thinking mode”, and
    integrates well with OpenAI-compatible tool-use formats. '
  context_length: 262144
  pricing:
    prompt: 6.0e-08
    completion: 2.5e-07
    image: 0.0
    request: 0.0
    currency: USD
  capabilities:
    supports_vision: false
    supports_function_calling: true
    supports_streaming: true
    modalities:
    - text
    - text->text
  metadata:
    architecture: Qwen3
  updated_at: 2025-12-19 00:46:07.739249+00:00
- model_id: qwen/qwen3-30b-a3b-instruct-2507
  name: 'Qwen: Qwen3 30B A3B Instruct 2507'
  provider: openrouter
  description: Qwen3-30B-A3B-Instruct-2507 is a 30.5B-parameter mixture-of-experts
    language model from Qwen, with 3.3B active parameters per inference. It operates
    in non-thinking mode and is designed for high-quality instruction following, multilingual
    understanding, and agentic tool use. Post-trained on instruction data, it demonstrates
    competitive performance across reasoning (AIME, ZebraLogic), coding (MultiPL-E,
    LiveCodeBench), and alignment (IFEval, WritingBench) benchmarks. It outperforms
    its non-instruct variant on subjective and open-ended tasks while retaining strong
    factual and coding performance.
  context_length: 262144
  pricing:
    prompt: 8.0e-08
    completion: 3.3e-07
    image: 0.0
    request: 0.0
    currency: USD
  capabilities:
    supports_vision: false
    supports_function_calling: true
    supports_streaming: true
    modalities:
    - text
    - text->text
  metadata:
    architecture: Qwen3
  updated_at: 2025-12-19 00:46:07.739261+00:00
- model_id: z-ai/glm-4.5
  name: 'Z.AI: GLM 4.5'
  provider: openrouter
  description: GLM-4.5 is our latest flagship foundation model, purpose-built for
    agent-based applications. It leverages a Mixture-of-Experts (MoE) architecture
    and supports a context length of up to 128k tokens. GLM-4.5 delivers significantly
    enhanced capabilities in reasoning, code generation, and agent alignment. It supports
    a hybrid inference mode with two options, a "thinking mode" designed for complex
    reasoning and tool use, and a "non-thinking mode" optimized for instant responses.
    Users can control the reasoning behaviour with the `reasoning` `enabled` boolean.
    [Learn more in our docs](https://openrouter.ai/docs/use-cases/reasoning-tokens#enable-reasoning-with-default-config)
  context_length: 131072
  pricing:
    prompt: 3.5e-07
    completion: 1.55e-06
    image: 0.0
    request: 0.0
    currency: USD
  capabilities:
    supports_vision: false
    supports_function_calling: true
    supports_streaming: true
    modalities:
    - text
    - text->text
  metadata:
    architecture: Other
  updated_at: 2025-12-19 00:46:07.739269+00:00
- model_id: z-ai/glm-4.5-air:free
  name: 'Z.AI: GLM 4.5 Air (free)'
  provider: openrouter
  description: GLM-4.5-Air is the lightweight variant of our latest flagship model
    family, also purpose-built for agent-centric applications. Like GLM-4.5, it adopts
    the Mixture-of-Experts (MoE) architecture but with a more compact parameter size.
    GLM-4.5-Air also supports hybrid inference modes, offering a "thinking mode" for
    advanced reasoning and tool use, and a "non-thinking mode" for real-time interaction.
    Users can control the reasoning behaviour with the `reasoning` `enabled` boolean.
    [Learn more in our docs](https://openrouter.ai/docs/use-cases/reasoning-tokens#enable-reasoning-with-default-config)
  context_length: 131072
  pricing:
    prompt: 0.0
    completion: 0.0
    image: 0.0
    request: 0.0
    currency: USD
  capabilities:
    supports_vision: false
    supports_function_calling: true
    supports_streaming: true
    modalities:
    - text
    - text->text
  metadata:
    architecture: Other
  updated_at: 2025-12-19 00:46:07.739280+00:00
- model_id: z-ai/glm-4.5-air
  name: 'Z.AI: GLM 4.5 Air'
  provider: openrouter
  description: GLM-4.5-Air is the lightweight variant of our latest flagship model
    family, also purpose-built for agent-centric applications. Like GLM-4.5, it adopts
    the Mixture-of-Experts (MoE) architecture but with a more compact parameter size.
    GLM-4.5-Air also supports hybrid inference modes, offering a "thinking mode" for
    advanced reasoning and tool use, and a "non-thinking mode" for real-time interaction.
    Users can control the reasoning behaviour with the `reasoning` `enabled` boolean.
    [Learn more in our docs](https://openrouter.ai/docs/use-cases/reasoning-tokens#enable-reasoning-with-default-config)
  context_length: 131072
  pricing:
    prompt: 1.04e-07
    completion: 6.8e-07
    image: 0.0
    request: 0.0
    currency: USD
  capabilities:
    supports_vision: false
    supports_function_calling: true
    supports_streaming: true
    modalities:
    - text
    - text->text
  metadata:
    architecture: Other
  updated_at: 2025-12-19 00:46:07.739290+00:00
- model_id: qwen/qwen3-235b-a22b-thinking-2507
  name: 'Qwen: Qwen3 235B A22B Thinking 2507'
  provider: openrouter
  description: 'Qwen3-235B-A22B-Thinking-2507 is a high-performance, open-weight Mixture-of-Experts
    (MoE) language model optimized for complex reasoning tasks. It activates 22B of
    its 235B parameters per forward pass and natively supports up to 262,144 tokens
    of context. This "thinking-only" variant enhances structured logical reasoning,
    mathematics, science, and long-form generation, showing strong benchmark performance
    across AIME, SuperGPQA, LiveCodeBench, and MMLU-Redux. It enforces a special reasoning
    mode (</think>) and is designed for high-token outputs (up to 81,920 tokens) in
    challenging domains.


    The model is instruction-tuned and excels at step-by-step reasoning, tool use,
    agentic workflows, and multilingual tasks. This release represents the most capable
    open-source variant in the Qwen3-235B series, surpassing many closed models in
    structured reasoning use cases.'
  context_length: 262144
  pricing:
    prompt: 1.1e-07
    completion: 6.0e-07
    image: 0.0
    request: 0.0
    currency: USD
  capabilities:
    supports_vision: false
    supports_function_calling: true
    supports_streaming: true
    modalities:
    - text
    - text->text
  metadata:
    architecture: Qwen3
  updated_at: 2025-12-19 00:46:07.739299+00:00
- model_id: z-ai/glm-4-32b
  name: 'Z.AI: GLM 4 32B '
  provider: openrouter
  description: 'GLM 4 32B is a cost-effective foundation language model.


    It can efficiently perform complex tasks and has significantly enhanced capabilities
    in tool use, online search, and code-related intelligent tasks.


    It is made by the same lab behind the thudm models.'
  context_length: 128000
  pricing:
    prompt: 1.0e-07
    completion: 1.0e-07
    image: 0.0
    request: 0.0
    currency: USD
  capabilities:
    supports_vision: false
    supports_function_calling: true
    supports_streaming: true
    modalities:
    - text
    - text->text
  metadata:
    architecture: Other
  updated_at: 2025-12-19 00:46:07.739307+00:00
- model_id: qwen/qwen3-coder:free
  name: 'Qwen: Qwen3 Coder 480B A35B (free)'
  provider: openrouter
  description: 'Qwen3-Coder-480B-A35B-Instruct is a Mixture-of-Experts (MoE) code
    generation model developed by the Qwen team. It is optimized for agentic coding
    tasks such as function calling, tool use, and long-context reasoning over repositories.
    The model features 480 billion total parameters, with 35 billion active per forward
    pass (8 out of 160 experts).


    Pricing for the Alibaba endpoints varies by context length. Once a request is
    greater than 128k input tokens, the higher pricing is used.'
  context_length: 262000
  pricing:
    prompt: 0.0
    completion: 0.0
    image: 0.0
    request: 0.0
    currency: USD
  capabilities:
    supports_vision: false
    supports_function_calling: true
    supports_streaming: true
    modalities:
    - text
    - text->text
  metadata:
    architecture: Qwen3
  updated_at: 2025-12-19 00:46:07.739321+00:00
- model_id: qwen/qwen3-coder
  name: 'Qwen: Qwen3 Coder 480B A35B'
  provider: openrouter
  description: 'Qwen3-Coder-480B-A35B-Instruct is a Mixture-of-Experts (MoE) code
    generation model developed by the Qwen team. It is optimized for agentic coding
    tasks such as function calling, tool use, and long-context reasoning over repositories.
    The model features 480 billion total parameters, with 35 billion active per forward
    pass (8 out of 160 experts).


    Pricing for the Alibaba endpoints varies by context length. Once a request is
    greater than 128k input tokens, the higher pricing is used.'
  context_length: 262144
  pricing:
    prompt: 2.2e-07
    completion: 9.5e-07
    image: 0.0
    request: 0.0
    currency: USD
  capabilities:
    supports_vision: false
    supports_function_calling: true
    supports_streaming: true
    modalities:
    - text
    - text->text
  metadata:
    architecture: Qwen3
  updated_at: 2025-12-19 00:46:07.739330+00:00
- model_id: qwen/qwen3-coder:exacto
  name: 'Qwen: Qwen3 Coder 480B A35B (exacto)'
  provider: openrouter
  description: 'Qwen3-Coder-480B-A35B-Instruct is a Mixture-of-Experts (MoE) code
    generation model developed by the Qwen team. It is optimized for agentic coding
    tasks such as function calling, tool use, and long-context reasoning over repositories.
    The model features 480 billion total parameters, with 35 billion active per forward
    pass (8 out of 160 experts).


    Pricing for the Alibaba endpoints varies by context length. Once a request is
    greater than 128k input tokens, the higher pricing is used.'
  context_length: 262144
  pricing:
    prompt: 2.2e-07
    completion: 1.8e-06
    image: 0.0
    request: 0.0
    currency: USD
  capabilities:
    supports_vision: false
    supports_function_calling: true
    supports_streaming: true
    modalities:
    - text
    - text->text
  metadata:
    architecture: Qwen3
  updated_at: 2025-12-19 00:46:07.739338+00:00
- model_id: bytedance/ui-tars-1.5-7b
  name: 'ByteDance: UI-TARS 7B '
  provider: openrouter
  description: 'UI-TARS-1.5 is a multimodal vision-language agent optimized for GUI-based
    environments, including desktop interfaces, web browsers, mobile systems, and
    games. Built by ByteDance, it builds upon the UI-TARS framework with reinforcement
    learning-based reasoning, enabling robust action planning and execution across
    virtual interfaces.


    This model achieves state-of-the-art results on a range of interactive and grounding
    benchmarks, including OSworld, WebVoyager, AndroidWorld, and ScreenSpot. It also
    demonstrates perfect task completion across diverse Poki games and outperforms
    prior models in Minecraft agent tasks. UI-TARS-1.5 supports thought decomposition
    during inference and shows strong scaling across variants, with the 1.5 version
    notably exceeding the performance of earlier 72B and 7B checkpoints.'
  context_length: 128000
  pricing:
    prompt: 1.0e-07
    completion: 2.0e-07
    image: 0.0
    request: 0.0
    currency: USD
  capabilities:
    supports_vision: true
    supports_function_calling: false
    supports_streaming: true
    modalities:
    - text
    - image->text
  metadata:
    architecture: Other
  updated_at: 2025-12-19 00:46:07.739346+00:00
- model_id: google/gemini-2.5-flash-lite
  name: 'Google: Gemini 2.5 Flash Lite'
  provider: openrouter
  description: 'Gemini 2.5 Flash-Lite is a lightweight reasoning model in the Gemini
    2.5 family, optimized for ultra-low latency and cost efficiency. It offers improved
    throughput, faster token generation, and better performance across common benchmarks
    compared to earlier Flash models. By default, "thinking" (i.e. multi-pass reasoning)
    is disabled to prioritize speed, but developers can enable it via the [Reasoning
    API parameter](https://openrouter.ai/docs/use-cases/reasoning-tokens) to selectively
    trade off cost for intelligence. '
  context_length: 1048576
  pricing:
    prompt: 1.0e-07
    completion: 4.0e-07
    image: 0.0
    request: 0.0
    currency: USD
  capabilities:
    supports_vision: true
    supports_function_calling: true
    supports_streaming: true
    modalities:
    - text
    - image->text
  metadata:
    architecture: Gemini
  updated_at: 2025-12-19 00:46:07.739356+00:00
- model_id: qwen/qwen3-235b-a22b-2507
  name: 'Qwen: Qwen3 235B A22B Instruct 2507'
  provider: openrouter
  description: 'Qwen3-235B-A22B-Instruct-2507 is a multilingual, instruction-tuned
    mixture-of-experts language model based on the Qwen3-235B architecture, with 22B
    active parameters per forward pass. It is optimized for general-purpose text generation,
    including instruction following, logical reasoning, math, code, and tool usage.
    The model supports a native 262K context length and does not implement "thinking
    mode" (<think> blocks).


    Compared to its base variant, this version delivers significant gains in knowledge
    coverage, long-context reasoning, coding benchmarks, and alignment with open-ended
    tasks. It is particularly strong on multilingual understanding, math reasoning
    (e.g., AIME, HMMT), and alignment evaluations like Arena-Hard and WritingBench.'
  context_length: 262144
  pricing:
    prompt: 7.1e-08
    completion: 4.63e-07
    image: 0.0
    request: 0.0
    currency: USD
  capabilities:
    supports_vision: false
    supports_function_calling: true
    supports_streaming: true
    modalities:
    - text
    - text->text
  metadata:
    architecture: Qwen3
  updated_at: 2025-12-19 00:46:07.739367+00:00
- model_id: switchpoint/router
  name: Switchpoint Router
  provider: openrouter
  description: "Switchpoint AI's router instantly analyzes your request and directs\
    \ it to the optimal AI from an ever-evolving library. \n\nAs the world of LLMs\
    \ advances, our router gets smarter, ensuring you always benefit from the industry's\
    \ newest models without changing your workflow.\n\nThis model is configured for\
    \ a simple, flat rate per response here on OpenRouter. It's powered by the full\
    \ routing engine from [Switchpoint AI](https://www.switchpoint.dev)."
  context_length: 131072
  pricing:
    prompt: 8.5e-07
    completion: 3.4e-06
    image: 0.0
    request: 0.0
    currency: USD
  capabilities:
    supports_vision: false
    supports_function_calling: false
    supports_streaming: true
    modalities:
    - text
    - text->text
  metadata:
    architecture: Other
  updated_at: 2025-12-19 00:46:07.739377+00:00
- model_id: moonshotai/kimi-k2:free
  name: 'MoonshotAI: Kimi K2 0711 (free)'
  provider: openrouter
  description: Kimi K2 Instruct is a large-scale Mixture-of-Experts (MoE) language
    model developed by Moonshot AI, featuring 1 trillion total parameters with 32
    billion active per forward pass. It is optimized for agentic capabilities, including
    advanced tool use, reasoning, and code synthesis. Kimi K2 excels across a broad
    range of benchmarks, particularly in coding (LiveCodeBench, SWE-bench), reasoning
    (ZebraLogic, GPQA), and tool-use (Tau2, AceBench) tasks. It supports long-context
    inference up to 128K tokens and is designed with a novel training stack that includes
    the MuonClip optimizer for stable large-scale MoE training.
  context_length: 32768
  pricing:
    prompt: 0.0
    completion: 0.0
    image: 0.0
    request: 0.0
    currency: USD
  capabilities:
    supports_vision: false
    supports_function_calling: false
    supports_streaming: true
    modalities:
    - text
    - text->text
  metadata:
    architecture: Other
  updated_at: 2025-12-19 00:46:07.739388+00:00
- model_id: moonshotai/kimi-k2
  name: 'MoonshotAI: Kimi K2 0711'
  provider: openrouter
  description: Kimi K2 Instruct is a large-scale Mixture-of-Experts (MoE) language
    model developed by Moonshot AI, featuring 1 trillion total parameters with 32
    billion active per forward pass. It is optimized for agentic capabilities, including
    advanced tool use, reasoning, and code synthesis. Kimi K2 excels across a broad
    range of benchmarks, particularly in coding (LiveCodeBench, SWE-bench), reasoning
    (ZebraLogic, GPQA), and tool-use (Tau2, AceBench) tasks. It supports long-context
    inference up to 128K tokens and is designed with a novel training stack that includes
    the MuonClip optimizer for stable large-scale MoE training.
  context_length: 131072
  pricing:
    prompt: 4.56e-07
    completion: 1.84e-06
    image: 0.0
    request: 0.0
    currency: USD
  capabilities:
    supports_vision: false
    supports_function_calling: true
    supports_streaming: true
    modalities:
    - text
    - text->text
  metadata:
    architecture: Other
  updated_at: 2025-12-19 00:46:07.739399+00:00
- model_id: thudm/glm-4.1v-9b-thinking
  name: 'THUDM: GLM 4.1V 9B Thinking'
  provider: openrouter
  description: 'GLM-4.1V-9B-Thinking is a 9B parameter vision-language model developed
    by THUDM, based on the GLM-4-9B foundation. It introduces a reasoning-centric
    "thinking paradigm" enhanced with reinforcement learning to improve multimodal
    reasoning, long-context understanding (up to 64K tokens), and complex problem
    solving. It achieves state-of-the-art performance among models in its class, outperforming
    even larger models like Qwen-2.5-VL-72B on a majority of benchmark tasks. '
  context_length: 65536
  pricing:
    prompt: 2.8e-08
    completion: 1.104e-07
    image: 0.0
    request: 0.0
    currency: USD
  capabilities:
    supports_vision: true
    supports_function_calling: false
    supports_streaming: true
    modalities:
    - text
    - image->text
  metadata:
    architecture: Other
  updated_at: 2025-12-19 00:46:07.739410+00:00
- model_id: mistralai/devstral-medium
  name: 'Mistral: Devstral Medium'
  provider: openrouter
  description: 'Devstral Medium is a high-performance code generation and agentic
    reasoning model developed jointly by Mistral AI and All Hands AI. Positioned as
    a step up from Devstral Small, it achieves 61.6% on SWE-Bench Verified, placing
    it ahead of Gemini 2.5 Pro and GPT-4.1 in code-related tasks, at a fraction of
    the cost. It is designed for generalization across prompt styles and tool use
    in code agents and frameworks.


    Devstral Medium is available via API only (not open-weight), and supports enterprise
    deployment on private infrastructure, with optional fine-tuning capabilities.'
  context_length: 131072
  pricing:
    prompt: 4.0e-07
    completion: 2.0e-06
    image: 0.0
    request: 0.0
    currency: USD
  capabilities:
    supports_vision: false
    supports_function_calling: true
    supports_streaming: true
    modalities:
    - text
    - text->text
  metadata:
    architecture: Mistral
  updated_at: 2025-12-19 00:46:07.739418+00:00
- model_id: mistralai/devstral-small
  name: 'Mistral: Devstral Small 1.1'
  provider: openrouter
  description: 'Devstral Small 1.1 is a 24B parameter open-weight language model for
    software engineering agents, developed by Mistral AI in collaboration with All
    Hands AI. Finetuned from Mistral Small 3.1 and released under the Apache 2.0 license,
    it features a 128k token context window and supports both Mistral-style function
    calling and XML output formats.


    Designed for agentic coding workflows, Devstral Small 1.1 is optimized for tasks
    such as codebase exploration, multi-file edits, and integration into autonomous
    development agents like OpenHands and Cline. It achieves 53.6% on SWE-Bench Verified,
    surpassing all other open models on this benchmark, while remaining lightweight
    enough to run on a single 4090 GPU or Apple silicon machine. The model uses a
    Tekken tokenizer with a 131k vocabulary and is deployable via vLLM, Transformers,
    Ollama, LM Studio, and other OpenAI-compatible runtimes.

    '
  context_length: 128000
  pricing:
    prompt: 7.0e-08
    completion: 2.8e-07
    image: 0.0
    request: 0.0
    currency: USD
  capabilities:
    supports_vision: false
    supports_function_calling: true
    supports_streaming: true
    modalities:
    - text
    - text->text
  metadata:
    architecture: Mistral
  updated_at: 2025-12-19 00:46:07.739428+00:00
- model_id: cognitivecomputations/dolphin-mistral-24b-venice-edition:free
  name: 'Venice: Uncensored (free)'
  provider: openrouter
  description: Venice Uncensored Dolphin Mistral 24B Venice Edition is a fine-tuned
    variant of Mistral-Small-24B-Instruct-2501, developed by dphn.ai in collaboration
    with Venice.ai. This model is designed as an “uncensored” instruct-tuned LLM,
    preserving user control over alignment, system prompts, and behavior. Intended
    for advanced and unrestricted use cases, Venice Uncensored emphasizes steerability
    and transparent behavior, removing default safety and alignment layers typically
    found in mainstream assistant models.
  context_length: 32768
  pricing:
    prompt: 0.0
    completion: 0.0
    image: 0.0
    request: 0.0
    currency: USD
  capabilities:
    supports_vision: false
    supports_function_calling: false
    supports_streaming: true
    modalities:
    - text
    - text->text
  metadata:
    architecture: Other
  updated_at: 2025-12-19 00:46:07.739440+00:00
- model_id: x-ai/grok-4
  name: 'xAI: Grok 4'
  provider: openrouter
  description: Grok 4 is xAI's latest reasoning model with a 256k context window.
    It supports parallel tool calling, structured outputs, and both image and text
    inputs. Note that reasoning is not exposed, reasoning cannot be disabled, and
    the reasoning effort cannot be specified. Pricing increases once the total tokens
    in a given request is greater than 128k tokens. See more details on the [xAI docs](https://docs.x.ai/docs/models/grok-4-0709)
  context_length: 256000
  pricing:
    prompt: 3.0e-06
    completion: 1.5e-05
    image: 0.0
    request: 0.0
    currency: USD
  capabilities:
    supports_vision: true
    supports_function_calling: true
    supports_streaming: true
    modalities:
    - text
    - image->text
  metadata:
    architecture: Grok
  updated_at: 2025-12-19 00:46:07.739449+00:00
- model_id: google/gemma-3n-e2b-it:free
  name: 'Google: Gemma 3n 2B (free)'
  provider: openrouter
  description: Gemma 3n E2B IT is a multimodal, instruction-tuned model developed
    by Google DeepMind, designed to operate efficiently at an effective parameter
    size of 2B while leveraging a 6B architecture. Based on the MatFormer architecture,
    it supports nested submodels and modular composition via the Mix-and-Match framework.
    Gemma 3n models are optimized for low-resource deployment, offering 32K context
    length and strong multilingual and reasoning performance across common benchmarks.
    This variant is trained on a diverse corpus including code, math, web, and multimodal
    data.
  context_length: 8192
  pricing:
    prompt: 0.0
    completion: 0.0
    image: 0.0
    request: 0.0
    currency: USD
  capabilities:
    supports_vision: false
    supports_function_calling: false
    supports_streaming: true
    modalities:
    - text
    - text->text
  metadata:
    architecture: Other
  updated_at: 2025-12-19 00:46:07.739457+00:00
- model_id: tencent/hunyuan-a13b-instruct
  name: 'Tencent: Hunyuan A13B Instruct'
  provider: openrouter
  description: Hunyuan-A13B is a 13B active parameter Mixture-of-Experts (MoE) language
    model developed by Tencent, with a total parameter count of 80B and support for
    reasoning via Chain-of-Thought. It offers competitive benchmark performance across
    mathematics, science, coding, and multi-turn reasoning tasks, while maintaining
    high inference efficiency via Grouped Query Attention (GQA) and quantization support
    (FP8, GPTQ, etc.).
  context_length: 131072
  pricing:
    prompt: 1.4e-07
    completion: 5.7e-07
    image: 0.0
    request: 0.0
    currency: USD
  capabilities:
    supports_vision: false
    supports_function_calling: false
    supports_streaming: true
    modalities:
    - text
    - text->text
  metadata:
    architecture: Other
  updated_at: 2025-12-19 00:46:07.739467+00:00
- model_id: tngtech/deepseek-r1t2-chimera:free
  name: 'TNG: DeepSeek R1T2 Chimera (free)'
  provider: openrouter
  description: DeepSeek-TNG-R1T2-Chimera is the second-generation Chimera model from
    TNG Tech. It is a 671 B-parameter mixture-of-experts text-generation model assembled
    from DeepSeek-AI’s R1-0528, R1, and V3-0324 checkpoints with an Assembly-of-Experts
    merge. The tri-parent design yields strong reasoning performance while running
    roughly 20 % faster than the original R1 and more than 2× faster than R1-0528
    under vLLM, giving a favorable cost-to-intelligence trade-off. The checkpoint
    supports contexts up to 60 k tokens in standard use (tested to ~130 k) and maintains
    consistent <think> token behaviour, making it suitable for long-context analysis,
    dialogue and other open-ended generation tasks.
  context_length: 163840
  pricing:
    prompt: 0.0
    completion: 0.0
    image: 0.0
    request: 0.0
    currency: USD
  capabilities:
    supports_vision: false
    supports_function_calling: false
    supports_streaming: true
    modalities:
    - text
    - text->text
  metadata:
    architecture: DeepSeek
  updated_at: 2025-12-19 00:46:07.739477+00:00
- model_id: tngtech/deepseek-r1t2-chimera
  name: 'TNG: DeepSeek R1T2 Chimera'
  provider: openrouter
  description: DeepSeek-TNG-R1T2-Chimera is the second-generation Chimera model from
    TNG Tech. It is a 671 B-parameter mixture-of-experts text-generation model assembled
    from DeepSeek-AI’s R1-0528, R1, and V3-0324 checkpoints with an Assembly-of-Experts
    merge. The tri-parent design yields strong reasoning performance while running
    roughly 20 % faster than the original R1 and more than 2× faster than R1-0528
    under vLLM, giving a favorable cost-to-intelligence trade-off. The checkpoint
    supports contexts up to 60 k tokens in standard use (tested to ~130 k) and maintains
    consistent <think> token behaviour, making it suitable for long-context analysis,
    dialogue and other open-ended generation tasks.
  context_length: 163840
  pricing:
    prompt: 3.0e-07
    completion: 1.2e-06
    image: 0.0
    request: 0.0
    currency: USD
  capabilities:
    supports_vision: false
    supports_function_calling: true
    supports_streaming: true
    modalities:
    - text
    - text->text
  metadata:
    architecture: DeepSeek
  updated_at: 2025-12-19 00:46:07.739486+00:00
- model_id: morph/morph-v3-large
  name: 'Morph: Morph V3 Large'
  provider: openrouter
  description: "Morph's high-accuracy apply model for complex code edits. ~4,500 tokens/sec\
    \ with 98% accuracy for precise code transformations.\n\nThe model requires the\
    \ prompt to be in the following format: \n<instruction>{instruction}</instruction>\n\
    <code>{initial_code}</code>\n<update>{edit_snippet}</update>\n\nZero Data Retention\
    \ is enabled for Morph. Learn more about this model in their [documentation](https://docs.morphllm.com/quickstart)"
  context_length: 262144
  pricing:
    prompt: 9.0e-07
    completion: 1.9e-06
    image: 0.0
    request: 0.0
    currency: USD
  capabilities:
    supports_vision: false
    supports_function_calling: false
    supports_streaming: true
    modalities:
    - text
    - text->text
  metadata:
    architecture: Other
  updated_at: 2025-12-19 00:46:07.739498+00:00
- model_id: morph/morph-v3-fast
  name: 'Morph: Morph V3 Fast'
  provider: openrouter
  description: "Morph's fastest apply model for code edits. ~10,500 tokens/sec with\
    \ 96% accuracy for rapid code transformations.\n\nThe model requires the prompt\
    \ to be in the following format: \n<instruction>{instruction}</instruction>\n\
    <code>{initial_code}</code>\n<update>{edit_snippet}</update>\n\nZero Data Retention\
    \ is enabled for Morph. Learn more about this model in their [documentation](https://docs.morphllm.com/quickstart)"
  context_length: 81920
  pricing:
    prompt: 8.0e-07
    completion: 1.2e-06
    image: 0.0
    request: 0.0
    currency: USD
  capabilities:
    supports_vision: false
    supports_function_calling: false
    supports_streaming: true
    modalities:
    - text
    - text->text
  metadata:
    architecture: Other
  updated_at: 2025-12-19 00:46:07.739508+00:00
- model_id: baidu/ernie-4.5-vl-424b-a47b
  name: 'Baidu: ERNIE 4.5 VL 424B A47B '
  provider: openrouter
  description: ERNIE-4.5-VL-424B-A47B is a multimodal Mixture-of-Experts (MoE) model
    from Baidu’s ERNIE 4.5 series, featuring 424B total parameters with 47B active
    per token. It is trained jointly on text and image data using a heterogeneous
    MoE architecture and modality-isolated routing to enable high-fidelity cross-modal
    reasoning, image understanding, and long-context generation (up to 131k tokens).
    Fine-tuned with techniques like SFT, DPO, UPO, and RLVR, this model supports both
    “thinking” and non-thinking inference modes. Designed for vision-language tasks
    in English and Chinese, it is optimized for efficient scaling and can operate
    under 4-bit/8-bit quantization.
  context_length: 123000
  pricing:
    prompt: 3.36e-07
    completion: 1.0e-06
    image: 0.0
    request: 0.0
    currency: USD
  capabilities:
    supports_vision: true
    supports_function_calling: false
    supports_streaming: true
    modalities:
    - text
    - image->text
  metadata:
    architecture: Other
  updated_at: 2025-12-19 00:46:07.739516+00:00
- model_id: baidu/ernie-4.5-300b-a47b
  name: 'Baidu: ERNIE 4.5 300B A47B '
  provider: openrouter
  description: ERNIE-4.5-300B-A47B is a 300B parameter Mixture-of-Experts (MoE) language
    model developed by Baidu as part of the ERNIE 4.5 series. It activates 47B parameters
    per token and supports text generation in both English and Chinese. Optimized
    for high-throughput inference and efficient scaling, it uses a heterogeneous MoE
    structure with advanced routing and quantization strategies, including FP8 and
    2-bit formats. This version is fine-tuned for language-only tasks and supports
    reasoning, tool parameters, and extended context lengths up to 131k tokens. Suitable
    for general-purpose LLM applications with high reasoning and throughput demands.
  context_length: 123000
  pricing:
    prompt: 2.24e-07
    completion: 8.8e-07
    image: 0.0
    request: 0.0
    currency: USD
  capabilities:
    supports_vision: false
    supports_function_calling: false
    supports_streaming: true
    modalities:
    - text
    - text->text
  metadata:
    architecture: Other
  updated_at: 2025-12-19 00:46:07.739524+00:00
- model_id: inception/mercury
  name: 'Inception: Mercury'
  provider: openrouter
  description: 'Mercury is the first diffusion large language model (dLLM). Applying
    a breakthrough discrete diffusion approach, the model runs 5-10x faster than even
    speed optimized models like GPT-4.1 Nano and Claude 3.5 Haiku while matching their
    performance. Mercury''s speed enables developers to provide responsive user experiences,
    including with voice agents, search interfaces, and chatbots. Read more in the
    [blog post]

    (https://www.inceptionlabs.ai/blog/introducing-mercury) here. '
  context_length: 128000
  pricing:
    prompt: 2.5e-07
    completion: 1.0e-06
    image: 0.0
    request: 0.0
    currency: USD
  capabilities:
    supports_vision: false
    supports_function_calling: true
    supports_streaming: true
    modalities:
    - text
    - text->text
  metadata:
    architecture: Other
  updated_at: 2025-12-19 00:46:07.739533+00:00
- model_id: mistralai/mistral-small-3.2-24b-instruct
  name: 'Mistral: Mistral Small 3.2 24B'
  provider: openrouter
  description: 'Mistral-Small-3.2-24B-Instruct-2506 is an updated 24B parameter model
    from Mistral optimized for instruction following, repetition reduction, and improved
    function calling. Compared to the 3.1 release, version 3.2 significantly improves
    accuracy on WildBench and Arena Hard, reduces infinite generations, and delivers
    gains in tool use and structured output tasks.


    It supports image and text inputs with structured outputs, function/tool calling,
    and strong performance across coding (HumanEval+, MBPP), STEM (MMLU, MATH, GPQA),
    and vision benchmarks (ChartQA, DocVQA).'
  context_length: 131072
  pricing:
    prompt: 6.0e-08
    completion: 1.8e-07
    image: 0.0
    request: 0.0
    currency: USD
  capabilities:
    supports_vision: true
    supports_function_calling: true
    supports_streaming: true
    modalities:
    - text
    - image->text
  metadata:
    architecture: Mistral
  updated_at: 2025-12-19 00:46:07.739543+00:00
- model_id: minimax/minimax-m1
  name: 'MiniMax: MiniMax M1'
  provider: openrouter
  description: 'MiniMax-M1 is a large-scale, open-weight reasoning model designed
    for extended context and high-efficiency inference. It leverages a hybrid Mixture-of-Experts
    (MoE) architecture paired with a custom "lightning attention" mechanism, allowing
    it to process long sequences—up to 1 million tokens—while maintaining competitive
    FLOP efficiency. With 456 billion total parameters and 45.9B active per token,
    this variant is optimized for complex, multi-step reasoning tasks.


    Trained via a custom reinforcement learning pipeline (CISPO), M1 excels in long-context
    understanding, software engineering, agentic tool use, and mathematical reasoning.
    Benchmarks show strong performance across FullStackBench, SWE-bench, MATH, GPQA,
    and TAU-Bench, often outperforming other open models like DeepSeek R1 and Qwen3-235B.'
  context_length: 1000000
  pricing:
    prompt: 4.0e-07
    completion: 2.2e-06
    image: 0.0
    request: 0.0
    currency: USD
  capabilities:
    supports_vision: false
    supports_function_calling: true
    supports_streaming: true
    modalities:
    - text
    - text->text
  metadata:
    architecture: Other
  updated_at: 2025-12-19 00:46:07.739553+00:00
- model_id: google/gemini-2.5-flash
  name: 'Google: Gemini 2.5 Flash'
  provider: openrouter
  description: "Gemini 2.5 Flash is Google's state-of-the-art workhorse model, specifically\
    \ designed for advanced reasoning, coding, mathematics, and scientific tasks.\
    \ It includes built-in \"thinking\" capabilities, enabling it to provide responses\
    \ with greater accuracy and nuanced context handling. \n\nAdditionally, Gemini\
    \ 2.5 Flash is configurable through the \"max tokens for reasoning\" parameter,\
    \ as described in the documentation (https://openrouter.ai/docs/use-cases/reasoning-tokens#max-tokens-for-reasoning)."
  context_length: 1048576
  pricing:
    prompt: 3.0e-07
    completion: 2.5e-06
    image: 0.001238
    request: 0.0
    currency: USD
  capabilities:
    supports_vision: true
    supports_function_calling: true
    supports_streaming: true
    modalities:
    - text
    - image->text
  metadata:
    architecture: Gemini
  updated_at: 2025-12-19 00:46:07.739564+00:00
- model_id: google/gemini-2.5-pro
  name: 'Google: Gemini 2.5 Pro'
  provider: openrouter
  description: Gemini 2.5 Pro is Google’s state-of-the-art AI model designed for advanced
    reasoning, coding, mathematics, and scientific tasks. It employs “thinking” capabilities,
    enabling it to reason through responses with enhanced accuracy and nuanced context
    handling. Gemini 2.5 Pro achieves top-tier performance on multiple benchmarks,
    including first-place positioning on the LMArena leaderboard, reflecting superior
    human-preference alignment and complex problem-solving abilities.
  context_length: 1048576
  pricing:
    prompt: 1.25e-06
    completion: 1.0e-05
    image: 0.00516
    request: 0.0
    currency: USD
  capabilities:
    supports_vision: true
    supports_function_calling: true
    supports_streaming: true
    modalities:
    - text
    - image->text
  metadata:
    architecture: Gemini
  updated_at: 2025-12-19 00:46:07.739575+00:00
- model_id: moonshotai/kimi-dev-72b
  name: 'MoonshotAI: Kimi Dev 72B'
  provider: openrouter
  description: Kimi-Dev-72B is an open-source large language model fine-tuned for
    software engineering and issue resolution tasks. Based on Qwen2.5-72B, it is optimized
    using large-scale reinforcement learning that applies code patches in real repositories
    and validates them via full test suite execution—rewarding only correct, robust
    completions. The model achieves 60.4% on SWE-bench Verified, setting a new benchmark
    among open-source models for software bug fixing and code reasoning.
  context_length: 131072
  pricing:
    prompt: 2.9e-07
    completion: 1.15e-06
    image: 0.0
    request: 0.0
    currency: USD
  capabilities:
    supports_vision: false
    supports_function_calling: false
    supports_streaming: true
    modalities:
    - text
    - text->text
  metadata:
    architecture: Other
  updated_at: 2025-12-19 00:46:07.739585+00:00
- model_id: openai/o3-pro
  name: 'OpenAI: o3 Pro'
  provider: openrouter
  description: 'The o-series of models are trained with reinforcement learning to
    think before they answer and perform complex reasoning. The o3-pro model uses
    more compute to think harder and provide consistently better answers.


    Note that BYOK is required for this model. Set up here: https://openrouter.ai/settings/integrations'
  context_length: 200000
  pricing:
    prompt: 2.0e-05
    completion: 8.0e-05
    image: 0.0153
    request: 0.0
    currency: USD
  capabilities:
    supports_vision: true
    supports_function_calling: true
    supports_streaming: true
    modalities:
    - text
    - image->text
  metadata:
    architecture: GPT
  updated_at: 2025-12-19 00:46:07.739595+00:00
- model_id: x-ai/grok-3-mini
  name: 'xAI: Grok 3 Mini'
  provider: openrouter
  description: A lightweight model that thinks before responding. Fast, smart, and
    great for logic-based tasks that do not require deep domain knowledge. The raw
    thinking traces are accessible.
  context_length: 131072
  pricing:
    prompt: 3.0e-07
    completion: 5.0e-07
    image: 0.0
    request: 0.0
    currency: USD
  capabilities:
    supports_vision: false
    supports_function_calling: true
    supports_streaming: true
    modalities:
    - text
    - text->text
  metadata:
    architecture: Grok
  updated_at: 2025-12-19 00:46:07.739606+00:00
- model_id: x-ai/grok-3
  name: 'xAI: Grok 3'
  provider: openrouter
  description: 'Grok 3 is the latest model from xAI. It''s their flagship model that
    excels at enterprise use cases like data extraction, coding, and text summarization.
    Possesses deep domain knowledge in finance, healthcare, law, and science.


    '
  context_length: 131072
  pricing:
    prompt: 3.0e-06
    completion: 1.5e-05
    image: 0.0
    request: 0.0
    currency: USD
  capabilities:
    supports_vision: false
    supports_function_calling: true
    supports_streaming: true
    modalities:
    - text
    - text->text
  metadata:
    architecture: Grok
  updated_at: 2025-12-19 00:46:07.739620+00:00
- model_id: google/gemini-2.5-pro-preview
  name: 'Google: Gemini 2.5 Pro Preview 06-05'
  provider: openrouter
  description: 'Gemini 2.5 Pro is Google’s state-of-the-art AI model designed for
    advanced reasoning, coding, mathematics, and scientific tasks. It employs “thinking”
    capabilities, enabling it to reason through responses with enhanced accuracy and
    nuanced context handling. Gemini 2.5 Pro achieves top-tier performance on multiple
    benchmarks, including first-place positioning on the LMArena leaderboard, reflecting
    superior human-preference alignment and complex problem-solving abilities.

    '
  context_length: 1048576
  pricing:
    prompt: 1.25e-06
    completion: 1.0e-05
    image: 0.00516
    request: 0.0
    currency: USD
  capabilities:
    supports_vision: true
    supports_function_calling: true
    supports_streaming: true
    modalities:
    - text
    - image->text
  metadata:
    architecture: Gemini
  updated_at: 2025-12-19 00:46:07.739630+00:00
- model_id: deepseek/deepseek-r1-0528-qwen3-8b
  name: 'DeepSeek: DeepSeek R1 0528 Qwen3 8B'
  provider: openrouter
  description: 'DeepSeek-R1-0528 is a lightly upgraded release of DeepSeek R1 that
    taps more compute and smarter post-training tricks, pushing its reasoning and
    inference to the brink of flagship models like O3 and Gemini 2.5 Pro.

    It now tops math, programming, and logic leaderboards, showcasing a step-change
    in depth-of-thought.

    The distilled variant, DeepSeek-R1-0528-Qwen3-8B, transfers this chain-of-thought
    into an 8 B-parameter form, beating standard Qwen3 8B by +10 pp and tying the
    235 B “thinking” giant on AIME 2024.'
  context_length: 32768
  pricing:
    prompt: 2.0e-08
    completion: 1.0e-07
    image: 0.0
    request: 0.0
    currency: USD
  capabilities:
    supports_vision: false
    supports_function_calling: false
    supports_streaming: true
    modalities:
    - text
    - text->text
  metadata:
    architecture: Qwen
  updated_at: 2025-12-19 00:46:07.739641+00:00
- model_id: deepseek/deepseek-r1-0528:free
  name: 'DeepSeek: R1 0528 (free)'
  provider: openrouter
  description: 'May 28th update to the [original DeepSeek R1](/deepseek/deepseek-r1)
    Performance on par with [OpenAI o1](/openai/o1), but open-sourced and with fully
    open reasoning tokens. It''s 671B parameters in size, with 37B active in an inference
    pass.


    Fully open-source model.'
  context_length: 163840
  pricing:
    prompt: 0.0
    completion: 0.0
    image: 0.0
    request: 0.0
    currency: USD
  capabilities:
    supports_vision: false
    supports_function_calling: false
    supports_streaming: true
    modalities:
    - text
    - text->text
  metadata:
    architecture: DeepSeek
  updated_at: 2025-12-19 00:46:07.739649+00:00
- model_id: deepseek/deepseek-r1-0528
  name: 'DeepSeek: R1 0528'
  provider: openrouter
  description: 'May 28th update to the [original DeepSeek R1](/deepseek/deepseek-r1)
    Performance on par with [OpenAI o1](/openai/o1), but open-sourced and with fully
    open reasoning tokens. It''s 671B parameters in size, with 37B active in an inference
    pass.


    Fully open-source model.'
  context_length: 163840
  pricing:
    prompt: 4.0e-07
    completion: 1.75e-06
    image: 0.0
    request: 0.0
    currency: USD
  capabilities:
    supports_vision: false
    supports_function_calling: true
    supports_streaming: true
    modalities:
    - text
    - text->text
  metadata:
    architecture: DeepSeek
  updated_at: 2025-12-19 00:46:07.739658+00:00
- model_id: anthropic/claude-opus-4
  name: 'Anthropic: Claude Opus 4'
  provider: openrouter
  description: "Claude Opus 4 is benchmarked as the world’s best coding model, at\
    \ time of release, bringing sustained performance on complex, long-running tasks\
    \ and agent workflows. It sets new benchmarks in software engineering, achieving\
    \ leading results on SWE-bench (72.5%) and Terminal-bench (43.2%). Opus 4 supports\
    \ extended, agentic workflows, handling thousands of task steps continuously for\
    \ hours without degradation. \n\nRead more at the [blog post here](https://www.anthropic.com/news/claude-4)"
  context_length: 200000
  pricing:
    prompt: 1.5e-05
    completion: 7.5e-05
    image: 0.024
    request: 0.0
    currency: USD
  capabilities:
    supports_vision: true
    supports_function_calling: true
    supports_streaming: true
    modalities:
    - text
    - image->text
  metadata:
    architecture: Claude
  updated_at: 2025-12-19 00:46:07.739668+00:00
- model_id: anthropic/claude-sonnet-4
  name: 'Anthropic: Claude Sonnet 4'
  provider: openrouter
  description: 'Claude Sonnet 4 significantly enhances the capabilities of its predecessor,
    Sonnet 3.7, excelling in both coding and reasoning tasks with improved precision
    and controllability. Achieving state-of-the-art performance on SWE-bench (72.7%),
    Sonnet 4 balances capability and computational efficiency, making it suitable
    for a broad range of applications from routine coding tasks to complex software
    development projects. Key enhancements include improved autonomous codebase navigation,
    reduced error rates in agent-driven workflows, and increased reliability in following
    intricate instructions. Sonnet 4 is optimized for practical everyday use, providing
    advanced reasoning capabilities while maintaining efficiency and responsiveness
    in diverse internal and external scenarios.


    Read more at the [blog post here](https://www.anthropic.com/news/claude-4)'
  context_length: 1000000
  pricing:
    prompt: 3.0e-06
    completion: 1.5e-05
    image: 0.0048
    request: 0.0
    currency: USD
  capabilities:
    supports_vision: true
    supports_function_calling: true
    supports_streaming: true
    modalities:
    - text
    - image->text
  metadata:
    architecture: Claude
  updated_at: 2025-12-19 00:46:07.739679+00:00
- model_id: mistralai/devstral-small-2505
  name: 'Mistral: Devstral Small 2505'
  provider: openrouter
  description: 'Devstral-Small-2505 is a 24B parameter agentic LLM fine-tuned from
    Mistral-Small-3.1, jointly developed by Mistral AI and All Hands AI for advanced
    software engineering tasks. It is optimized for codebase exploration, multi-file
    editing, and integration into coding agents, achieving state-of-the-art results
    on SWE-Bench Verified (46.8%).


    Devstral supports a 128k context window and uses a custom Tekken tokenizer. It
    is text-only, with the vision encoder removed, and is suitable for local deployment
    on high-end consumer hardware (e.g., RTX 4090, 32GB RAM Macs). Devstral is best
    used in agentic workflows via the OpenHands scaffold and is compatible with inference
    frameworks like vLLM, Transformers, and Ollama. It is released under the Apache
    2.0 license.'
  context_length: 128000
  pricing:
    prompt: 6.0e-08
    completion: 1.2e-07
    image: 0.0
    request: 0.0
    currency: USD
  capabilities:
    supports_vision: false
    supports_function_calling: false
    supports_streaming: true
    modalities:
    - text
    - text->text
  metadata:
    architecture: Mistral
  updated_at: 2025-12-19 00:46:07.739690+00:00
- model_id: google/gemma-3n-e4b-it:free
  name: 'Google: Gemma 3n 4B (free)'
  provider: openrouter
  description: 'Gemma 3n E4B-it is optimized for efficient execution on mobile and
    low-resource devices, such as phones, laptops, and tablets. It supports multimodal
    inputs—including text, visual data, and audio—enabling diverse tasks such as text
    generation, speech recognition, translation, and image analysis. Leveraging innovations
    like Per-Layer Embedding (PLE) caching and the MatFormer architecture, Gemma 3n
    dynamically manages memory usage and computational load by selectively activating
    model parameters, significantly reducing runtime resource requirements.


    This model supports a wide linguistic range (trained in over 140 languages) and
    features a flexible 32K token context window. Gemma 3n can selectively load parameters,
    optimizing memory and computational efficiency based on the task or device capabilities,
    making it well-suited for privacy-focused, offline-capable applications and on-device
    AI solutions. [Read more in the blog post](https://developers.googleblog.com/en/introducing-gemma-3n/)'
  context_length: 8192
  pricing:
    prompt: 0.0
    completion: 0.0
    image: 0.0
    request: 0.0
    currency: USD
  capabilities:
    supports_vision: false
    supports_function_calling: false
    supports_streaming: true
    modalities:
    - text
    - text->text
  metadata:
    architecture: Other
  updated_at: 2025-12-19 00:46:07.739700+00:00
- model_id: google/gemma-3n-e4b-it
  name: 'Google: Gemma 3n 4B'
  provider: openrouter
  description: 'Gemma 3n E4B-it is optimized for efficient execution on mobile and
    low-resource devices, such as phones, laptops, and tablets. It supports multimodal
    inputs—including text, visual data, and audio—enabling diverse tasks such as text
    generation, speech recognition, translation, and image analysis. Leveraging innovations
    like Per-Layer Embedding (PLE) caching and the MatFormer architecture, Gemma 3n
    dynamically manages memory usage and computational load by selectively activating
    model parameters, significantly reducing runtime resource requirements.


    This model supports a wide linguistic range (trained in over 140 languages) and
    features a flexible 32K token context window. Gemma 3n can selectively load parameters,
    optimizing memory and computational efficiency based on the task or device capabilities,
    making it well-suited for privacy-focused, offline-capable applications and on-device
    AI solutions. [Read more in the blog post](https://developers.googleblog.com/en/introducing-gemma-3n/)'
  context_length: 32768
  pricing:
    prompt: 2.0e-08
    completion: 4.0e-08
    image: 0.0
    request: 0.0
    currency: USD
  capabilities:
    supports_vision: false
    supports_function_calling: false
    supports_streaming: true
    modalities:
    - text
    - text->text
  metadata:
    architecture: Other
  updated_at: 2025-12-19 00:46:07.739710+00:00
- model_id: openai/codex-mini
  name: 'OpenAI: Codex Mini'
  provider: openrouter
  description: codex-mini-latest is a fine-tuned version of o4-mini specifically for
    use in Codex CLI. For direct use in the API, we recommend starting with gpt-4.1.
  context_length: 200000
  pricing:
    prompt: 1.5e-06
    completion: 6.0e-06
    image: 0.0
    request: 0.0
    currency: USD
  capabilities:
    supports_vision: true
    supports_function_calling: true
    supports_streaming: true
    modalities:
    - text
    - image->text
  metadata:
    architecture: GPT
  updated_at: 2025-12-19 00:46:07.739718+00:00
- model_id: nousresearch/deephermes-3-mistral-24b-preview
  name: 'Nous: DeepHermes 3 Mistral 24B Preview'
  provider: openrouter
  description: "DeepHermes 3 (Mistral 24B Preview) is an instruction-tuned language\
    \ model by Nous Research based on Mistral-Small-24B, designed for chat, function\
    \ calling, and advanced multi-turn reasoning. It introduces a dual-mode system\
    \ that toggles between intuitive chat responses and structured “deep reasoning”\
    \ mode using special system prompts. Fine-tuned via distillation from R1, it supports\
    \ structured output (JSON mode) and function call syntax for agent-based applications.\n\
    \nDeepHermes 3 supports a **reasoning toggle via system prompt**, allowing users\
    \ to switch between fast, intuitive responses and deliberate, multi-step reasoning.\
    \ When activated with the following specific system instruction, the model enters\
    \ a *\"deep thinking\"* mode—generating extended chains of thought wrapped in\
    \ `<think></think>` tags before delivering a final answer. \n\nSystem Prompt:\
    \ You are a deep thinking AI, you may use extremely long chains of thought to\
    \ deeply consider the problem and deliberate with yourself via systematic reasoning\
    \ processes to help come to a correct solution prior to answering. You should\
    \ enclose your thoughts and internal monologue inside <think> </think> tags, and\
    \ then provide your solution or response to the problem.\n"
  context_length: 32768
  pricing:
    prompt: 2.0e-08
    completion: 1.0e-07
    image: 0.0
    request: 0.0
    currency: USD
  capabilities:
    supports_vision: false
    supports_function_calling: true
    supports_streaming: true
    modalities:
    - text
    - text->text
  metadata:
    architecture: Other
  updated_at: 2025-12-19 00:46:07.739726+00:00
- model_id: mistralai/mistral-medium-3
  name: 'Mistral: Mistral Medium 3'
  provider: openrouter
  description: 'Mistral Medium 3 is a high-performance enterprise-grade language model
    designed to deliver frontier-level capabilities at significantly reduced operational
    cost. It balances state-of-the-art reasoning and multimodal performance with 8×
    lower cost compared to traditional large models, making it suitable for scalable
    deployments across professional and industrial use cases.


    The model excels in domains such as coding, STEM reasoning, and enterprise adaptation.
    It supports hybrid, on-prem, and in-VPC deployments and is optimized for integration
    into custom workflows. Mistral Medium 3 offers competitive accuracy relative to
    larger models like Claude Sonnet 3.5/3.7, Llama 4 Maverick, and Command R+, while
    maintaining broad compatibility across cloud environments.'
  context_length: 131072
  pricing:
    prompt: 4.0e-07
    completion: 2.0e-06
    image: 0.0
    request: 0.0
    currency: USD
  capabilities:
    supports_vision: true
    supports_function_calling: true
    supports_streaming: true
    modalities:
    - text
    - image->text
  metadata:
    architecture: Mistral
  updated_at: 2025-12-19 00:46:07.739740+00:00
- model_id: google/gemini-2.5-pro-preview-05-06
  name: 'Google: Gemini 2.5 Pro Preview 05-06'
  provider: openrouter
  description: Gemini 2.5 Pro is Google’s state-of-the-art AI model designed for advanced
    reasoning, coding, mathematics, and scientific tasks. It employs “thinking” capabilities,
    enabling it to reason through responses with enhanced accuracy and nuanced context
    handling. Gemini 2.5 Pro achieves top-tier performance on multiple benchmarks,
    including first-place positioning on the LMArena leaderboard, reflecting superior
    human-preference alignment and complex problem-solving abilities.
  context_length: 1048576
  pricing:
    prompt: 1.25e-06
    completion: 1.0e-05
    image: 0.00516
    request: 0.0
    currency: USD
  capabilities:
    supports_vision: true
    supports_function_calling: true
    supports_streaming: true
    modalities:
    - text
    - image->text
  metadata:
    architecture: Gemini
  updated_at: 2025-12-19 00:46:07.739795+00:00
- model_id: arcee-ai/spotlight
  name: 'Arcee AI: Spotlight'
  provider: openrouter
  description: 'Spotlight is a 7‑billion‑parameter vision‑language model derived from
    Qwen 2.5‑VL and fine‑tuned by Arcee AI for tight image‑text grounding tasks. It
    offers a 32 k‑token context window, enabling rich multimodal conversations that
    combine lengthy documents with one or more images. Training emphasized fast inference
    on consumer GPUs while retaining strong captioning, visual‐question‑answering,
    and diagram‑analysis accuracy. As a result, Spotlight slots neatly into agent
    workflows where screenshots, charts or UI mock‑ups need to be interpreted on the
    fly. Early benchmarks show it matching or out‑scoring larger VLMs such as LLaVA‑1.6
    13 B on popular VQA and POPE alignment tests. '
  context_length: 131072
  pricing:
    prompt: 1.8e-07
    completion: 1.8e-07
    image: 0.0
    request: 0.0
    currency: USD
  capabilities:
    supports_vision: true
    supports_function_calling: false
    supports_streaming: true
    modalities:
    - text
    - image->text
  metadata:
    architecture: Other
  updated_at: 2025-12-19 00:46:07.739806+00:00
- model_id: arcee-ai/maestro-reasoning
  name: 'Arcee AI: Maestro Reasoning'
  provider: openrouter
  description: 'Maestro Reasoning is Arcee''s flagship analysis model: a 32 B‑parameter
    derivative of Qwen 2.5‑32 B tuned with DPO and chain‑of‑thought RL for step‑by‑step
    logic. Compared to the earlier 7 B preview, the production 32 B release widens
    the context window to 128 k tokens and doubles pass‑rate on MATH and GSM‑8K, while
    also lifting code completion accuracy. Its instruction style encourages structured
    "thought → answer" traces that can be parsed or hidden according to user preference.
    That transparency pairs well with audit‑focused industries like finance or healthcare
    where seeing the reasoning path matters. In Arcee Conductor, Maestro is automatically
    selected for complex, multi‑constraint queries that smaller SLMs bounce. '
  context_length: 131072
  pricing:
    prompt: 9.0e-07
    completion: 3.3e-06
    image: 0.0
    request: 0.0
    currency: USD
  capabilities:
    supports_vision: false
    supports_function_calling: false
    supports_streaming: true
    modalities:
    - text
    - text->text
  metadata:
    architecture: Other
  updated_at: 2025-12-19 00:46:07.739815+00:00
- model_id: arcee-ai/virtuoso-large
  name: 'Arcee AI: Virtuoso Large'
  provider: openrouter
  description: Virtuoso‑Large is Arcee's top‑tier general‑purpose LLM at 72 B parameters,
    tuned to tackle cross‑domain reasoning, creative writing and enterprise QA. Unlike
    many 70 B peers, it retains the 128 k context inherited from Qwen 2.5, letting
    it ingest books, codebases or financial filings wholesale. Training blended DeepSeek R1
    distillation, multi‑epoch supervised fine‑tuning and a final DPO/RLHF alignment
    stage, yielding strong performance on BIG‑Bench‑Hard, GSM‑8K and long‑context
    Needle‑In‑Haystack tests. Enterprises use Virtuoso‑Large as the "fallback" brain
    in Conductor pipelines when other SLMs flag low confidence. Despite its size,
    aggressive KV‑cache optimizations keep first‑token latency in the low‑second range
    on 8× H100 nodes, making it a practical production‑grade powerhouse.
  context_length: 131072
  pricing:
    prompt: 7.5e-07
    completion: 1.2e-06
    image: 0.0
    request: 0.0
    currency: USD
  capabilities:
    supports_vision: false
    supports_function_calling: true
    supports_streaming: true
    modalities:
    - text
    - text->text
  metadata:
    architecture: Other
  updated_at: 2025-12-19 00:46:07.739824+00:00
- model_id: arcee-ai/coder-large
  name: 'Arcee AI: Coder Large'
  provider: openrouter
  description: 'Coder‑Large is a 32 B‑parameter offspring of Qwen 2.5‑Instruct that
    has been further trained on permissively‑licensed GitHub, CodeSearchNet and synthetic
    bug‑fix corpora. It supports a 32k context window, enabling multi‑file refactoring
    or long diff review in a single call, and understands 30‑plus programming languages
    with special attention to TypeScript, Go and Terraform. Internal benchmarks show
    5–8 pt gains over CodeLlama‑34 B‑Python on HumanEval and competitive BugFix scores
    thanks to a reinforcement pass that rewards compilable output. The model emits
    structured explanations alongside code blocks by default, making it suitable for
    educational tooling as well as production copilot scenarios. Cost‑wise, Together
    AI prices it well below proprietary incumbents, so teams can scale interactive
    coding without runaway spend. '
  context_length: 32768
  pricing:
    prompt: 5.0e-07
    completion: 8.0e-07
    image: 0.0
    request: 0.0
    currency: USD
  capabilities:
    supports_vision: false
    supports_function_calling: false
    supports_streaming: true
    modalities:
    - text
    - text->text
  metadata:
    architecture: Other
  updated_at: 2025-12-19 00:46:07.739838+00:00
- model_id: microsoft/phi-4-reasoning-plus
  name: 'Microsoft: Phi 4 Reasoning Plus'
  provider: openrouter
  description: 'Phi-4-reasoning-plus is an enhanced 14B parameter model from Microsoft,
    fine-tuned from Phi-4 with additional reinforcement learning to boost accuracy
    on math, science, and code reasoning tasks. It uses the same dense decoder-only
    transformer architecture as Phi-4, but generates longer, more comprehensive outputs
    structured into a step-by-step reasoning trace and final answer.


    While it offers improved benchmark scores over Phi-4-reasoning across tasks like
    AIME, OmniMath, and HumanEvalPlus, its responses are typically ~50% longer, resulting
    in higher latency. Designed for English-only applications, it is well-suited for
    structured reasoning workflows where output quality takes priority over response
    speed.'
  context_length: 32768
  pricing:
    prompt: 7.0e-08
    completion: 3.5e-07
    image: 0.0
    request: 0.0
    currency: USD
  capabilities:
    supports_vision: false
    supports_function_calling: false
    supports_streaming: true
    modalities:
    - text
    - text->text
  metadata:
    architecture: Other
  updated_at: 2025-12-19 00:46:07.739852+00:00
- model_id: inception/mercury-coder
  name: 'Inception: Mercury Coder'
  provider: openrouter
  description: Mercury Coder is the first diffusion large language model (dLLM). Applying
    a breakthrough discrete diffusion approach, the model runs 5-10x faster than even
    speed optimized models like Claude 3.5 Haiku and GPT-4o Mini while matching their
    performance. Mercury Coder's speed means that developers can stay in the flow
    while coding, enjoying rapid chat-based iteration and responsive code completion
    suggestions. On Copilot Arena, Mercury Coder ranks 1st in speed and ties for 2nd
    in quality. Read more in the [blog post here](https://www.inceptionlabs.ai/blog/introducing-mercury).
  context_length: 128000
  pricing:
    prompt: 2.5e-07
    completion: 1.0e-06
    image: 0.0
    request: 0.0
    currency: USD
  capabilities:
    supports_vision: false
    supports_function_calling: true
    supports_streaming: true
    modalities:
    - text
    - text->text
  metadata:
    architecture: Other
  updated_at: 2025-12-19 00:46:07.739860+00:00
- model_id: qwen/qwen3-4b:free
  name: 'Qwen: Qwen3 4B (free)'
  provider: openrouter
  description: Qwen3-4B is a 4 billion parameter dense language model from the Qwen3
    series, designed to support both general-purpose and reasoning-intensive tasks.
    It introduces a dual-mode architecture—thinking and non-thinking—allowing dynamic
    switching between high-precision logical reasoning and efficient dialogue generation.
    This makes it well-suited for multi-turn chat, instruction following, and complex
    agent workflows.
  context_length: 40960
  pricing:
    prompt: 0.0
    completion: 0.0
    image: 0.0
    request: 0.0
    currency: USD
  capabilities:
    supports_vision: false
    supports_function_calling: true
    supports_streaming: true
    modalities:
    - text
    - text->text
  metadata:
    architecture: Qwen3
  updated_at: 2025-12-19 00:46:07.739870+00:00
- model_id: deepseek/deepseek-prover-v2
  name: 'DeepSeek: DeepSeek Prover V2'
  provider: openrouter
  description: DeepSeek Prover V2 is a 671B parameter model, speculated to be geared
    towards logic and mathematics. Likely an upgrade from [DeepSeek-Prover-V1.5](https://huggingface.co/deepseek-ai/DeepSeek-Prover-V1.5-RL)
    Not much is known about the model yet, as DeepSeek released it on Hugging Face
    without an announcement or description.
  context_length: 163840
  pricing:
    prompt: 5.0e-07
    completion: 2.18e-06
    image: 0.0
    request: 0.0
    currency: USD
  capabilities:
    supports_vision: false
    supports_function_calling: false
    supports_streaming: true
    modalities:
    - text
    - text->text
  metadata:
    architecture: DeepSeek
  updated_at: 2025-12-19 00:46:07.739879+00:00
- model_id: meta-llama/llama-guard-4-12b
  name: 'Meta: Llama Guard 4 12B'
  provider: openrouter
  description: 'Llama Guard 4 is a Llama 4 Scout-derived multimodal pretrained model,
    fine-tuned for content safety classification. Similar to previous versions, it
    can be used to classify content in both LLM inputs (prompt classification) and
    in LLM responses (response classification). It acts as an LLM—generating text
    in its output that indicates whether a given prompt or response is safe or unsafe,
    and if unsafe, it also lists the content categories violated.


    Llama Guard 4 was aligned to safeguard against the standardized MLCommons hazards
    taxonomy and designed to support multimodal Llama 4 capabilities. Specifically,
    it combines features from previous Llama Guard models, providing content moderation
    for English and multiple supported languages, along with enhanced capabilities
    to handle mixed text-and-image prompts, including multiple images. Additionally,
    Llama Guard 4 is integrated into the Llama Moderations API, extending robust safety
    classification to text and images.'
  context_length: 163840
  pricing:
    prompt: 1.8e-07
    completion: 1.8e-07
    image: 0.0
    request: 0.0
    currency: USD
  capabilities:
    supports_vision: true
    supports_function_calling: false
    supports_streaming: true
    modalities:
    - text
    - image->text
  metadata:
    architecture: Other
  updated_at: 2025-12-19 00:46:07.739887+00:00
- model_id: qwen/qwen3-30b-a3b
  name: 'Qwen: Qwen3 30B A3B'
  provider: openrouter
  description: 'Qwen3, the latest generation in the Qwen large language model series,
    features both dense and mixture-of-experts (MoE) architectures to excel in reasoning,
    multilingual support, and advanced agent tasks. Its unique ability to switch seamlessly
    between a thinking mode for complex reasoning and a non-thinking mode for efficient
    dialogue ensures versatile, high-quality performance.


    Significantly outperforming prior models like QwQ and Qwen2.5, Qwen3 delivers
    superior mathematics, coding, commonsense reasoning, creative writing, and interactive
    dialogue capabilities. The Qwen3-30B-A3B variant includes 30.5 billion parameters
    (3.3 billion activated), 48 layers, 128 experts (8 activated per task), and supports
    up to 131K token contexts with YaRN, setting a new standard among open-source
    models.'
  context_length: 40960
  pricing:
    prompt: 6.0e-08
    completion: 2.2e-07
    image: 0.0
    request: 0.0
    currency: USD
  capabilities:
    supports_vision: false
    supports_function_calling: true
    supports_streaming: true
    modalities:
    - text
    - text->text
  metadata:
    architecture: Qwen3
  updated_at: 2025-12-19 00:46:07.739895+00:00
- model_id: qwen/qwen3-8b
  name: 'Qwen: Qwen3 8B'
  provider: openrouter
  description: Qwen3-8B is a dense 8.2B parameter causal language model from the Qwen3
    series, designed for both reasoning-heavy tasks and efficient dialogue. It supports
    seamless switching between "thinking" mode for math, coding, and logical inference,
    and "non-thinking" mode for general conversation. The model is fine-tuned for
    instruction-following, agent integration, creative writing, and multilingual use
    across 100+ languages and dialects. It natively supports a 32K token context window
    and can extend to 131K tokens with YaRN scaling.
  context_length: 128000
  pricing:
    prompt: 2.8e-08
    completion: 1.104e-07
    image: 0.0
    request: 0.0
    currency: USD
  capabilities:
    supports_vision: false
    supports_function_calling: true
    supports_streaming: true
    modalities:
    - text
    - text->text
  metadata:
    architecture: Qwen3
  updated_at: 2025-12-19 00:46:07.739907+00:00
- model_id: qwen/qwen3-14b
  name: 'Qwen: Qwen3 14B'
  provider: openrouter
  description: Qwen3-14B is a dense 14.8B parameter causal language model from the
    Qwen3 series, designed for both complex reasoning and efficient dialogue. It supports
    seamless switching between a "thinking" mode for tasks like math, programming,
    and logical inference, and a "non-thinking" mode for general-purpose conversation.
    The model is fine-tuned for instruction-following, agent tool use, creative writing,
    and multilingual tasks across 100+ languages and dialects. It natively handles
    32K token contexts and can extend to 131K tokens using YaRN-based scaling.
  context_length: 40960
  pricing:
    prompt: 5.0e-08
    completion: 2.2e-07
    image: 0.0
    request: 0.0
    currency: USD
  capabilities:
    supports_vision: false
    supports_function_calling: true
    supports_streaming: true
    modalities:
    - text
    - text->text
  metadata:
    architecture: Qwen3
  updated_at: 2025-12-19 00:46:07.739915+00:00
- model_id: qwen/qwen3-32b
  name: 'Qwen: Qwen3 32B'
  provider: openrouter
  description: 'Qwen3-32B is a dense 32.8B parameter causal language model from the
    Qwen3 series, optimized for both complex reasoning and efficient dialogue. It
    supports seamless switching between a "thinking" mode for tasks like math, coding,
    and logical inference, and a "non-thinking" mode for faster, general-purpose conversation.
    The model demonstrates strong performance in instruction-following, agent tool
    use, creative writing, and multilingual tasks across 100+ languages and dialects.
    It natively handles 32K token contexts and can extend to 131K tokens using YaRN-based
    scaling. '
  context_length: 40960
  pricing:
    prompt: 8.0e-08
    completion: 2.4e-07
    image: 0.0
    request: 0.0
    currency: USD
  capabilities:
    supports_vision: false
    supports_function_calling: true
    supports_streaming: true
    modalities:
    - text
    - text->text
  metadata:
    architecture: Qwen3
  updated_at: 2025-12-19 00:46:07.739924+00:00
- model_id: qwen/qwen3-235b-a22b:free
  name: 'Qwen: Qwen3 235B A22B (free)'
  provider: openrouter
  description: Qwen3-235B-A22B is a 235B parameter mixture-of-experts (MoE) model
    developed by Qwen, activating 22B parameters per forward pass. It supports seamless
    switching between a "thinking" mode for complex reasoning, math, and code tasks,
    and a "non-thinking" mode for general conversational efficiency. The model demonstrates
    strong reasoning ability, multilingual support (100+ languages and dialects),
    advanced instruction-following, and agent tool-calling capabilities. It natively
    handles a 32K token context window and extends up to 131K tokens using YaRN-based
    scaling.
  context_length: 131072
  pricing:
    prompt: 0.0
    completion: 0.0
    image: 0.0
    request: 0.0
    currency: USD
  capabilities:
    supports_vision: false
    supports_function_calling: true
    supports_streaming: true
    modalities:
    - text
    - text->text
  metadata:
    architecture: Qwen3
  updated_at: 2025-12-19 00:46:07.739932+00:00
- model_id: qwen/qwen3-235b-a22b
  name: 'Qwen: Qwen3 235B A22B'
  provider: openrouter
  description: Qwen3-235B-A22B is a 235B parameter mixture-of-experts (MoE) model
    developed by Qwen, activating 22B parameters per forward pass. It supports seamless
    switching between a "thinking" mode for complex reasoning, math, and code tasks,
    and a "non-thinking" mode for general conversational efficiency. The model demonstrates
    strong reasoning ability, multilingual support (100+ languages and dialects),
    advanced instruction-following, and agent tool-calling capabilities. It natively
    handles a 32K token context window and extends up to 131K tokens using YaRN-based
    scaling.
  context_length: 40960
  pricing:
    prompt: 1.8e-07
    completion: 5.4e-07
    image: 0.0
    request: 0.0
    currency: USD
  capabilities:
    supports_vision: false
    supports_function_calling: true
    supports_streaming: true
    modalities:
    - text
    - text->text
  metadata:
    architecture: Qwen3
  updated_at: 2025-12-19 00:46:07.739945+00:00
- model_id: tngtech/deepseek-r1t-chimera:free
  name: 'TNG: DeepSeek R1T Chimera (free)'
  provider: openrouter
  description: 'DeepSeek-R1T-Chimera is created by merging DeepSeek-R1 and DeepSeek-V3
    (0324), combining the reasoning capabilities of R1 with the token efficiency improvements
    of V3. It is based on a DeepSeek-MoE Transformer architecture and is optimized
    for general text generation tasks.


    The model merges pretrained weights from both source models to balance performance
    across reasoning, efficiency, and instruction-following tasks. It is released
    under the MIT license and intended for research and commercial use.'
  context_length: 163840
  pricing:
    prompt: 0.0
    completion: 0.0
    image: 0.0
    request: 0.0
    currency: USD
  capabilities:
    supports_vision: false
    supports_function_calling: false
    supports_streaming: true
    modalities:
    - text
    - text->text
  metadata:
    architecture: DeepSeek
  updated_at: 2025-12-19 00:46:07.739956+00:00
- model_id: tngtech/deepseek-r1t-chimera
  name: 'TNG: DeepSeek R1T Chimera'
  provider: openrouter
  description: 'DeepSeek-R1T-Chimera is created by merging DeepSeek-R1 and DeepSeek-V3
    (0324), combining the reasoning capabilities of R1 with the token efficiency improvements
    of V3. It is based on a DeepSeek-MoE Transformer architecture and is optimized
    for general text generation tasks.


    The model merges pretrained weights from both source models to balance performance
    across reasoning, efficiency, and instruction-following tasks. It is released
    under the MIT license and intended for research and commercial use.'
  context_length: 163840
  pricing:
    prompt: 3.0e-07
    completion: 1.2e-06
    image: 0.0
    request: 0.0
    currency: USD
  capabilities:
    supports_vision: false
    supports_function_calling: false
    supports_streaming: true
    modalities:
    - text
    - text->text
  metadata:
    architecture: DeepSeek
  updated_at: 2025-12-19 00:46:07.739966+00:00
- model_id: openai/o4-mini-high
  name: 'OpenAI: o4 Mini High'
  provider: openrouter
  description: "OpenAI o4-mini-high is the same model as [o4-mini](/openai/o4-mini)\
    \ with reasoning_effort set to high. \n\nOpenAI o4-mini is a compact reasoning\
    \ model in the o-series, optimized for fast, cost-efficient performance while\
    \ retaining strong multimodal and agentic capabilities. It supports tool use and\
    \ demonstrates competitive reasoning and coding performance across benchmarks\
    \ like AIME (99.5% with Python) and SWE-bench, outperforming its predecessor o3-mini\
    \ and even approaching o3 in some domains.\n\nDespite its smaller size, o4-mini\
    \ exhibits high accuracy in STEM tasks, visual problem solving (e.g., MathVista,\
    \ MMMU), and code editing. It is especially well-suited for high-throughput scenarios\
    \ where latency or cost is critical. Thanks to its efficient architecture and\
    \ refined reinforcement learning training, o4-mini can chain tools, generate structured\
    \ outputs, and solve multi-step tasks with minimal delay—often in under a minute."
  context_length: 200000
  pricing:
    prompt: 1.1e-06
    completion: 4.4e-06
    image: 0.0008415
    request: 0.0
    currency: USD
  capabilities:
    supports_vision: true
    supports_function_calling: true
    supports_streaming: true
    modalities:
    - text
    - image->text
  metadata:
    architecture: Other
  updated_at: 2025-12-19 00:46:07.739974+00:00
- model_id: openai/o3
  name: 'OpenAI: o3'
  provider: openrouter
  description: 'o3 is a well-rounded and powerful model across domains. It sets a
    new standard for math, science, coding, and visual reasoning tasks. It also excels
    at technical writing and instruction-following. Use it to think through multi-step
    problems that involve analysis across text, code, and images. '
  context_length: 200000
  pricing:
    prompt: 2.0e-06
    completion: 8.0e-06
    image: 0.00153
    request: 0.0
    currency: USD
  capabilities:
    supports_vision: true
    supports_function_calling: true
    supports_streaming: true
    modalities:
    - text
    - image->text
  metadata:
    architecture: GPT
  updated_at: 2025-12-19 00:46:07.739985+00:00
- model_id: openai/o4-mini
  name: 'OpenAI: o4 Mini'
  provider: openrouter
  description: 'OpenAI o4-mini is a compact reasoning model in the o-series, optimized
    for fast, cost-efficient performance while retaining strong multimodal and agentic
    capabilities. It supports tool use and demonstrates competitive reasoning and
    coding performance across benchmarks like AIME (99.5% with Python) and SWE-bench,
    outperforming its predecessor o3-mini and even approaching o3 in some domains.


    Despite its smaller size, o4-mini exhibits high accuracy in STEM tasks, visual
    problem solving (e.g., MathVista, MMMU), and code editing. It is especially well-suited
    for high-throughput scenarios where latency or cost is critical. Thanks to its
    efficient architecture and refined reinforcement learning training, o4-mini can
    chain tools, generate structured outputs, and solve multi-step tasks with minimal
    delay—often in under a minute.'
  context_length: 200000
  pricing:
    prompt: 1.1e-06
    completion: 4.4e-06
    image: 0.0008415
    request: 0.0
    currency: USD
  capabilities:
    supports_vision: true
    supports_function_calling: true
    supports_streaming: true
    modalities:
    - text
    - image->text
  metadata:
    architecture: GPT
  updated_at: 2025-12-19 00:46:07.739995+00:00
- model_id: qwen/qwen2.5-coder-7b-instruct
  name: 'Qwen: Qwen2.5 Coder 7B Instruct'
  provider: openrouter
  description: 'Qwen2.5-Coder-7B-Instruct is a 7B parameter instruction-tuned language
    model optimized for code-related tasks such as code generation, reasoning, and
    bug fixing. Based on the Qwen2.5 architecture, it incorporates enhancements like
    RoPE, SwiGLU, RMSNorm, and GQA attention with support for up to 128K tokens using
    YaRN-based extrapolation. It is trained on a large corpus of source code, synthetic
    data, and text-code grounding, providing robust performance across programming
    languages and agentic coding workflows.


    This model is part of the Qwen2.5-Coder family and offers strong compatibility
    with tools like vLLM for efficient deployment. Released under the Apache 2.0 license.'
  context_length: 32768
  pricing:
    prompt: 3.0e-08
    completion: 9.0e-08
    image: 0.0
    request: 0.0
    currency: USD
  capabilities:
    supports_vision: false
    supports_function_calling: false
    supports_streaming: true
    modalities:
    - text
    - text->text
  metadata:
    architecture: Qwen
  updated_at: 2025-12-19 00:46:07.740004+00:00
- model_id: openai/gpt-4.1
  name: 'OpenAI: GPT-4.1'
  provider: openrouter
  description: GPT-4.1 is a flagship large language model optimized for advanced instruction
    following, real-world software engineering, and long-context reasoning. It supports
    a 1 million token context window and outperforms GPT-4o and GPT-4.5 across coding
    (54.6% SWE-bench Verified), instruction compliance (87.4% IFEval), and multimodal
    understanding benchmarks. It is tuned for precise code diffs, agent reliability,
    and high recall in large document contexts, making it ideal for agents, IDE tooling,
    and enterprise knowledge retrieval.
  context_length: 1047576
  pricing:
    prompt: 2.0e-06
    completion: 8.0e-06
    image: 0.0
    request: 0.0
    currency: USD
  capabilities:
    supports_vision: true
    supports_function_calling: true
    supports_streaming: true
    modalities:
    - text
    - image->text
  metadata:
    architecture: GPT
  updated_at: 2025-12-19 00:46:07.740012+00:00
- model_id: openai/gpt-4.1-mini
  name: 'OpenAI: GPT-4.1 Mini'
  provider: openrouter
  description: GPT-4.1 Mini is a mid-sized model delivering performance competitive
    with GPT-4o at substantially lower latency and cost. It retains a 1 million token
    context window and scores 45.1% on hard instruction evals, 35.8% on MultiChallenge,
    and 84.1% on IFEval. Mini also shows strong coding ability (e.g., 31.6% on Aider’s
    polyglot diff benchmark) and vision understanding, making it suitable for interactive
    applications with tight performance constraints.
  context_length: 1047576
  pricing:
    prompt: 4.0e-07
    completion: 1.6e-06
    image: 0.0
    request: 0.0
    currency: USD
  capabilities:
    supports_vision: true
    supports_function_calling: true
    supports_streaming: true
    modalities:
    - text
    - image->text
  metadata:
    architecture: GPT
  updated_at: 2025-12-19 00:46:07.740025+00:00
- model_id: openai/gpt-4.1-nano
  name: 'OpenAI: GPT-4.1 Nano'
  provider: openrouter
  description: For tasks that demand low latency, GPT‑4.1 nano is the fastest and
    cheapest model in the GPT-4.1 series. It delivers exceptional performance at a
    small size with its 1 million token context window, and scores 80.1% on MMLU,
    50.3% on GPQA, and 9.8% on Aider polyglot coding – even higher than GPT‑4o mini.
    It’s ideal for tasks like classification or autocompletion.
  context_length: 1047576
  pricing:
    prompt: 1.0e-07
    completion: 4.0e-07
    image: 0.0
    request: 0.0
    currency: USD
  capabilities:
    supports_vision: true
    supports_function_calling: true
    supports_streaming: true
    modalities:
    - text
    - image->text
  metadata:
    architecture: GPT
  updated_at: 2025-12-19 00:46:07.740033+00:00
- model_id: eleutherai/llemma_7b
  name: 'EleutherAI: Llemma 7b'
  provider: openrouter
  description: Llemma 7B is a language model for mathematics. It was initialized with
    Code Llama 7B weights, and trained on the Proof-Pile-2 for 200B tokens. Llemma
    models are particularly strong at chain-of-thought mathematical reasoning and
    using computational tools for mathematics, such as Python and formal theorem provers.
  context_length: 4096
  pricing:
    prompt: 8.0e-07
    completion: 1.2e-06
    image: 0.0
    request: 0.0
    currency: USD
  capabilities:
    supports_vision: false
    supports_function_calling: false
    supports_streaming: true
    modalities:
    - text
    - text->text
  metadata:
    architecture: Other
  updated_at: 2025-12-19 00:46:07.740047+00:00
- model_id: alfredpros/codellama-7b-instruct-solidity
  name: 'AlfredPros: CodeLLaMa 7B Instruct Solidity'
  provider: openrouter
  description: A finetuned 7 billion parameters Code LLaMA - Instruct model to generate
    Solidity smart contract using 4-bit QLoRA finetuning provided by PEFT library.
  context_length: 4096
  pricing:
    prompt: 8.0e-07
    completion: 1.2e-06
    image: 0.0
    request: 0.0
    currency: USD
  capabilities:
    supports_vision: false
    supports_function_calling: false
    supports_streaming: true
    modalities:
    - text
    - text->text
  metadata:
    architecture: Other
  updated_at: 2025-12-19 00:46:07.740056+00:00
- model_id: arliai/qwq-32b-arliai-rpr-v1
  name: 'ArliAI: QwQ 32B RpR v1'
  provider: openrouter
  description: 'QwQ-32B-ArliAI-RpR-v1 is a 32B parameter model fine-tuned from Qwen/QwQ-32B
    using a curated creative writing and roleplay dataset originally developed for
    the RPMax series. It is designed to maintain coherence and reasoning across long
    multi-turn conversations by introducing explicit reasoning steps per dialogue
    turn, generated and refined using the base model itself.


    The model was trained using RS-QLORA+ on 8K sequence lengths and supports up to
    128K context windows (with practical performance around 32K). It is optimized
    for creative roleplay and dialogue generation, with an emphasis on minimizing
    cross-context repetition while preserving stylistic diversity.'
  context_length: 32768
  pricing:
    prompt: 3.0e-08
    completion: 1.1e-07
    image: 0.0
    request: 0.0
    currency: USD
  capabilities:
    supports_vision: false
    supports_function_calling: false
    supports_streaming: true
    modalities:
    - text
    - text->text
  metadata:
    architecture: Other
  updated_at: 2025-12-19 00:46:07.740070+00:00
- model_id: x-ai/grok-3-mini-beta
  name: 'xAI: Grok 3 Mini Beta'
  provider: openrouter
  description: "Grok 3 Mini is a lightweight, smaller thinking model. Unlike traditional\
    \ models that generate answers immediately, Grok 3 Mini thinks before responding.\
    \ It’s ideal for reasoning-heavy tasks that don’t demand extensive domain knowledge,\
    \ and shines in math-specific and quantitative use cases, such as solving challenging\
    \ puzzles or math problems.\n\nTransparent \"thinking\" traces accessible. Defaults\
    \ to low reasoning, can boost with setting `reasoning: { effort: \"high\" }`\n\
    \nNote: That there are two xAI endpoints for this model. By default when using\
    \ this model we will always route you to the base endpoint. If you want the fast\
    \ endpoint you can add `provider: { sort: throughput}`, to sort by throughput\
    \ instead. \n"
  context_length: 131072
  pricing:
    prompt: 3.0e-07
    completion: 5.0e-07
    image: 0.0
    request: 0.0
    currency: USD
  capabilities:
    supports_vision: false
    supports_function_calling: true
    supports_streaming: true
    modalities:
    - text
    - text->text
  metadata:
    architecture: Grok
  updated_at: 2025-12-19 00:46:07.740078+00:00
- model_id: x-ai/grok-3-beta
  name: 'xAI: Grok 3 Beta'
  provider: openrouter
  description: "Grok 3 is the latest model from xAI. It's their flagship model that\
    \ excels at enterprise use cases like data extraction, coding, and text summarization.\
    \ Possesses deep domain knowledge in finance, healthcare, law, and science.\n\n\
    Excels in structured tasks and benchmarks like GPQA, LCB, and MMLU-Pro where it\
    \ outperforms Grok 3 Mini even on high thinking. \n\nNote: That there are two\
    \ xAI endpoints for this model. By default when using this model we will always\
    \ route you to the base endpoint. If you want the fast endpoint you can add `provider:\
    \ { sort: throughput}`, to sort by throughput instead. \n"
  context_length: 131072
  pricing:
    prompt: 3.0e-06
    completion: 1.5e-05
    image: 0.0
    request: 0.0
    currency: USD
  capabilities:
    supports_vision: false
    supports_function_calling: true
    supports_streaming: true
    modalities:
    - text
    - text->text
  metadata:
    architecture: Grok
  updated_at: 2025-12-19 00:46:07.740088+00:00
- model_id: nvidia/llama-3.1-nemotron-ultra-253b-v1
  name: 'NVIDIA: Llama 3.1 Nemotron Ultra 253B v1'
  provider: openrouter
  description: 'Llama-3.1-Nemotron-Ultra-253B-v1 is a large language model (LLM) optimized
    for advanced reasoning, human-interactive chat, retrieval-augmented generation
    (RAG), and tool-calling tasks. Derived from Meta’s Llama-3.1-405B-Instruct, it
    has been significantly customized using Neural Architecture Search (NAS), resulting
    in enhanced efficiency, reduced memory usage, and improved inference latency.
    The model supports a context length of up to 128K tokens and can operate efficiently
    on an 8x NVIDIA H100 node.


    Note: you must include `detailed thinking on` in the system prompt to enable reasoning.
    Please see [Usage Recommendations](https://huggingface.co/nvidia/Llama-3_1-Nemotron-Ultra-253B-v1#quick-start-and-usage-recommendations)
    for more.'
  context_length: 131072
  pricing:
    prompt: 6.0e-07
    completion: 1.8e-06
    image: 0.0
    request: 0.0
    currency: USD
  capabilities:
    supports_vision: false
    supports_function_calling: false
    supports_streaming: true
    modalities:
    - text
    - text->text
  metadata:
    architecture: Llama3
  updated_at: 2025-12-19 00:46:07.740097+00:00
- model_id: meta-llama/llama-4-maverick
  name: 'Meta: Llama 4 Maverick'
  provider: openrouter
  description: 'Llama 4 Maverick 17B Instruct (128E) is a high-capacity multimodal
    language model from Meta, built on a mixture-of-experts (MoE) architecture with
    128 experts and 17 billion active parameters per forward pass (400B total). It
    supports multilingual text and image input, and produces multilingual text and
    code output across 12 supported languages. Optimized for vision-language tasks,
    Maverick is instruction-tuned for assistant-like behavior, image reasoning, and
    general-purpose multimodal interaction.


    Maverick features early fusion for native multimodality and a 1 million token
    context window. It was trained on a curated mixture of public, licensed, and Meta-platform
    data, covering ~22 trillion tokens, with a knowledge cutoff in August 2024. Released
    on April 5, 2025 under the Llama 4 Community License, Maverick is suited for research
    and commercial applications requiring advanced multimodal understanding and high
    model throughput.'
  context_length: 1048576
  pricing:
    prompt: 1.5e-07
    completion: 6.0e-07
    image: 0.0006684
    request: 0.0
    currency: USD
  capabilities:
    supports_vision: true
    supports_function_calling: true
    supports_streaming: true
    modalities:
    - text
    - image->text
  metadata:
    architecture: Llama4
  updated_at: 2025-12-19 00:46:07.740107+00:00
- model_id: meta-llama/llama-4-scout
  name: 'Meta: Llama 4 Scout'
  provider: openrouter
  description: 'Llama 4 Scout 17B Instruct (16E) is a mixture-of-experts (MoE) language
    model developed by Meta, activating 17 billion parameters out of a total of 109B.
    It supports native multimodal input (text and image) and multilingual output (text
    and code) across 12 supported languages. Designed for assistant-style interaction
    and visual reasoning, Scout uses 16 experts per forward pass and features a context
    length of 10 million tokens, with a training corpus of ~40 trillion tokens.


    Built for high efficiency and local or commercial deployment, Llama 4 Scout incorporates
    early fusion for seamless modality integration. It is instruction-tuned for use
    in multilingual chat, captioning, and image understanding tasks. Released under
    the Llama 4 Community License, it was last trained on data up to August 2024 and
    launched publicly on April 5, 2025.'
  context_length: 327680
  pricing:
    prompt: 8.0e-08
    completion: 3.0e-07
    image: 0.0003342
    request: 0.0
    currency: USD
  capabilities:
    supports_vision: true
    supports_function_calling: true
    supports_streaming: true
    modalities:
    - text
    - image->text
  metadata:
    architecture: Llama4
  updated_at: 2025-12-19 00:46:07.740115+00:00
- model_id: qwen/qwen2.5-vl-32b-instruct
  name: 'Qwen: Qwen2.5 VL 32B Instruct'
  provider: openrouter
  description: Qwen2.5-VL-32B is a multimodal vision-language model fine-tuned through
    reinforcement learning for enhanced mathematical reasoning, structured outputs,
    and visual problem-solving capabilities. It excels at visual analysis tasks, including
    object recognition, textual interpretation within images, and precise event localization
    in extended videos. Qwen2.5-VL-32B demonstrates state-of-the-art performance across
    multimodal benchmarks such as MMMU, MathVista, and VideoMME, while maintaining
    strong reasoning and clarity in text-based tasks like MMLU, mathematical problem-solving,
    and code generation.
  context_length: 16384
  pricing:
    prompt: 5.0e-08
    completion: 2.2e-07
    image: 0.0
    request: 0.0
    currency: USD
  capabilities:
    supports_vision: true
    supports_function_calling: false
    supports_streaming: true
    modalities:
    - text
    - image->text
  metadata:
    architecture: Qwen
  updated_at: 2025-12-19 00:46:07.740126+00:00
- model_id: deepseek/deepseek-chat-v3-0324
  name: 'DeepSeek: DeepSeek V3 0324'
  provider: openrouter
  description: 'DeepSeek V3, a 685B-parameter, mixture-of-experts model, is the latest
    iteration of the flagship chat model family from the DeepSeek team.


    It succeeds the [DeepSeek V3](/deepseek/deepseek-chat-v3) model and performs really
    well on a variety of tasks.'
  context_length: 163840
  pricing:
    prompt: 2.0e-07
    completion: 8.8e-07
    image: 0.0
    request: 0.0
    currency: USD
  capabilities:
    supports_vision: false
    supports_function_calling: true
    supports_streaming: true
    modalities:
    - text
    - text->text
  metadata:
    architecture: DeepSeek
  updated_at: 2025-12-19 00:46:07.740134+00:00
- model_id: openai/o1-pro
  name: 'OpenAI: o1-pro'
  provider: openrouter
  description: The o1 series of models are trained with reinforcement learning to
    think before they answer and perform complex reasoning. The o1-pro model uses
    more compute to think harder and provide consistently better answers.
  context_length: 200000
  pricing:
    prompt: 0.00015
    completion: 0.0006
    image: 0.21675
    request: 0.0
    currency: USD
  capabilities:
    supports_vision: true
    supports_function_calling: false
    supports_streaming: true
    modalities:
    - text
    - image->text
  metadata:
    architecture: GPT
  updated_at: 2025-12-19 00:46:07.740148+00:00
- model_id: mistralai/mistral-small-3.1-24b-instruct:free
  name: 'Mistral: Mistral Small 3.1 24B (free)'
  provider: openrouter
  description: Mistral Small 3.1 24B Instruct is an upgraded variant of Mistral Small
    3 (2501), featuring 24 billion parameters with advanced multimodal capabilities.
    It provides state-of-the-art performance in text-based reasoning and vision tasks,
    including image analysis, programming, mathematical reasoning, and multilingual
    support across dozens of languages. Equipped with an extensive 128k token context
    window and optimized for efficient local inference, it supports use cases such
    as conversational agents, function calling, long-document comprehension, and privacy-sensitive
    deployments. The updated version is [Mistral Small 3.2](mistralai/mistral-small-3.2-24b-instruct)
  context_length: 128000
  pricing:
    prompt: 0.0
    completion: 0.0
    image: 0.0
    request: 0.0
    currency: USD
  capabilities:
    supports_vision: true
    supports_function_calling: true
    supports_streaming: true
    modalities:
    - text
    - image->text
  metadata:
    architecture: Mistral
  updated_at: 2025-12-19 00:46:07.740159+00:00
- model_id: mistralai/mistral-small-3.1-24b-instruct
  name: 'Mistral: Mistral Small 3.1 24B'
  provider: openrouter
  description: Mistral Small 3.1 24B Instruct is an upgraded variant of Mistral Small
    3 (2501), featuring 24 billion parameters with advanced multimodal capabilities.
    It provides state-of-the-art performance in text-based reasoning and vision tasks,
    including image analysis, programming, mathematical reasoning, and multilingual
    support across dozens of languages. Equipped with an extensive 128k token context
    window and optimized for efficient local inference, it supports use cases such
    as conversational agents, function calling, long-document comprehension, and privacy-sensitive
    deployments. The updated version is [Mistral Small 3.2](mistralai/mistral-small-3.2-24b-instruct)
  context_length: 131072
  pricing:
    prompt: 3.0e-08
    completion: 1.1e-07
    image: 0.0
    request: 0.0
    currency: USD
  capabilities:
    supports_vision: true
    supports_function_calling: true
    supports_streaming: true
    modalities:
    - text
    - image->text
  metadata:
    architecture: Mistral
  updated_at: 2025-12-19 00:46:07.740167+00:00
- model_id: allenai/olmo-2-0325-32b-instruct
  name: 'AllenAI: Olmo 2 32B Instruct'
  provider: openrouter
  description: OLMo-2 32B Instruct is a supervised instruction-finetuned variant of
    the OLMo-2 32B March 2025 base model. It excels in complex reasoning and instruction-following
    tasks across diverse benchmarks such as GSM8K, MATH, IFEval, and general NLP evaluation.
    Developed by AI2, OLMo-2 32B is part of an open, research-oriented initiative,
    trained primarily on English-language datasets to advance the understanding and
    development of open-source language models.
  context_length: 128000
  pricing:
    prompt: 5.0e-08
    completion: 2.0e-07
    image: 0.0
    request: 0.0
    currency: USD
  capabilities:
    supports_vision: false
    supports_function_calling: false
    supports_streaming: true
    modalities:
    - text
    - text->text
  metadata:
    architecture: Other
  updated_at: 2025-12-19 00:46:07.740177+00:00
- model_id: google/gemma-3-4b-it:free
  name: 'Google: Gemma 3 4B (free)'
  provider: openrouter
  description: Gemma 3 introduces multimodality, supporting vision-language input
    and text outputs. It handles context windows up to 128k tokens, understands over
    140 languages, and offers improved math, reasoning, and chat capabilities, including
    structured outputs and function calling.
  context_length: 32768
  pricing:
    prompt: 0.0
    completion: 0.0
    image: 0.0
    request: 0.0
    currency: USD
  capabilities:
    supports_vision: true
    supports_function_calling: false
    supports_streaming: true
    modalities:
    - text
    - image->text
  metadata:
    architecture: Gemini
  updated_at: 2025-12-19 00:46:07.740186+00:00
- model_id: google/gemma-3-4b-it
  name: 'Google: Gemma 3 4B'
  provider: openrouter
  description: Gemma 3 introduces multimodality, supporting vision-language input
    and text outputs. It handles context windows up to 128k tokens, understands over
    140 languages, and offers improved math, reasoning, and chat capabilities, including
    structured outputs and function calling.
  context_length: 96000
  pricing:
    prompt: 1.703012e-08
    completion: 6.81536e-08
    image: 0.0
    request: 0.0
    currency: USD
  capabilities:
    supports_vision: true
    supports_function_calling: false
    supports_streaming: true
    modalities:
    - text
    - image->text
  metadata:
    architecture: Gemini
  updated_at: 2025-12-19 00:46:07.740195+00:00
- model_id: google/gemma-3-12b-it:free
  name: 'Google: Gemma 3 12B (free)'
  provider: openrouter
  description: Gemma 3 introduces multimodality, supporting vision-language input
    and text outputs. It handles context windows up to 128k tokens, understands over
    140 languages, and offers improved math, reasoning, and chat capabilities, including
    structured outputs and function calling. Gemma 3 12B is the second largest in
    the family of Gemma 3 models after [Gemma 3 27B](google/gemma-3-27b-it)
  context_length: 32768
  pricing:
    prompt: 0.0
    completion: 0.0
    image: 0.0
    request: 0.0
    currency: USD
  capabilities:
    supports_vision: true
    supports_function_calling: false
    supports_streaming: true
    modalities:
    - text
    - image->text
  metadata:
    architecture: Gemini
  updated_at: 2025-12-19 00:46:07.740205+00:00
- model_id: google/gemma-3-12b-it
  name: 'Google: Gemma 3 12B'
  provider: openrouter
  description: Gemma 3 introduces multimodality, supporting vision-language input
    and text outputs. It handles context windows up to 128k tokens, understands over
    140 languages, and offers improved math, reasoning, and chat capabilities, including
    structured outputs and function calling. Gemma 3 12B is the second largest in
    the family of Gemma 3 models after [Gemma 3 27B](google/gemma-3-27b-it)
  context_length: 131072
  pricing:
    prompt: 3.0e-08
    completion: 1.0e-07
    image: 0.0
    request: 0.0
    currency: USD
  capabilities:
    supports_vision: true
    supports_function_calling: false
    supports_streaming: true
    modalities:
    - text
    - image->text
  metadata:
    architecture: Gemini
  updated_at: 2025-12-19 00:46:07.740215+00:00
- model_id: cohere/command-a
  name: 'Cohere: Command A'
  provider: openrouter
  description: 'Command A is an open-weights 111B parameter model with a 256k context
    window focused on delivering great performance across agentic, multilingual, and
    coding use cases.

    Compared to other leading proprietary and open-weights models Command A delivers
    maximum performance with minimum hardware costs, excelling on business-critical
    agentic and multilingual tasks.'
  context_length: 256000
  pricing:
    prompt: 2.5e-06
    completion: 1.0e-05
    image: 0.0
    request: 0.0
    currency: USD
  capabilities:
    supports_vision: false
    supports_function_calling: false
    supports_streaming: true
    modalities:
    - text
    - text->text
  metadata:
    architecture: Other
  updated_at: 2025-12-19 00:46:07.740224+00:00
- model_id: openai/gpt-4o-mini-search-preview
  name: 'OpenAI: GPT-4o-mini Search Preview'
  provider: openrouter
  description: GPT-4o mini Search Preview is a specialized model for web search in
    Chat Completions. It is trained to understand and execute web search queries.
  context_length: 128000
  pricing:
    prompt: 1.5e-07
    completion: 6.0e-07
    image: 0.000217
    request: 0.0275
    currency: USD
  capabilities:
    supports_vision: false
    supports_function_calling: false
    supports_streaming: true
    modalities:
    - text
    - text->text
  metadata:
    architecture: GPT
  updated_at: 2025-12-19 00:46:07.740236+00:00
- model_id: openai/gpt-4o-search-preview
  name: 'OpenAI: GPT-4o Search Preview'
  provider: openrouter
  description: GPT-4o Search Previewis a specialized model for web search in Chat
    Completions. It is trained to understand and execute web search queries.
  context_length: 128000
  pricing:
    prompt: 2.5e-06
    completion: 1.0e-05
    image: 0.003613
    request: 0.035
    currency: USD
  capabilities:
    supports_vision: false
    supports_function_calling: false
    supports_streaming: true
    modalities:
    - text
    - text->text
  metadata:
    architecture: GPT
  updated_at: 2025-12-19 00:46:07.740244+00:00
- model_id: google/gemma-3-27b-it:free
  name: 'Google: Gemma 3 27B (free)'
  provider: openrouter
  description: Gemma 3 introduces multimodality, supporting vision-language input
    and text outputs. It handles context windows up to 128k tokens, understands over
    140 languages, and offers improved math, reasoning, and chat capabilities, including
    structured outputs and function calling. Gemma 3 27B is Google's latest open source
    model, successor to [Gemma 2](google/gemma-2-27b-it)
  context_length: 131072
  pricing:
    prompt: 0.0
    completion: 0.0
    image: 0.0
    request: 0.0
    currency: USD
  capabilities:
    supports_vision: true
    supports_function_calling: true
    supports_streaming: true
    modalities:
    - text
    - image->text
  metadata:
    architecture: Gemini
  updated_at: 2025-12-19 00:46:07.740256+00:00
- model_id: google/gemma-3-27b-it
  name: 'Google: Gemma 3 27B'
  provider: openrouter
  description: Gemma 3 introduces multimodality, supporting vision-language input
    and text outputs. It handles context windows up to 128k tokens, understands over
    140 languages, and offers improved math, reasoning, and chat capabilities, including
    structured outputs and function calling. Gemma 3 27B is Google's latest open source
    model, successor to [Gemma 2](google/gemma-2-27b-it)
  context_length: 96000
  pricing:
    prompt: 4.0e-08
    completion: 1.5e-07
    image: 0.0
    request: 0.0
    currency: USD
  capabilities:
    supports_vision: true
    supports_function_calling: true
    supports_streaming: true
    modalities:
    - text
    - image->text
  metadata:
    architecture: Gemini
  updated_at: 2025-12-19 00:46:07.740267+00:00
- model_id: thedrummer/skyfall-36b-v2
  name: 'TheDrummer: Skyfall 36B V2'
  provider: openrouter
  description: Skyfall 36B v2 is an enhanced iteration of Mistral Small 2501, specifically
    fine-tuned for improved creativity, nuanced writing, role-playing, and coherent
    storytelling.
  context_length: 32768
  pricing:
    prompt: 5.5e-07
    completion: 8.0e-07
    image: 0.0
    request: 0.0
    currency: USD
  capabilities:
    supports_vision: false
    supports_function_calling: false
    supports_streaming: true
    modalities:
    - text
    - text->text
  metadata:
    architecture: Other
  updated_at: 2025-12-19 00:46:07.740275+00:00
- model_id: microsoft/phi-4-multimodal-instruct
  name: 'Microsoft: Phi 4 Multimodal Instruct'
  provider: openrouter
  description: 'Phi-4 Multimodal Instruct is a versatile 5.6B parameter foundation
    model that combines advanced reasoning and instruction-following capabilities
    across both text and visual inputs, providing accurate text outputs. The unified
    architecture enables efficient, low-latency inference, suitable for edge and mobile
    deployments. Phi-4 Multimodal Instruct supports text inputs in multiple languages
    including Arabic, Chinese, English, French, German, Japanese, Spanish, and more,
    with visual input optimized primarily for English. It delivers impressive performance
    on multimodal tasks involving mathematical, scientific, and document reasoning,
    providing developers and enterprises a powerful yet compact model for sophisticated
    interactive applications. For more information, see the [Phi-4 Multimodal blog
    post](https://azure.microsoft.com/en-us/blog/empowering-innovation-the-next-generation-of-the-phi-family/).

    '
  context_length: 131072
  pricing:
    prompt: 5.0e-08
    completion: 1.0e-07
    image: 0.00017685
    request: 0.0
    currency: USD
  capabilities:
    supports_vision: true
    supports_function_calling: false
    supports_streaming: true
    modalities:
    - text
    - image->text
  metadata:
    architecture: Other
  updated_at: 2025-12-19 00:46:07.740283+00:00
- model_id: perplexity/sonar-reasoning-pro
  name: 'Perplexity: Sonar Reasoning Pro'
  provider: openrouter
  description: 'Note: Sonar Pro pricing includes Perplexity search pricing. See [details
    here](https://docs.perplexity.ai/guides/pricing#detailed-pricing-breakdown-for-sonar-reasoning-pro-and-sonar-pro)


    Sonar Reasoning Pro is a premier reasoning model powered by DeepSeek R1 with Chain
    of Thought (CoT). Designed for advanced use cases, it supports in-depth, multi-step
    queries with a larger context window and can surface more citations per search,
    enabling more comprehensive and extensible responses.'
  context_length: 128000
  pricing:
    prompt: 2.0e-06
    completion: 8.0e-06
    image: 0.0
    request: 0.0
    currency: USD
  capabilities:
    supports_vision: true
    supports_function_calling: false
    supports_streaming: true
    modalities:
    - text
    - image->text
  metadata:
    architecture: Other
  updated_at: 2025-12-19 00:46:07.740296+00:00
- model_id: perplexity/sonar-pro
  name: 'Perplexity: Sonar Pro'
  provider: openrouter
  description: 'Note: Sonar Pro pricing includes Perplexity search pricing. See [details
    here](https://docs.perplexity.ai/guides/pricing#detailed-pricing-breakdown-for-sonar-reasoning-pro-and-sonar-pro)


    For enterprises seeking more advanced capabilities, the Sonar Pro API can handle
    in-depth, multi-step queries with added extensibility, like double the number
    of citations per search as Sonar on average. Plus, with a larger context window,
    it can handle longer and more nuanced searches and follow-up questions. '
  context_length: 200000
  pricing:
    prompt: 3.0e-06
    completion: 1.5e-05
    image: 0.0
    request: 0.0
    currency: USD
  capabilities:
    supports_vision: true
    supports_function_calling: false
    supports_streaming: true
    modalities:
    - text
    - image->text
  metadata:
    architecture: Other
  updated_at: 2025-12-19 00:46:07.740304+00:00
- model_id: perplexity/sonar-deep-research
  name: 'Perplexity: Sonar Deep Research'
  provider: openrouter
  description: "Sonar Deep Research is a research-focused model designed for multi-step\
    \ retrieval, synthesis, and reasoning across complex topics. It autonomously searches,\
    \ reads, and evaluates sources, refining its approach as it gathers information.\
    \ This enables comprehensive report generation across domains like finance, technology,\
    \ health, and current events.\n\nNotes on Pricing ([Source](https://docs.perplexity.ai/guides/pricing#detailed-pricing-breakdown-for-sonar-deep-research))\
    \ \n- Input tokens comprise of Prompt tokens (user prompt) + Citation tokens (these\
    \ are processed tokens from running searches)\n- Deep Research runs multiple searches\
    \ to conduct exhaustive research. Searches are priced at $5/1000 searches. A request\
    \ that does 30 searches will cost $0.15 in this step.\n- Reasoning is a distinct\
    \ step in Deep Research since it does extensive automated reasoning through all\
    \ the material it gathers during its research phase. Reasoning tokens here are\
    \ a bit different than the CoTs in the answer - these are tokens that we use to\
    \ reason through the research material prior to generating the outputs via the\
    \ CoTs. Reasoning tokens are priced at $3/1M tokens"
  context_length: 128000
  pricing:
    prompt: 2.0e-06
    completion: 8.0e-06
    image: 0.0
    request: 0.0
    currency: USD
  capabilities:
    supports_vision: false
    supports_function_calling: false
    supports_streaming: true
    modalities:
    - text
    - text->text
  metadata:
    architecture: Other
  updated_at: 2025-12-19 00:46:07.740314+00:00
- model_id: qwen/qwq-32b
  name: 'Qwen: QwQ 32B'
  provider: openrouter
  description: QwQ is the reasoning model of the Qwen series. Compared with conventional
    instruction-tuned models, QwQ, which is capable of thinking and reasoning, can
    achieve significantly enhanced performance in downstream tasks, especially hard
    problems. QwQ-32B is the medium-sized reasoning model, which is capable of achieving
    competitive performance against state-of-the-art reasoning models, e.g., DeepSeek-R1,
    o1-mini.
  context_length: 32768
  pricing:
    prompt: 1.5e-07
    completion: 4.0e-07
    image: 0.0
    request: 0.0
    currency: USD
  capabilities:
    supports_vision: false
    supports_function_calling: true
    supports_streaming: true
    modalities:
    - text
    - text->text
  metadata:
    architecture: Qwen
  updated_at: 2025-12-19 00:46:07.740325+00:00
- model_id: google/gemini-2.0-flash-lite-001
  name: 'Google: Gemini 2.0 Flash Lite'
  provider: openrouter
  description: Gemini 2.0 Flash Lite offers a significantly faster time to first token
    (TTFT) compared to [Gemini Flash 1.5](/google/gemini-flash-1.5), while maintaining
    quality on par with larger models like [Gemini Pro 1.5](/google/gemini-pro-1.5),
    all at extremely economical token prices.
  context_length: 1048576
  pricing:
    prompt: 7.5e-08
    completion: 3.0e-07
    image: 0.0
    request: 0.0
    currency: USD
  capabilities:
    supports_vision: true
    supports_function_calling: true
    supports_streaming: true
    modalities:
    - text
    - image->text
  metadata:
    architecture: Gemini
  updated_at: 2025-12-19 00:46:07.740337+00:00
- model_id: anthropic/claude-3.7-sonnet:thinking
  name: 'Anthropic: Claude 3.7 Sonnet (thinking)'
  provider: openrouter
  description: "Claude 3.7 Sonnet is an advanced large language model with improved\
    \ reasoning, coding, and problem-solving capabilities. It introduces a hybrid\
    \ reasoning approach, allowing users to choose between rapid responses and extended,\
    \ step-by-step processing for complex tasks. The model demonstrates notable improvements\
    \ in coding, particularly in front-end development and full-stack updates, and\
    \ excels in agentic workflows, where it can autonomously navigate multi-step processes.\
    \ \n\nClaude 3.7 Sonnet maintains performance parity with its predecessor in standard\
    \ mode while offering an extended reasoning mode for enhanced accuracy in math,\
    \ coding, and instruction-following tasks.\n\nRead more at the [blog post here](https://www.anthropic.com/news/claude-3-7-sonnet)"
  context_length: 200000
  pricing:
    prompt: 3.0e-06
    completion: 1.5e-05
    image: 0.0048
    request: 0.0
    currency: USD
  capabilities:
    supports_vision: true
    supports_function_calling: true
    supports_streaming: true
    modalities:
    - text
    - image->text
  metadata:
    architecture: Claude
  updated_at: 2025-12-19 00:46:07.740345+00:00
- model_id: anthropic/claude-3.7-sonnet
  name: 'Anthropic: Claude 3.7 Sonnet'
  provider: openrouter
  description: "Claude 3.7 Sonnet is an advanced large language model with improved\
    \ reasoning, coding, and problem-solving capabilities. It introduces a hybrid\
    \ reasoning approach, allowing users to choose between rapid responses and extended,\
    \ step-by-step processing for complex tasks. The model demonstrates notable improvements\
    \ in coding, particularly in front-end development and full-stack updates, and\
    \ excels in agentic workflows, where it can autonomously navigate multi-step processes.\
    \ \n\nClaude 3.7 Sonnet maintains performance parity with its predecessor in standard\
    \ mode while offering an extended reasoning mode for enhanced accuracy in math,\
    \ coding, and instruction-following tasks.\n\nRead more at the [blog post here](https://www.anthropic.com/news/claude-3-7-sonnet)"
  context_length: 200000
  pricing:
    prompt: 3.0e-06
    completion: 1.5e-05
    image: 0.0048
    request: 0.0
    currency: USD
  capabilities:
    supports_vision: true
    supports_function_calling: true
    supports_streaming: true
    modalities:
    - text
    - image->text
  metadata:
    architecture: Claude
  updated_at: 2025-12-19 00:46:07.740353+00:00
- model_id: mistralai/mistral-saba
  name: 'Mistral: Saba'
  provider: openrouter
  description: Mistral Saba is a 24B-parameter language model specifically designed
    for the Middle East and South Asia, delivering accurate and contextually relevant
    responses while maintaining efficient performance. Trained on curated regional
    datasets, it supports multiple Indian-origin languages—including Tamil and Malayalam—alongside
    Arabic. This makes it a versatile option for a range of regional and multilingual
    applications. Read more at the blog post [here](https://mistral.ai/en/news/mistral-saba)
  context_length: 32768
  pricing:
    prompt: 2.0e-07
    completion: 6.0e-07
    image: 0.0
    request: 0.0
    currency: USD
  capabilities:
    supports_vision: false
    supports_function_calling: true
    supports_streaming: true
    modalities:
    - text
    - text->text
  metadata:
    architecture: Mistral
  updated_at: 2025-12-19 00:46:07.740363+00:00
- model_id: meta-llama/llama-guard-3-8b
  name: Llama Guard 3 8B
  provider: openrouter
  description: 'Llama Guard 3 is a Llama-3.1-8B pretrained model, fine-tuned for content
    safety classification. Similar to previous versions, it can be used to classify
    content in both LLM inputs (prompt classification) and in LLM responses (response
    classification). It acts as an LLM – it generates text in its output that indicates
    whether a given prompt or response is safe or unsafe, and if unsafe, it also lists
    the content categories violated.


    Llama Guard 3 was aligned to safeguard against the MLCommons standardized hazards
    taxonomy and designed to support Llama 3.1 capabilities. Specifically, it provides
    content moderation in 8 languages, and was optimized to support safety and security
    for search and code interpreter tool calls.

    '
  context_length: 131072
  pricing:
    prompt: 2.0e-08
    completion: 6.0e-08
    image: 0.0
    request: 0.0
    currency: USD
  capabilities:
    supports_vision: false
    supports_function_calling: false
    supports_streaming: true
    modalities:
    - text
    - text->text
  metadata:
    architecture: Llama3
  updated_at: 2025-12-19 00:46:07.740373+00:00
- model_id: openai/o3-mini-high
  name: 'OpenAI: o3 Mini High'
  provider: openrouter
  description: "OpenAI o3-mini-high is the same model as [o3-mini](/openai/o3-mini)\
    \ with reasoning_effort set to high. \n\no3-mini is a cost-efficient language\
    \ model optimized for STEM reasoning tasks, particularly excelling in science,\
    \ mathematics, and coding. The model features three adjustable reasoning effort\
    \ levels and supports key developer capabilities including function calling, structured\
    \ outputs, and streaming, though it does not include vision processing capabilities.\n\
    \nThe model demonstrates significant improvements over its predecessor, with expert\
    \ testers preferring its responses 56% of the time and noting a 39% reduction\
    \ in major errors on complex questions. With medium reasoning effort settings,\
    \ o3-mini matches the performance of the larger o1 model on challenging reasoning\
    \ evaluations like AIME and GPQA, while maintaining lower latency and cost."
  context_length: 200000
  pricing:
    prompt: 1.1e-06
    completion: 4.4e-06
    image: 0.0
    request: 0.0
    currency: USD
  capabilities:
    supports_vision: false
    supports_function_calling: true
    supports_streaming: true
    modalities:
    - text
    - text->text
  metadata:
    architecture: GPT
  updated_at: 2025-12-19 00:46:07.740384+00:00
- model_id: google/gemini-2.0-flash-001
  name: 'Google: Gemini 2.0 Flash'
  provider: openrouter
  description: Gemini Flash 2.0 offers a significantly faster time to first token
    (TTFT) compared to [Gemini Flash 1.5](/google/gemini-flash-1.5), while maintaining
    quality on par with larger models like [Gemini Pro 1.5](/google/gemini-pro-1.5).
    It introduces notable enhancements in multimodal understanding, coding capabilities,
    complex instruction following, and function calling. These advancements come together
    to deliver more seamless and robust agentic experiences.
  context_length: 1048576
  pricing:
    prompt: 1.0e-07
    completion: 4.0e-07
    image: 2.58e-05
    request: 0.0
    currency: USD
  capabilities:
    supports_vision: true
    supports_function_calling: true
    supports_streaming: true
    modalities:
    - text
    - image->text
  metadata:
    architecture: Gemini
  updated_at: 2025-12-19 00:46:07.740392+00:00
- model_id: qwen/qwen-vl-plus
  name: 'Qwen: Qwen VL Plus'
  provider: openrouter
  description: 'Qwen''s Enhanced Large Visual Language Model. Significantly upgraded
    for detailed recognition capabilities and text recognition abilities, supporting
    ultra-high pixel resolutions up to millions of pixels and extreme aspect ratios
    for image input. It delivers significant performance across a broad range of visual
    tasks.

    '
  context_length: 7500
  pricing:
    prompt: 2.1e-07
    completion: 6.3e-07
    image: 0.0002688
    request: 0.0
    currency: USD
  capabilities:
    supports_vision: true
    supports_function_calling: false
    supports_streaming: true
    modalities:
    - text
    - image->text
  metadata:
    architecture: Qwen
  updated_at: 2025-12-19 00:46:07.740400+00:00
- model_id: aion-labs/aion-1.0
  name: 'AionLabs: Aion-1.0'
  provider: openrouter
  description: Aion-1.0 is a multi-model system designed for high performance across
    various tasks, including reasoning and coding. It is built on DeepSeek-R1, augmented
    with additional models and techniques such as Tree of Thoughts (ToT) and Mixture
    of Experts (MoE). It is Aion Lab's most powerful reasoning model.
  context_length: 131072
  pricing:
    prompt: 4.0e-06
    completion: 8.0e-06
    image: 0.0
    request: 0.0
    currency: USD
  capabilities:
    supports_vision: false
    supports_function_calling: false
    supports_streaming: true
    modalities:
    - text
    - text->text
  metadata:
    architecture: Other
  updated_at: 2025-12-19 00:46:07.740413+00:00
- model_id: aion-labs/aion-1.0-mini
  name: 'AionLabs: Aion-1.0-Mini'
  provider: openrouter
  description: Aion-1.0-Mini 32B parameter model is a distilled version of the DeepSeek-R1
    model, designed for strong performance in reasoning domains such as mathematics,
    coding, and logic. It is a modified variant of a FuseAI model that outperforms
    R1-Distill-Qwen-32B and R1-Distill-Llama-70B, with benchmark results available
    on its [Hugging Face page](https://huggingface.co/FuseAI/FuseO1-DeepSeekR1-QwQ-SkyT1-32B-Preview),
    independently replicated for verification.
  context_length: 131072
  pricing:
    prompt: 7.0e-07
    completion: 1.4e-06
    image: 0.0
    request: 0.0
    currency: USD
  capabilities:
    supports_vision: false
    supports_function_calling: false
    supports_streaming: true
    modalities:
    - text
    - text->text
  metadata:
    architecture: Other
  updated_at: 2025-12-19 00:46:07.740421+00:00
- model_id: aion-labs/aion-rp-llama-3.1-8b
  name: 'AionLabs: Aion-RP 1.0 (8B)'
  provider: openrouter
  description: Aion-RP-Llama-3.1-8B ranks the highest in the character evaluation
    portion of the RPBench-Auto benchmark, a roleplaying-specific variant of Arena-Hard-Auto,
    where LLMs evaluate each other’s responses. It is a fine-tuned base model rather
    than an instruct model, designed to produce more natural and varied writing.
  context_length: 32768
  pricing:
    prompt: 2.0e-07
    completion: 2.0e-07
    image: 0.0
    request: 0.0
    currency: USD
  capabilities:
    supports_vision: false
    supports_function_calling: false
    supports_streaming: true
    modalities:
    - text
    - text->text
  metadata:
    architecture: Other
  updated_at: 2025-12-19 00:46:07.740466+00:00
- model_id: qwen/qwen-vl-max
  name: 'Qwen: Qwen VL Max'
  provider: openrouter
  description: 'Qwen VL Max is a visual understanding model with 7500 tokens context
    length. It excels in delivering optimal performance for a broader spectrum of
    complex tasks.

    '
  context_length: 131072
  pricing:
    prompt: 8.0e-07
    completion: 3.2e-06
    image: 0.001024
    request: 0.0
    currency: USD
  capabilities:
    supports_vision: true
    supports_function_calling: true
    supports_streaming: true
    modalities:
    - text
    - image->text
  metadata:
    architecture: Qwen
  updated_at: 2025-12-19 00:46:07.740478+00:00
- model_id: qwen/qwen-turbo
  name: 'Qwen: Qwen-Turbo'
  provider: openrouter
  description: Qwen-Turbo, based on Qwen2.5, is a 1M context model that provides fast
    speed and low cost, suitable for simple tasks.
  context_length: 1000000
  pricing:
    prompt: 5.0e-08
    completion: 2.0e-07
    image: 0.0
    request: 0.0
    currency: USD
  capabilities:
    supports_vision: false
    supports_function_calling: true
    supports_streaming: true
    modalities:
    - text
    - text->text
  metadata:
    architecture: Qwen
  updated_at: 2025-12-19 00:46:07.740489+00:00
- model_id: qwen/qwen2.5-vl-72b-instruct
  name: 'Qwen: Qwen2.5 VL 72B Instruct'
  provider: openrouter
  description: Qwen2.5-VL is proficient in recognizing common objects such as flowers,
    birds, fish, and insects. It is also highly capable of analyzing texts, charts,
    icons, graphics, and layouts within images.
  context_length: 32768
  pricing:
    prompt: 3.0e-08
    completion: 1.3e-07
    image: 0.0
    request: 0.0
    currency: USD
  capabilities:
    supports_vision: true
    supports_function_calling: false
    supports_streaming: true
    modalities:
    - text
    - image->text
  metadata:
    architecture: Qwen
  updated_at: 2025-12-19 00:46:07.740502+00:00
- model_id: qwen/qwen-plus
  name: 'Qwen: Qwen-Plus'
  provider: openrouter
  description: Qwen-Plus, based on the Qwen2.5 foundation model, is a 131K context
    model with a balanced performance, speed, and cost combination.
  context_length: 131072
  pricing:
    prompt: 4.0e-07
    completion: 1.2e-06
    image: 0.0
    request: 0.0
    currency: USD
  capabilities:
    supports_vision: false
    supports_function_calling: true
    supports_streaming: true
    modalities:
    - text
    - text->text
  metadata:
    architecture: Qwen
  updated_at: 2025-12-19 00:46:07.740512+00:00
- model_id: qwen/qwen-max
  name: 'Qwen: Qwen-Max '
  provider: openrouter
  description: Qwen-Max, based on Qwen2.5, provides the best inference performance
    among [Qwen models](/qwen), especially for complex multi-step tasks. It's a large-scale
    MoE model that has been pretrained on over 20 trillion tokens and further post-trained
    with curated Supervised Fine-Tuning (SFT) and Reinforcement Learning from Human
    Feedback (RLHF) methodologies. The parameter count is unknown.
  context_length: 32768
  pricing:
    prompt: 1.6e-06
    completion: 6.4e-06
    image: 0.0
    request: 0.0
    currency: USD
  capabilities:
    supports_vision: false
    supports_function_calling: true
    supports_streaming: true
    modalities:
    - text
    - text->text
  metadata:
    architecture: Qwen
  updated_at: 2025-12-19 00:46:07.740523+00:00
- model_id: openai/o3-mini
  name: 'OpenAI: o3 Mini'
  provider: openrouter
  description: 'OpenAI o3-mini is a cost-efficient language model optimized for STEM
    reasoning tasks, particularly excelling in science, mathematics, and coding.


    This model supports the `reasoning_effort` parameter, which can be set to "high",
    "medium", or "low" to control the thinking time of the model. The default is "medium".
    OpenRouter also offers the model slug `openai/o3-mini-high` to default the parameter
    to "high".


    The model features three adjustable reasoning effort levels and supports key developer
    capabilities including function calling, structured outputs, and streaming, though
    it does not include vision processing capabilities.


    The model demonstrates significant improvements over its predecessor, with expert
    testers preferring its responses 56% of the time and noting a 39% reduction in
    major errors on complex questions. With medium reasoning effort settings, o3-mini
    matches the performance of the larger o1 model on challenging reasoning evaluations
    like AIME and GPQA, while maintaining lower latency and cost.'
  context_length: 200000
  pricing:
    prompt: 1.1e-06
    completion: 4.4e-06
    image: 0.0
    request: 0.0
    currency: USD
  capabilities:
    supports_vision: false
    supports_function_calling: true
    supports_streaming: true
    modalities:
    - text
    - text->text
  metadata:
    architecture: GPT
  updated_at: 2025-12-19 00:46:07.740531+00:00
- model_id: mistralai/mistral-small-24b-instruct-2501
  name: 'Mistral: Mistral Small 3'
  provider: openrouter
  description: 'Mistral Small 3 is a 24B-parameter language model optimized for low-latency
    performance across common AI tasks. Released under the Apache 2.0 license, it
    features both pre-trained and instruction-tuned versions designed for efficient
    local deployment.


    The model achieves 81% accuracy on the MMLU benchmark and performs competitively
    with larger models like Llama 3.3 70B and Qwen 32B, while operating at three times
    the speed on equivalent hardware. [Read the blog post about the model here.](https://mistral.ai/news/mistral-small-3/)'
  context_length: 32768
  pricing:
    prompt: 3.0e-08
    completion: 1.1e-07
    image: 0.0
    request: 0.0
    currency: USD
  capabilities:
    supports_vision: false
    supports_function_calling: true
    supports_streaming: true
    modalities:
    - text
    - text->text
  metadata:
    architecture: Mistral
  updated_at: 2025-12-19 00:46:07.740541+00:00
- model_id: deepseek/deepseek-r1-distill-qwen-32b
  name: 'DeepSeek: R1 Distill Qwen 32B'
  provider: openrouter
  description: 'DeepSeek R1 Distill Qwen 32B is a distilled large language model based
    on [Qwen 2.5 32B](https://huggingface.co/Qwen/Qwen2.5-32B), using outputs from
    [DeepSeek R1](/deepseek/deepseek-r1). It outperforms OpenAI''s o1-mini across
    various benchmarks, achieving new state-of-the-art results for dense models.\n\nOther
    benchmark results include:\n\n- AIME 2024 pass@1: 72.6\n- MATH-500 pass@1: 94.3\n-
    CodeForces Rating: 1691\n\nThe model leverages fine-tuning from DeepSeek R1''s
    outputs, enabling competitive performance comparable to larger frontier models.'
  context_length: 64000
  pricing:
    prompt: 2.4e-07
    completion: 2.4e-07
    image: 0.0
    request: 0.0
    currency: USD
  capabilities:
    supports_vision: false
    supports_function_calling: false
    supports_streaming: true
    modalities:
    - text
    - text->text
  metadata:
    architecture: Qwen
  updated_at: 2025-12-19 00:46:07.740549+00:00
- model_id: deepseek/deepseek-r1-distill-qwen-14b
  name: 'DeepSeek: R1 Distill Qwen 14B'
  provider: openrouter
  description: 'DeepSeek R1 Distill Qwen 14B is a distilled large language model based
    on [Qwen 2.5 14B](https://huggingface.co/deepseek-ai/DeepSeek-R1-Distill-Qwen-14B),
    using outputs from [DeepSeek R1](/deepseek/deepseek-r1). It outperforms OpenAI''s
    o1-mini across various benchmarks, achieving new state-of-the-art results for
    dense models.


    Other benchmark results include:


    - AIME 2024 pass@1: 69.7

    - MATH-500 pass@1: 93.9

    - CodeForces Rating: 1481


    The model leverages fine-tuning from DeepSeek R1''s outputs, enabling competitive
    performance comparable to larger frontier models.'
  context_length: 32768
  pricing:
    prompt: 1.2e-07
    completion: 1.2e-07
    image: 0.0
    request: 0.0
    currency: USD
  capabilities:
    supports_vision: false
    supports_function_calling: false
    supports_streaming: true
    modalities:
    - text
    - text->text
  metadata:
    architecture: Qwen
  updated_at: 2025-12-19 00:46:07.740559+00:00
- model_id: perplexity/sonar-reasoning
  name: 'Perplexity: Sonar Reasoning'
  provider: openrouter
  description: 'Sonar Reasoning is a reasoning model provided by Perplexity based
    on [DeepSeek R1](/deepseek/deepseek-r1).


    It allows developers to utilize long chain of thought with built-in web search.
    Sonar Reasoning is uncensored and hosted in US datacenters. '
  context_length: 127000
  pricing:
    prompt: 1.0e-06
    completion: 5.0e-06
    image: 0.0
    request: 0.005
    currency: USD
  capabilities:
    supports_vision: false
    supports_function_calling: false
    supports_streaming: true
    modalities:
    - text
    - text->text
  metadata:
    architecture: Other
  updated_at: 2025-12-19 00:46:07.740569+00:00
- model_id: perplexity/sonar
  name: 'Perplexity: Sonar'
  provider: openrouter
  description: Sonar is lightweight, affordable, fast, and simple to use — now featuring
    citations and the ability to customize sources. It is designed for companies seeking
    to integrate lightweight question-and-answer features optimized for speed.
  context_length: 127072
  pricing:
    prompt: 1.0e-06
    completion: 1.0e-06
    image: 0.0
    request: 0.005
    currency: USD
  capabilities:
    supports_vision: true
    supports_function_calling: false
    supports_streaming: true
    modalities:
    - text
    - image->text
  metadata:
    architecture: Other
  updated_at: 2025-12-19 00:46:07.740578+00:00
- model_id: deepseek/deepseek-r1-distill-llama-70b
  name: 'DeepSeek: R1 Distill Llama 70B'
  provider: openrouter
  description: 'DeepSeek R1 Distill Llama 70B is a distilled large language model
    based on [Llama-3.3-70B-Instruct](/meta-llama/llama-3.3-70b-instruct), using outputs
    from [DeepSeek R1](/deepseek/deepseek-r1). The model combines advanced distillation
    techniques to achieve high performance across multiple benchmarks, including:


    - AIME 2024 pass@1: 70.0

    - MATH-500 pass@1: 94.5

    - CodeForces Rating: 1633


    The model leverages fine-tuning from DeepSeek R1''s outputs, enabling competitive
    performance comparable to larger frontier models.'
  context_length: 131072
  pricing:
    prompt: 3.0e-08
    completion: 1.3e-07
    image: 0.0
    request: 0.0
    currency: USD
  capabilities:
    supports_vision: false
    supports_function_calling: true
    supports_streaming: true
    modalities:
    - text
    - text->text
  metadata:
    architecture: Llama3
  updated_at: 2025-12-19 00:46:07.740587+00:00
- model_id: deepseek/deepseek-r1
  name: 'DeepSeek: R1'
  provider: openrouter
  description: 'DeepSeek R1 is here: Performance on par with [OpenAI o1](/openai/o1),
    but open-sourced and with fully open reasoning tokens. It''s 671B parameters in
    size, with 37B active in an inference pass.


    Fully open-source model & [technical report](https://api-docs.deepseek.com/news/news250120).


    MIT licensed: Distill & commercialize freely!'
  context_length: 163840
  pricing:
    prompt: 3.0e-07
    completion: 1.2e-06
    image: 0.0
    request: 0.0
    currency: USD
  capabilities:
    supports_vision: false
    supports_function_calling: true
    supports_streaming: true
    modalities:
    - text
    - text->text
  metadata:
    architecture: DeepSeek
  updated_at: 2025-12-19 00:46:07.740598+00:00
- model_id: minimax/minimax-01
  name: 'MiniMax: MiniMax-01'
  provider: openrouter
  description: 'MiniMax-01 is a combines MiniMax-Text-01 for text generation and MiniMax-VL-01
    for image understanding. It has 456 billion parameters, with 45.9 billion parameters
    activated per inference, and can handle a context of up to 4 million tokens.


    The text model adopts a hybrid architecture that combines Lightning Attention,
    Softmax Attention, and Mixture-of-Experts (MoE). The image model adopts the “ViT-MLP-LLM”
    framework and is trained on top of the text model.


    To read more about the release, see: https://www.minimaxi.com/en/news/minimax-01-series-2'
  context_length: 1000192
  pricing:
    prompt: 2.0e-07
    completion: 1.1e-06
    image: 0.0
    request: 0.0
    currency: USD
  capabilities:
    supports_vision: true
    supports_function_calling: false
    supports_streaming: true
    modalities:
    - text
    - image->text
  metadata:
    architecture: Other
  updated_at: 2025-12-19 00:46:07.740609+00:00
- model_id: microsoft/phi-4
  name: 'Microsoft: Phi 4'
  provider: openrouter
  description: "[Microsoft Research](/microsoft) Phi-4 is designed to perform well\
    \ in complex reasoning tasks and can operate efficiently in situations with limited\
    \ memory or where quick responses are needed. \n\nAt 14 billion parameters, it\
    \ was trained on a mix of high-quality synthetic datasets, data from curated websites,\
    \ and academic materials. It has undergone careful improvement to follow instructions\
    \ accurately and maintain strong safety standards. It works best with English\
    \ language inputs.\n\nFor more information, please see [Phi-4 Technical Report](https://arxiv.org/pdf/2412.08905)\n"
  context_length: 16384
  pricing:
    prompt: 6.0e-08
    completion: 1.4e-07
    image: 0.0
    request: 0.0
    currency: USD
  capabilities:
    supports_vision: false
    supports_function_calling: false
    supports_streaming: true
    modalities:
    - text
    - text->text
  metadata:
    architecture: Other
  updated_at: 2025-12-19 00:46:07.740617+00:00
- model_id: sao10k/l3.1-70b-hanami-x1
  name: 'Sao10K: Llama 3.1 70B Hanami x1'
  provider: openrouter
  description: This is [Sao10K](/sao10k)'s experiment over [Euryale v2.2](/sao10k/l3.1-euryale-70b).
  context_length: 16000
  pricing:
    prompt: 3.0e-06
    completion: 3.0e-06
    image: 0.0
    request: 0.0
    currency: USD
  capabilities:
    supports_vision: false
    supports_function_calling: false
    supports_streaming: true
    modalities:
    - text
    - text->text
  metadata:
    architecture: Llama3
  updated_at: 2025-12-19 00:46:07.740626+00:00
- model_id: deepseek/deepseek-chat
  name: 'DeepSeek: DeepSeek V3'
  provider: openrouter
  description: 'DeepSeek-V3 is the latest model from the DeepSeek team, building upon
    the instruction following and coding abilities of the previous versions. Pre-trained
    on nearly 15 trillion tokens, the reported evaluations reveal that the model outperforms
    other open-source models and rivals leading closed-source models.


    For model details, please visit [the DeepSeek-V3 repo](https://github.com/deepseek-ai/DeepSeek-V3)
    for more information, or see the [launch announcement](https://api-docs.deepseek.com/news/news1226).'
  context_length: 163840
  pricing:
    prompt: 3.0e-07
    completion: 1.2e-06
    image: 0.0
    request: 0.0
    currency: USD
  capabilities:
    supports_vision: false
    supports_function_calling: true
    supports_streaming: true
    modalities:
    - text
    - text->text
  metadata:
    architecture: DeepSeek
  updated_at: 2025-12-19 00:46:07.740636+00:00
- model_id: sao10k/l3.3-euryale-70b
  name: 'Sao10K: Llama 3.3 Euryale 70B'
  provider: openrouter
  description: Euryale L3.3 70B is a model focused on creative roleplay from [Sao10k](https://ko-fi.com/sao10k).
    It is the successor of [Euryale L3 70B v2.2](/models/sao10k/l3-euryale-70b).
  context_length: 131072
  pricing:
    prompt: 6.5e-07
    completion: 7.5e-07
    image: 0.0
    request: 0.0
    currency: USD
  capabilities:
    supports_vision: false
    supports_function_calling: false
    supports_streaming: true
    modalities:
    - text
    - text->text
  metadata:
    architecture: Llama3
  updated_at: 2025-12-19 00:46:07.740645+00:00
- model_id: openai/o1
  name: 'OpenAI: o1'
  provider: openrouter
  description: "The latest and strongest model family from OpenAI, o1 is designed\
    \ to spend more time thinking before responding. The o1 model series is trained\
    \ with large-scale reinforcement learning to reason using chain of thought. \n\
    \nThe o1 models are optimized for math, science, programming, and other STEM-related\
    \ tasks. They consistently exhibit PhD-level accuracy on benchmarks in physics,\
    \ chemistry, and biology. Learn more in the [launch announcement](https://openai.com/o1).\n"
  context_length: 200000
  pricing:
    prompt: 1.5e-05
    completion: 6.0e-05
    image: 0.021675
    request: 0.0
    currency: USD
  capabilities:
    supports_vision: true
    supports_function_calling: true
    supports_streaming: true
    modalities:
    - text
    - image->text
  metadata:
    architecture: GPT
  updated_at: 2025-12-19 00:46:07.740657+00:00
- model_id: cohere/command-r7b-12-2024
  name: 'Cohere: Command R7B (12-2024)'
  provider: openrouter
  description: 'Command R7B (12-2024) is a small, fast update of the Command R+ model,
    delivered in December 2024. It excels at RAG, tool use, agents, and similar tasks
    requiring complex reasoning and multiple steps.


    Use of this model is subject to Cohere''s [Usage Policy](https://docs.cohere.com/docs/usage-policy)
    and [SaaS Agreement](https://cohere.com/saas-agreement).'
  context_length: 128000
  pricing:
    prompt: 3.75e-08
    completion: 1.5e-07
    image: 0.0
    request: 0.0
    currency: USD
  capabilities:
    supports_vision: false
    supports_function_calling: false
    supports_streaming: true
    modalities:
    - text
    - text->text
  metadata:
    architecture: Cohere
  updated_at: 2025-12-19 00:46:07.740670+00:00
- model_id: google/gemini-2.0-flash-exp:free
  name: 'Google: Gemini 2.0 Flash Experimental (free)'
  provider: openrouter
  description: Gemini Flash 2.0 offers a significantly faster time to first token
    (TTFT) compared to [Gemini Flash 1.5](/google/gemini-flash-1.5), while maintaining
    quality on par with larger models like [Gemini Pro 1.5](/google/gemini-pro-1.5).
    It introduces notable enhancements in multimodal understanding, coding capabilities,
    complex instruction following, and function calling. These advancements come together
    to deliver more seamless and robust agentic experiences.
  context_length: 1048576
  pricing:
    prompt: 0.0
    completion: 0.0
    image: 0.0
    request: 0.0
    currency: USD
  capabilities:
    supports_vision: true
    supports_function_calling: true
    supports_streaming: true
    modalities:
    - text
    - image->text
  metadata:
    architecture: Gemini
  updated_at: 2025-12-19 00:46:07.740680+00:00
- model_id: meta-llama/llama-3.3-70b-instruct:free
  name: 'Meta: Llama 3.3 70B Instruct (free)'
  provider: openrouter
  description: 'The Meta Llama 3.3 multilingual large language model (LLM) is a pretrained
    and instruction tuned generative model in 70B (text in/text out). The Llama 3.3
    instruction tuned text only model is optimized for multilingual dialogue use cases
    and outperforms many of the available open source and closed chat models on common
    industry benchmarks.


    Supported languages: English, German, French, Italian, Portuguese, Hindi, Spanish,
    and Thai.


    [Model Card](https://github.com/meta-llama/llama-models/blob/main/models/llama3_3/MODEL_CARD.md)'
  context_length: 131072
  pricing:
    prompt: 0.0
    completion: 0.0
    image: 0.0
    request: 0.0
    currency: USD
  capabilities:
    supports_vision: false
    supports_function_calling: true
    supports_streaming: true
    modalities:
    - text
    - text->text
  metadata:
    architecture: Llama3
  updated_at: 2025-12-19 00:46:07.740689+00:00
- model_id: meta-llama/llama-3.3-70b-instruct
  name: 'Meta: Llama 3.3 70B Instruct'
  provider: openrouter
  description: 'The Meta Llama 3.3 multilingual large language model (LLM) is a pretrained
    and instruction tuned generative model in 70B (text in/text out). The Llama 3.3
    instruction tuned text only model is optimized for multilingual dialogue use cases
    and outperforms many of the available open source and closed chat models on common
    industry benchmarks.


    Supported languages: English, German, French, Italian, Portuguese, Hindi, Spanish,
    and Thai.


    [Model Card](https://github.com/meta-llama/llama-models/blob/main/models/llama3_3/MODEL_CARD.md)'
  context_length: 131072
  pricing:
    prompt: 1.0e-07
    completion: 3.2e-07
    image: 0.0
    request: 0.0
    currency: USD
  capabilities:
    supports_vision: false
    supports_function_calling: true
    supports_streaming: true
    modalities:
    - text
    - text->text
  metadata:
    architecture: Llama3
  updated_at: 2025-12-19 00:46:07.740697+00:00
- model_id: amazon/nova-lite-v1
  name: 'Amazon: Nova Lite 1.0'
  provider: openrouter
  description: 'Amazon Nova Lite 1.0 is a very low-cost multimodal model from Amazon
    that focused on fast processing of image, video, and text inputs to generate text
    output. Amazon Nova Lite can handle real-time customer interactions, document
    analysis, and visual question-answering tasks with high accuracy.


    With an input context of 300K tokens, it can analyze multiple images or up to
    30 minutes of video in a single input.'
  context_length: 300000
  pricing:
    prompt: 6.0e-08
    completion: 2.4e-07
    image: 9.0e-05
    request: 0.0
    currency: USD
  capabilities:
    supports_vision: true
    supports_function_calling: true
    supports_streaming: true
    modalities:
    - text
    - image->text
  metadata:
    architecture: Nova
  updated_at: 2025-12-19 00:46:07.740705+00:00
- model_id: amazon/nova-micro-v1
  name: 'Amazon: Nova Micro 1.0'
  provider: openrouter
  description: Amazon Nova Micro 1.0 is a text-only model that delivers the lowest
    latency responses in the Amazon Nova family of models at a very low cost. With
    a context length of 128K tokens and optimized for speed and cost, Amazon Nova
    Micro excels at tasks such as text summarization, translation, content classification,
    interactive chat, and brainstorming. It has  simple mathematical reasoning and
    coding abilities.
  context_length: 128000
  pricing:
    prompt: 3.5e-08
    completion: 1.4e-07
    image: 0.0
    request: 0.0
    currency: USD
  capabilities:
    supports_vision: false
    supports_function_calling: true
    supports_streaming: true
    modalities:
    - text
    - text->text
  metadata:
    architecture: Nova
  updated_at: 2025-12-19 00:46:07.740719+00:00
- model_id: amazon/nova-pro-v1
  name: 'Amazon: Nova Pro 1.0'
  provider: openrouter
  description: 'Amazon Nova Pro 1.0 is a capable multimodal model from Amazon focused
    on providing a combination of accuracy, speed, and cost for a wide range of tasks.
    As of December 2024, it achieves state-of-the-art performance on key benchmarks
    including visual question answering (TextVQA) and video understanding (VATEX).


    Amazon Nova Pro demonstrates strong capabilities in processing both visual and
    textual information and at analyzing financial documents.


    **NOTE**: Video input is not supported at this time.'
  context_length: 300000
  pricing:
    prompt: 8.0e-07
    completion: 3.2e-06
    image: 0.0012
    request: 0.0
    currency: USD
  capabilities:
    supports_vision: true
    supports_function_calling: true
    supports_streaming: true
    modalities:
    - text
    - image->text
  metadata:
    architecture: Nova
  updated_at: 2025-12-19 00:46:07.740727+00:00
- model_id: openai/gpt-4o-2024-11-20
  name: 'OpenAI: GPT-4o (2024-11-20)'
  provider: openrouter
  description: 'The 2024-11-20 version of GPT-4o offers a leveled-up creative writing
    ability with more natural, engaging, and tailored writing to improve relevance
    & readability. It’s also better at working with uploaded files, providing deeper
    insights & more thorough responses.


    GPT-4o ("o" for "omni") is OpenAI''s latest AI model, supporting both text and
    image inputs with text outputs. It maintains the intelligence level of [GPT-4
    Turbo](/models/openai/gpt-4-turbo) while being twice as fast and 50% more cost-effective.
    GPT-4o also offers improved performance in processing non-English languages and
    enhanced visual capabilities.'
  context_length: 128000
  pricing:
    prompt: 2.5e-06
    completion: 1.0e-05
    image: 0.003613
    request: 0.0
    currency: USD
  capabilities:
    supports_vision: true
    supports_function_calling: true
    supports_streaming: true
    modalities:
    - text
    - image->text
  metadata:
    architecture: GPT
  updated_at: 2025-12-19 00:46:07.740735+00:00
- model_id: mistralai/mistral-large-2411
  name: Mistral Large 2411
  provider: openrouter
  description: 'Mistral Large 2 2411 is an update of [Mistral Large 2](/mistralai/mistral-large)
    released together with [Pixtral Large 2411](/mistralai/pixtral-large-2411)


    It provides a significant upgrade on the previous [Mistral Large 24.07](/mistralai/mistral-large-2407),
    with notable improvements in long context understanding, a new system prompt,
    and more accurate function calling.'
  context_length: 131072
  pricing:
    prompt: 2.0e-06
    completion: 6.0e-06
    image: 0.0
    request: 0.0
    currency: USD
  capabilities:
    supports_vision: false
    supports_function_calling: true
    supports_streaming: true
    modalities:
    - text
    - text->text
  metadata:
    architecture: Mistral
  updated_at: 2025-12-19 00:46:07.740743+00:00
- model_id: mistralai/mistral-large-2407
  name: Mistral Large 2407
  provider: openrouter
  description: 'This is Mistral AI''s flagship model, Mistral Large 2 (version mistral-large-2407).
    It''s a proprietary weights-available model and excels at reasoning, code, JSON,
    chat, and more. Read the launch announcement [here](https://mistral.ai/news/mistral-large-2407/).


    It supports dozens of languages including French, German, Spanish, Italian, Portuguese,
    Arabic, Hindi, Russian, Chinese, Japanese, and Korean, along with 80+ coding languages
    including Python, Java, C, C++, JavaScript, and Bash. Its long context window
    allows precise information recall from large documents.

    '
  context_length: 131072
  pricing:
    prompt: 2.0e-06
    completion: 6.0e-06
    image: 0.0
    request: 0.0
    currency: USD
  capabilities:
    supports_vision: false
    supports_function_calling: true
    supports_streaming: true
    modalities:
    - text
    - text->text
  metadata:
    architecture: Mistral
  updated_at: 2025-12-19 00:46:07.740753+00:00
- model_id: mistralai/pixtral-large-2411
  name: 'Mistral: Pixtral Large 2411'
  provider: openrouter
  description: 'Pixtral Large is a 124B parameter, open-weight, multimodal model built
    on top of [Mistral Large 2](/mistralai/mistral-large-2411). The model is able
    to understand documents, charts and natural images.


    The model is available under the Mistral Research License (MRL) for research and
    educational use, and the Mistral Commercial License for experimentation, testing,
    and production for commercial purposes.


    '
  context_length: 131072
  pricing:
    prompt: 2.0e-06
    completion: 6.0e-06
    image: 0.002888
    request: 0.0
    currency: USD
  capabilities:
    supports_vision: true
    supports_function_calling: true
    supports_streaming: true
    modalities:
    - text
    - image->text
  metadata:
    architecture: Mistral
  updated_at: 2025-12-19 00:46:07.740776+00:00
- model_id: qwen/qwen-2.5-coder-32b-instruct
  name: Qwen2.5 Coder 32B Instruct
  provider: openrouter
  description: "Qwen2.5-Coder is the latest series of Code-Specific Qwen large language\
    \ models (formerly known as CodeQwen). Qwen2.5-Coder brings the following improvements\
    \ upon CodeQwen1.5:\n\n- Significantly improvements in **code generation**, **code\
    \ reasoning** and **code fixing**. \n- A more comprehensive foundation for real-world\
    \ applications such as **Code Agents**. Not only enhancing coding capabilities\
    \ but also maintaining its strengths in mathematics and general competencies.\n\
    \nTo read more about its evaluation results, check out [Qwen 2.5 Coder's blog](https://qwenlm.github.io/blog/qwen2.5-coder-family/)."
  context_length: 32768
  pricing:
    prompt: 3.0e-08
    completion: 1.1e-07
    image: 0.0
    request: 0.0
    currency: USD
  capabilities:
    supports_vision: false
    supports_function_calling: false
    supports_streaming: true
    modalities:
    - text
    - text->text
  metadata:
    architecture: Qwen
  updated_at: 2025-12-19 00:46:07.740787+00:00
- model_id: raifle/sorcererlm-8x22b
  name: SorcererLM 8x22B
  provider: openrouter
  description: 'SorcererLM is an advanced RP and storytelling model, built as a Low-rank
    16-bit LoRA fine-tuned on [WizardLM-2 8x22B](/microsoft/wizardlm-2-8x22b).


    - Advanced reasoning and emotional intelligence for engaging and immersive interactions

    - Vivid writing capabilities enriched with spatial and contextual awareness

    - Enhanced narrative depth, promoting creative and dynamic storytelling'
  context_length: 16000
  pricing:
    prompt: 4.5e-06
    completion: 4.5e-06
    image: 0.0
    request: 0.0
    currency: USD
  capabilities:
    supports_vision: false
    supports_function_calling: false
    supports_streaming: true
    modalities:
    - text
    - text->text
  metadata:
    architecture: Mistral
  updated_at: 2025-12-19 00:46:07.740796+00:00
- model_id: thedrummer/unslopnemo-12b
  name: 'TheDrummer: UnslopNemo 12B'
  provider: openrouter
  description: UnslopNemo v4.1 is the latest addition from the creator of Rocinante,
    designed for adventure writing and role-play scenarios.
  context_length: 32768
  pricing:
    prompt: 4.0e-07
    completion: 4.0e-07
    image: 0.0
    request: 0.0
    currency: USD
  capabilities:
    supports_vision: false
    supports_function_calling: true
    supports_streaming: true
    modalities:
    - text
    - text->text
  metadata:
    architecture: Mistral
  updated_at: 2025-12-19 00:46:07.740806+00:00
- model_id: anthropic/claude-3.5-haiku-20241022
  name: 'Anthropic: Claude 3.5 Haiku (2024-10-22)'
  provider: openrouter
  description: 'Claude 3.5 Haiku features enhancements across all skill sets including
    coding, tool use, and reasoning. As the fastest model in the Anthropic lineup,
    it offers rapid response times suitable for applications that require high interactivity
    and low latency, such as user-facing chatbots and on-the-fly code completions.
    It also excels in specialized tasks like data extraction and real-time content
    moderation, making it a versatile tool for a broad range of industries.


    It does not support image inputs.


    See the launch announcement and benchmark results [here](https://www.anthropic.com/news/3-5-models-and-computer-use)'
  context_length: 200000
  pricing:
    prompt: 8.0e-07
    completion: 4.0e-06
    image: 0.0
    request: 0.0
    currency: USD
  capabilities:
    supports_vision: true
    supports_function_calling: true
    supports_streaming: true
    modalities:
    - text
    - image->text
  metadata:
    architecture: Claude
  updated_at: 2025-12-19 00:46:07.740815+00:00
- model_id: anthropic/claude-3.5-haiku
  name: 'Anthropic: Claude 3.5 Haiku'
  provider: openrouter
  description: 'Claude 3.5 Haiku features offers enhanced capabilities in speed, coding
    accuracy, and tool use. Engineered to excel in real-time applications, it delivers
    quick response times that are essential for dynamic tasks such as chat interactions
    and immediate coding suggestions.


    This makes it highly suitable for environments that demand both speed and precision,
    such as software development, customer service bots, and data management systems.


    This model is currently pointing to [Claude 3.5 Haiku (2024-10-22)](/anthropic/claude-3-5-haiku-20241022).'
  context_length: 200000
  pricing:
    prompt: 8.0e-07
    completion: 4.0e-06
    image: 0.0
    request: 0.0
    currency: USD
  capabilities:
    supports_vision: true
    supports_function_calling: true
    supports_streaming: true
    modalities:
    - text
    - image->text
  metadata:
    architecture: Claude
  updated_at: 2025-12-19 00:46:07.740825+00:00
- model_id: anthracite-org/magnum-v4-72b
  name: Magnum v4 72B
  provider: openrouter
  description: 'This is a series of models designed to replicate the prose quality
    of the Claude 3 models, specifically Sonnet(https://openrouter.ai/anthropic/claude-3.5-sonnet)
    and Opus(https://openrouter.ai/anthropic/claude-3-opus).


    The model is fine-tuned on top of [Qwen2.5 72B](https://openrouter.ai/qwen/qwen-2.5-72b-instruct).'
  context_length: 16384
  pricing:
    prompt: 3.0e-06
    completion: 5.0e-06
    image: 0.0
    request: 0.0
    currency: USD
  capabilities:
    supports_vision: false
    supports_function_calling: false
    supports_streaming: true
    modalities:
    - text
    - text->text
  metadata:
    architecture: Qwen
  updated_at: 2025-12-19 00:46:07.740835+00:00
- model_id: anthropic/claude-3.5-sonnet
  name: 'Anthropic: Claude 3.5 Sonnet'
  provider: openrouter
  description: 'New Claude 3.5 Sonnet delivers better-than-Opus capabilities, faster-than-Sonnet
    speeds, at the same Sonnet prices. Sonnet is particularly good at:


    - Coding: Scores ~49% on SWE-Bench Verified, higher than the last best score,
    and without any fancy prompt scaffolding

    - Data science: Augments human data science expertise; navigates unstructured
    data while using multiple tools for insights

    - Visual processing: excelling at interpreting charts, graphs, and images, accurately
    transcribing text to derive insights beyond just the text alone

    - Agentic tasks: exceptional tool use, making it great at agentic tasks (i.e.
    complex, multi-step problem solving tasks that require engaging with other systems)


    #multimodal'
  context_length: 200000
  pricing:
    prompt: 6.0e-06
    completion: 3.0e-05
    image: 0.0
    request: 0.0
    currency: USD
  capabilities:
    supports_vision: true
    supports_function_calling: true
    supports_streaming: true
    modalities:
    - text
    - image->text
  metadata:
    architecture: Claude
  updated_at: 2025-12-19 00:46:07.740848+00:00
- model_id: mistralai/ministral-8b
  name: 'Mistral: Ministral 8B'
  provider: openrouter
  description: Ministral 8B is an 8B parameter model featuring a unique interleaved
    sliding-window attention pattern for faster, memory-efficient inference. Designed
    for edge use cases, it supports up to 128k context length and excels in knowledge
    and reasoning tasks. It outperforms peers in the sub-10B category, making it perfect
    for low-latency, privacy-first applications.
  context_length: 131072
  pricing:
    prompt: 1.0e-07
    completion: 1.0e-07
    image: 0.0
    request: 0.0
    currency: USD
  capabilities:
    supports_vision: false
    supports_function_calling: true
    supports_streaming: true
    modalities:
    - text
    - text->text
  metadata:
    architecture: Mistral
  updated_at: 2025-12-19 00:46:07.740856+00:00
- model_id: mistralai/ministral-3b
  name: 'Mistral: Ministral 3B'
  provider: openrouter
  description: Ministral 3B is a 3B parameter model optimized for on-device and edge
    computing. It excels in knowledge, commonsense reasoning, and function-calling,
    outperforming larger models like Mistral 7B on most benchmarks. Supporting up
    to 128k context length, it’s ideal for orchestrating agentic workflows and specialist
    tasks with efficient inference.
  context_length: 131072
  pricing:
    prompt: 4.0e-08
    completion: 4.0e-08
    image: 0.0
    request: 0.0
    currency: USD
  capabilities:
    supports_vision: false
    supports_function_calling: true
    supports_streaming: true
    modalities:
    - text
    - text->text
  metadata:
    architecture: Mistral
  updated_at: 2025-12-19 00:46:07.740866+00:00
- model_id: qwen/qwen-2.5-7b-instruct
  name: 'Qwen: Qwen2.5 7B Instruct'
  provider: openrouter
  description: 'Qwen2.5 7B is the latest series of Qwen large language models. Qwen2.5
    brings the following improvements upon Qwen2:


    - Significantly more knowledge and has greatly improved capabilities in coding
    and mathematics, thanks to our specialized expert models in these domains.


    - Significant improvements in instruction following, generating long texts (over
    8K tokens), understanding structured data (e.g, tables), and generating structured
    outputs especially JSON. More resilient to the diversity of system prompts, enhancing
    role-play implementation and condition-setting for chatbots.


    - Long-context Support up to 128K tokens and can generate up to 8K tokens.


    - Multilingual support for over 29 languages, including Chinese, English, French,
    Spanish, Portuguese, German, Italian, Russian, Japanese, Korean, Vietnamese, Thai,
    Arabic, and more.


    Usage of this model is subject to [Tongyi Qianwen LICENSE AGREEMENT](https://huggingface.co/Qwen/Qwen1.5-110B-Chat/blob/main/LICENSE).'
  context_length: 32768
  pricing:
    prompt: 4.0e-08
    completion: 1.0e-07
    image: 0.0
    request: 0.0
    currency: USD
  capabilities:
    supports_vision: false
    supports_function_calling: false
    supports_streaming: true
    modalities:
    - text
    - text->text
  metadata:
    architecture: Qwen
  updated_at: 2025-12-19 00:46:07.740878+00:00
- model_id: nvidia/llama-3.1-nemotron-70b-instruct
  name: 'NVIDIA: Llama 3.1 Nemotron 70B Instruct'
  provider: openrouter
  description: 'NVIDIA''s Llama 3.1 Nemotron 70B is a language model designed for
    generating precise and useful responses. Leveraging [Llama 3.1 70B](/models/meta-llama/llama-3.1-70b-instruct)
    architecture and Reinforcement Learning from Human Feedback (RLHF), it excels
    in automatic alignment benchmarks. This model is tailored for applications requiring
    high accuracy in helpfulness and response generation, suitable for diverse user
    queries across multiple domains.


    Usage of this model is subject to [Meta''s Acceptable Use Policy](https://www.llama.com/llama3/use-policy/).'
  context_length: 131072
  pricing:
    prompt: 1.2e-06
    completion: 1.2e-06
    image: 0.0
    request: 0.0
    currency: USD
  capabilities:
    supports_vision: false
    supports_function_calling: true
    supports_streaming: true
    modalities:
    - text
    - text->text
  metadata:
    architecture: Llama3
  updated_at: 2025-12-19 00:46:07.740886+00:00
- model_id: inflection/inflection-3-pi
  name: 'Inflection: Inflection 3 Pi'
  provider: openrouter
  description: 'Inflection 3 Pi powers Inflection''s [Pi](https://pi.ai) chatbot,
    including backstory, emotional intelligence, productivity, and safety. It has
    access to recent news, and excels in scenarios like customer support and roleplay.


    Pi has been trained to mirror your tone and style, if you use more emojis, so
    will Pi! Try experimenting with various prompts and conversation styles.'
  context_length: 8000
  pricing:
    prompt: 2.5e-06
    completion: 1.0e-05
    image: 0.0
    request: 0.0
    currency: USD
  capabilities:
    supports_vision: false
    supports_function_calling: false
    supports_streaming: true
    modalities:
    - text
    - text->text
  metadata:
    architecture: Other
  updated_at: 2025-12-19 00:46:07.740894+00:00
- model_id: inflection/inflection-3-productivity
  name: 'Inflection: Inflection 3 Productivity'
  provider: openrouter
  description: 'Inflection 3 Productivity is optimized for following instructions.
    It is better for tasks requiring JSON output or precise adherence to provided
    guidelines. It has access to recent news.


    For emotional intelligence similar to Pi, see [Inflect 3 Pi](/inflection/inflection-3-pi)


    See [Inflection''s announcement](https://inflection.ai/blog/enterprise) for more
    details.'
  context_length: 8000
  pricing:
    prompt: 2.5e-06
    completion: 1.0e-05
    image: 0.0
    request: 0.0
    currency: USD
  capabilities:
    supports_vision: false
    supports_function_calling: false
    supports_streaming: true
    modalities:
    - text
    - text->text
  metadata:
    architecture: Other
  updated_at: 2025-12-19 00:46:07.740904+00:00
- model_id: thedrummer/rocinante-12b
  name: 'TheDrummer: Rocinante 12B'
  provider: openrouter
  description: 'Rocinante 12B is designed for engaging storytelling and rich prose.


    Early testers have reported:

    - Expanded vocabulary with unique and expressive word choices

    - Enhanced creativity for vivid narratives

    - Adventure-filled and captivating stories'
  context_length: 32768
  pricing:
    prompt: 1.7e-07
    completion: 4.3e-07
    image: 0.0
    request: 0.0
    currency: USD
  capabilities:
    supports_vision: false
    supports_function_calling: true
    supports_streaming: true
    modalities:
    - text
    - text->text
  metadata:
    architecture: Qwen
  updated_at: 2025-12-19 00:46:07.740918+00:00
- model_id: meta-llama/llama-3.2-3b-instruct:free
  name: 'Meta: Llama 3.2 3B Instruct (free)'
  provider: openrouter
  description: 'Llama 3.2 3B is a 3-billion-parameter multilingual large language
    model, optimized for advanced natural language processing tasks like dialogue
    generation, reasoning, and summarization. Designed with the latest transformer
    architecture, it supports eight languages, including English, Spanish, and Hindi,
    and is adaptable for additional languages.


    Trained on 9 trillion tokens, the Llama 3.2 3B model excels in instruction-following,
    complex reasoning, and tool use. Its balanced performance makes it ideal for applications
    needing accuracy and efficiency in text generation across multilingual settings.


    Click here for the [original model card](https://github.com/meta-llama/llama-models/blob/main/models/llama3_2/MODEL_CARD.md).


    Usage of this model is subject to [Meta''s Acceptable Use Policy](https://www.llama.com/llama3/use-policy/).'
  context_length: 131072
  pricing:
    prompt: 0.0
    completion: 0.0
    image: 0.0
    request: 0.0
    currency: USD
  capabilities:
    supports_vision: false
    supports_function_calling: false
    supports_streaming: true
    modalities:
    - text
    - text->text
  metadata:
    architecture: Llama3
  updated_at: 2025-12-19 00:46:07.740926+00:00
- model_id: meta-llama/llama-3.2-3b-instruct
  name: 'Meta: Llama 3.2 3B Instruct'
  provider: openrouter
  description: 'Llama 3.2 3B is a 3-billion-parameter multilingual large language
    model, optimized for advanced natural language processing tasks like dialogue
    generation, reasoning, and summarization. Designed with the latest transformer
    architecture, it supports eight languages, including English, Spanish, and Hindi,
    and is adaptable for additional languages.


    Trained on 9 trillion tokens, the Llama 3.2 3B model excels in instruction-following,
    complex reasoning, and tool use. Its balanced performance makes it ideal for applications
    needing accuracy and efficiency in text generation across multilingual settings.


    Click here for the [original model card](https://github.com/meta-llama/llama-models/blob/main/models/llama3_2/MODEL_CARD.md).


    Usage of this model is subject to [Meta''s Acceptable Use Policy](https://www.llama.com/llama3/use-policy/).'
  context_length: 131072
  pricing:
    prompt: 2.0e-08
    completion: 2.0e-08
    image: 0.0
    request: 0.0
    currency: USD
  capabilities:
    supports_vision: false
    supports_function_calling: true
    supports_streaming: true
    modalities:
    - text
    - text->text
  metadata:
    architecture: Llama3
  updated_at: 2025-12-19 00:46:07.740936+00:00
- model_id: meta-llama/llama-3.2-1b-instruct
  name: 'Meta: Llama 3.2 1B Instruct'
  provider: openrouter
  description: 'Llama 3.2 1B is a 1-billion-parameter language model focused on efficiently
    performing natural language tasks, such as summarization, dialogue, and multilingual
    text analysis. Its smaller size allows it to operate efficiently in low-resource
    environments while maintaining strong task performance.


    Supporting eight core languages and fine-tunable for more, Llama 1.3B is ideal
    for businesses or developers seeking lightweight yet powerful AI solutions that
    can operate in diverse multilingual settings without the high computational demand
    of larger models.


    Click here for the [original model card](https://github.com/meta-llama/llama-models/blob/main/models/llama3_2/MODEL_CARD.md).


    Usage of this model is subject to [Meta''s Acceptable Use Policy](https://www.llama.com/llama3/use-policy/).'
  context_length: 60000
  pricing:
    prompt: 2.7e-08
    completion: 2.0e-07
    image: 0.0
    request: 0.0
    currency: USD
  capabilities:
    supports_vision: false
    supports_function_calling: false
    supports_streaming: true
    modalities:
    - text
    - text->text
  metadata:
    architecture: Llama3
  updated_at: 2025-12-19 00:46:07.740945+00:00
- model_id: meta-llama/llama-3.2-90b-vision-instruct
  name: 'Meta: Llama 3.2 90B Vision Instruct'
  provider: openrouter
  description: 'The Llama 90B Vision model is a top-tier, 90-billion-parameter multimodal
    model designed for the most challenging visual reasoning and language tasks. It
    offers unparalleled accuracy in image captioning, visual question answering, and
    advanced image-text comprehension. Pre-trained on vast multimodal datasets and
    fine-tuned with human feedback, the Llama 90B Vision is engineered to handle the
    most demanding image-based AI tasks.


    This model is perfect for industries requiring cutting-edge multimodal AI capabilities,
    particularly those dealing with complex, real-time visual and textual analysis.


    Click here for the [original model card](https://github.com/meta-llama/llama-models/blob/main/models/llama3_2/MODEL_CARD_VISION.md).


    Usage of this model is subject to [Meta''s Acceptable Use Policy](https://www.llama.com/llama3/use-policy/).'
  context_length: 32768
  pricing:
    prompt: 3.5e-07
    completion: 4.0e-07
    image: 0.0005058
    request: 0.0
    currency: USD
  capabilities:
    supports_vision: true
    supports_function_calling: false
    supports_streaming: true
    modalities:
    - text
    - image->text
  metadata:
    architecture: Llama3
  updated_at: 2025-12-19 00:46:07.740955+00:00
- model_id: meta-llama/llama-3.2-11b-vision-instruct
  name: 'Meta: Llama 3.2 11B Vision Instruct'
  provider: openrouter
  description: 'Llama 3.2 11B Vision is a multimodal model with 11 billion parameters,
    designed to handle tasks combining visual and textual data. It excels in tasks
    such as image captioning and visual question answering, bridging the gap between
    language generation and visual reasoning. Pre-trained on a massive dataset of
    image-text pairs, it performs well in complex, high-accuracy image analysis.


    Its ability to integrate visual understanding with language processing makes it
    an ideal solution for industries requiring comprehensive visual-linguistic AI
    applications, such as content creation, AI-driven customer service, and research.


    Click here for the [original model card](https://github.com/meta-llama/llama-models/blob/main/models/llama3_2/MODEL_CARD_VISION.md).


    Usage of this model is subject to [Meta''s Acceptable Use Policy](https://www.llama.com/llama3/use-policy/).'
  context_length: 131072
  pricing:
    prompt: 4.9e-08
    completion: 4.9e-08
    image: 7.948e-05
    request: 0.0
    currency: USD
  capabilities:
    supports_vision: true
    supports_function_calling: false
    supports_streaming: true
    modalities:
    - text
    - image->text
  metadata:
    architecture: Llama3
  updated_at: 2025-12-19 00:46:07.740966+00:00
- model_id: qwen/qwen-2.5-72b-instruct
  name: Qwen2.5 72B Instruct
  provider: openrouter
  description: 'Qwen2.5 72B is the latest series of Qwen large language models. Qwen2.5
    brings the following improvements upon Qwen2:


    - Significantly more knowledge and has greatly improved capabilities in coding
    and mathematics, thanks to our specialized expert models in these domains.


    - Significant improvements in instruction following, generating long texts (over
    8K tokens), understanding structured data (e.g, tables), and generating structured
    outputs especially JSON. More resilient to the diversity of system prompts, enhancing
    role-play implementation and condition-setting for chatbots.


    - Long-context Support up to 128K tokens and can generate up to 8K tokens.


    - Multilingual support for over 29 languages, including Chinese, English, French,
    Spanish, Portuguese, German, Italian, Russian, Japanese, Korean, Vietnamese, Thai,
    Arabic, and more.


    Usage of this model is subject to [Tongyi Qianwen LICENSE AGREEMENT](https://huggingface.co/Qwen/Qwen1.5-110B-Chat/blob/main/LICENSE).'
  context_length: 32768
  pricing:
    prompt: 7.0e-08
    completion: 2.6e-07
    image: 0.0
    request: 0.0
    currency: USD
  capabilities:
    supports_vision: false
    supports_function_calling: true
    supports_streaming: true
    modalities:
    - text
    - text->text
  metadata:
    architecture: Qwen
  updated_at: 2025-12-19 00:46:07.740976+00:00
- model_id: neversleep/llama-3.1-lumimaid-8b
  name: 'NeverSleep: Lumimaid v0.2 8B'
  provider: openrouter
  description: 'Lumimaid v0.2 8B is a finetune of [Llama 3.1 8B](/models/meta-llama/llama-3.1-8b-instruct)
    with a "HUGE step up dataset wise" compared to Lumimaid v0.1. Sloppy chats output
    were purged.


    Usage of this model is subject to [Meta''s Acceptable Use Policy](https://llama.meta.com/llama3/use-policy/).'
  context_length: 32768
  pricing:
    prompt: 9.0e-08
    completion: 6.0e-07
    image: 0.0
    request: 0.0
    currency: USD
  capabilities:
    supports_vision: false
    supports_function_calling: false
    supports_streaming: true
    modalities:
    - text
    - text->text
  metadata:
    architecture: Llama3
  updated_at: 2025-12-19 00:46:07.740985+00:00
- model_id: mistralai/pixtral-12b
  name: 'Mistral: Pixtral 12B'
  provider: openrouter
  description: 'The first multi-modal, text+image-to-text model from Mistral AI. Its
    weights were launched via torrent: https://x.com/mistralai/status/1833758285167722836.'
  context_length: 32768
  pricing:
    prompt: 1.0e-07
    completion: 1.0e-07
    image: 0.0001445
    request: 0.0
    currency: USD
  capabilities:
    supports_vision: true
    supports_function_calling: true
    supports_streaming: true
    modalities:
    - text
    - image->text
  metadata:
    architecture: Mistral
  updated_at: 2025-12-19 00:46:07.740997+00:00
- model_id: cohere/command-r-08-2024
  name: 'Cohere: Command R (08-2024)'
  provider: openrouter
  description: 'command-r-08-2024 is an update of the [Command R](/models/cohere/command-r)
    with improved performance for multilingual retrieval-augmented generation (RAG)
    and tool use. More broadly, it is better at math, code and reasoning and is competitive
    with the previous version of the larger Command R+ model.


    Read the launch post [here](https://docs.cohere.com/changelog/command-gets-refreshed).


    Use of this model is subject to Cohere''s [Usage Policy](https://docs.cohere.com/docs/usage-policy)
    and [SaaS Agreement](https://cohere.com/saas-agreement).'
  context_length: 128000
  pricing:
    prompt: 1.5e-07
    completion: 6.0e-07
    image: 0.0
    request: 0.0
    currency: USD
  capabilities:
    supports_vision: false
    supports_function_calling: true
    supports_streaming: true
    modalities:
    - text
    - text->text
  metadata:
    architecture: Cohere
  updated_at: 2025-12-19 00:46:07.741006+00:00
- model_id: cohere/command-r-plus-08-2024
  name: 'Cohere: Command R+ (08-2024)'
  provider: openrouter
  description: 'command-r-plus-08-2024 is an update of the [Command R+](/models/cohere/command-r-plus)
    with roughly 50% higher throughput and 25% lower latencies as compared to the
    previous Command R+ version, while keeping the hardware footprint the same.


    Read the launch post [here](https://docs.cohere.com/changelog/command-gets-refreshed).


    Use of this model is subject to Cohere''s [Usage Policy](https://docs.cohere.com/docs/usage-policy)
    and [SaaS Agreement](https://cohere.com/saas-agreement).'
  context_length: 128000
  pricing:
    prompt: 2.5e-06
    completion: 1.0e-05
    image: 0.0
    request: 0.0
    currency: USD
  capabilities:
    supports_vision: false
    supports_function_calling: true
    supports_streaming: true
    modalities:
    - text
    - text->text
  metadata:
    architecture: Cohere
  updated_at: 2025-12-19 00:46:07.741016+00:00
- model_id: sao10k/l3.1-euryale-70b
  name: 'Sao10K: Llama 3.1 Euryale 70B v2.2'
  provider: openrouter
  description: Euryale L3.1 70B v2.2 is a model focused on creative roleplay from
    [Sao10k](https://ko-fi.com/sao10k). It is the successor of [Euryale L3 70B v2.1](/models/sao10k/l3-euryale-70b).
  context_length: 32768
  pricing:
    prompt: 6.5e-07
    completion: 7.5e-07
    image: 0.0
    request: 0.0
    currency: USD
  capabilities:
    supports_vision: false
    supports_function_calling: true
    supports_streaming: true
    modalities:
    - text
    - text->text
  metadata:
    architecture: Llama3
  updated_at: 2025-12-19 00:46:07.741027+00:00
- model_id: qwen/qwen-2.5-vl-7b-instruct:free
  name: 'Qwen: Qwen2.5-VL 7B Instruct (free)'
  provider: openrouter
  description: 'Qwen2.5 VL 7B is a multimodal LLM from the Qwen Team with the following
    key enhancements:


    - SoTA understanding of images of various resolution & ratio: Qwen2.5-VL achieves
    state-of-the-art performance on visual understanding benchmarks, including MathVista,
    DocVQA, RealWorldQA, MTVQA, etc.


    - Understanding videos of 20min+: Qwen2.5-VL can understand videos over 20 minutes
    for high-quality video-based question answering, dialog, content creation, etc.


    - Agent that can operate your mobiles, robots, etc.: with the abilities of complex
    reasoning and decision making, Qwen2.5-VL can be integrated with devices like
    mobile phones, robots, etc., for automatic operation based on visual environment
    and text instructions.


    - Multilingual Support: to serve global users, besides English and Chinese, Qwen2.5-VL
    now supports the understanding of texts in different languages inside images,
    including most European languages, Japanese, Korean, Arabic, Vietnamese, etc.


    For more details, see this [blog post](https://qwenlm.github.io/blog/qwen2-vl/)
    and [GitHub repo](https://github.com/QwenLM/Qwen2-VL).


    Usage of this model is subject to [Tongyi Qianwen LICENSE AGREEMENT](https://huggingface.co/Qwen/Qwen1.5-110B-Chat/blob/main/LICENSE).'
  context_length: 32768
  pricing:
    prompt: 0.0
    completion: 0.0
    image: 0.0
    request: 0.0
    currency: USD
  capabilities:
    supports_vision: true
    supports_function_calling: false
    supports_streaming: true
    modalities:
    - text
    - image->text
  metadata:
    architecture: Qwen
  updated_at: 2025-12-19 00:46:07.741037+00:00
- model_id: qwen/qwen-2.5-vl-7b-instruct
  name: 'Qwen: Qwen2.5-VL 7B Instruct'
  provider: openrouter
  description: 'Qwen2.5 VL 7B is a multimodal LLM from the Qwen Team with the following
    key enhancements:


    - SoTA understanding of images of various resolution & ratio: Qwen2.5-VL achieves
    state-of-the-art performance on visual understanding benchmarks, including MathVista,
    DocVQA, RealWorldQA, MTVQA, etc.


    - Understanding videos of 20min+: Qwen2.5-VL can understand videos over 20 minutes
    for high-quality video-based question answering, dialog, content creation, etc.


    - Agent that can operate your mobiles, robots, etc.: with the abilities of complex
    reasoning and decision making, Qwen2.5-VL can be integrated with devices like
    mobile phones, robots, etc., for automatic operation based on visual environment
    and text instructions.


    - Multilingual Support: to serve global users, besides English and Chinese, Qwen2.5-VL
    now supports the understanding of texts in different languages inside images,
    including most European languages, Japanese, Korean, Arabic, Vietnamese, etc.


    For more details, see this [blog post](https://qwenlm.github.io/blog/qwen2-vl/)
    and [GitHub repo](https://github.com/QwenLM/Qwen2-VL).


    Usage of this model is subject to [Tongyi Qianwen LICENSE AGREEMENT](https://huggingface.co/Qwen/Qwen1.5-110B-Chat/blob/main/LICENSE).'
  context_length: 32768
  pricing:
    prompt: 2.0e-07
    completion: 2.0e-07
    image: 0.0001445
    request: 0.0
    currency: USD
  capabilities:
    supports_vision: true
    supports_function_calling: false
    supports_streaming: true
    modalities:
    - text
    - image->text
  metadata:
    architecture: Qwen
  updated_at: 2025-12-19 00:46:07.741048+00:00
- model_id: microsoft/phi-3.5-mini-128k-instruct
  name: 'Microsoft: Phi-3.5 Mini 128K Instruct'
  provider: openrouter
  description: 'Phi-3.5 models are lightweight, state-of-the-art open models. These
    models were trained with Phi-3 datasets that include both synthetic data and the
    filtered, publicly available websites data, with a focus on high quality and reasoning-dense
    properties. Phi-3.5 Mini uses 3.8B parameters, and is a dense decoder-only transformer
    model using the same tokenizer as [Phi-3 Mini](/models/microsoft/phi-3-mini-128k-instruct).


    The models underwent a rigorous enhancement process, incorporating both supervised
    fine-tuning, proximal policy optimization, and direct preference optimization
    to ensure precise instruction adherence and robust safety measures. When assessed
    against benchmarks that test common sense, language understanding, math, code,
    long context and logical reasoning, Phi-3.5 models showcased robust and state-of-the-art
    performance among models with less than 13 billion parameters.'
  context_length: 128000
  pricing:
    prompt: 1.0e-07
    completion: 1.0e-07
    image: 0.0
    request: 0.0
    currency: USD
  capabilities:
    supports_vision: false
    supports_function_calling: true
    supports_streaming: true
    modalities:
    - text
    - text->text
  metadata:
    architecture: Other
  updated_at: 2025-12-19 00:46:07.741058+00:00
- model_id: nousresearch/hermes-3-llama-3.1-70b
  name: 'Nous: Hermes 3 70B Instruct'
  provider: openrouter
  description: 'Hermes 3 is a generalist language model with many improvements over
    [Hermes 2](/models/nousresearch/nous-hermes-2-mistral-7b-dpo), including advanced
    agentic capabilities, much better roleplaying, reasoning, multi-turn conversation,
    long context coherence, and improvements across the board.


    Hermes 3 70B is a competitive, if not superior finetune of the [Llama-3.1 70B
    foundation model](/models/meta-llama/llama-3.1-70b-instruct), focused on aligning
    LLMs to the user, with powerful steering capabilities and control given to the
    end user.


    The Hermes 3 series builds and expands on the Hermes 2 set of capabilities, including
    more powerful and reliable function calling and structured output capabilities,
    generalist assistant capabilities, and improved code generation skills.'
  context_length: 65536
  pricing:
    prompt: 3.0e-07
    completion: 3.0e-07
    image: 0.0
    request: 0.0
    currency: USD
  capabilities:
    supports_vision: false
    supports_function_calling: false
    supports_streaming: true
    modalities:
    - text
    - text->text
  metadata:
    architecture: Llama3
  updated_at: 2025-12-19 00:46:07.741067+00:00
- model_id: nousresearch/hermes-3-llama-3.1-405b:free
  name: 'Nous: Hermes 3 405B Instruct (free)'
  provider: openrouter
  description: 'Hermes 3 is a generalist language model with many improvements over
    Hermes 2, including advanced agentic capabilities, much better roleplaying, reasoning,
    multi-turn conversation, long context coherence, and improvements across the board.


    Hermes 3 405B is a frontier-level, full-parameter finetune of the Llama-3.1 405B
    foundation model, focused on aligning LLMs to the user, with powerful steering
    capabilities and control given to the end user.


    The Hermes 3 series builds and expands on the Hermes 2 set of capabilities, including
    more powerful and reliable function calling and structured output capabilities,
    generalist assistant capabilities, and improved code generation skills.


    Hermes 3 is competitive, if not superior, to Llama-3.1 Instruct models at general
    capabilities, with varying strengths and weaknesses attributable between the two.'
  context_length: 131072
  pricing:
    prompt: 0.0
    completion: 0.0
    image: 0.0
    request: 0.0
    currency: USD
  capabilities:
    supports_vision: false
    supports_function_calling: false
    supports_streaming: true
    modalities:
    - text
    - text->text
  metadata:
    architecture: Llama3
  updated_at: 2025-12-19 00:46:07.741077+00:00
- model_id: nousresearch/hermes-3-llama-3.1-405b
  name: 'Nous: Hermes 3 405B Instruct'
  provider: openrouter
  description: 'Hermes 3 is a generalist language model with many improvements over
    Hermes 2, including advanced agentic capabilities, much better roleplaying, reasoning,
    multi-turn conversation, long context coherence, and improvements across the board.


    Hermes 3 405B is a frontier-level, full-parameter finetune of the Llama-3.1 405B
    foundation model, focused on aligning LLMs to the user, with powerful steering
    capabilities and control given to the end user.


    The Hermes 3 series builds and expands on the Hermes 2 set of capabilities, including
    more powerful and reliable function calling and structured output capabilities,
    generalist assistant capabilities, and improved code generation skills.


    Hermes 3 is competitive, if not superior, to Llama-3.1 Instruct models at general
    capabilities, with varying strengths and weaknesses attributable between the two.'
  context_length: 131072
  pricing:
    prompt: 1.0e-06
    completion: 1.0e-06
    image: 0.0
    request: 0.0
    currency: USD
  capabilities:
    supports_vision: false
    supports_function_calling: false
    supports_streaming: true
    modalities:
    - text
    - text->text
  metadata:
    architecture: Llama3
  updated_at: 2025-12-19 00:46:07.741089+00:00
- model_id: openai/chatgpt-4o-latest
  name: 'OpenAI: ChatGPT-4o'
  provider: openrouter
  description: 'OpenAI ChatGPT 4o is continually updated by OpenAI to point to the
    current version of GPT-4o used by ChatGPT. It therefore differs slightly from
    the API version of [GPT-4o](/models/openai/gpt-4o) in that it has additional RLHF.
    It is intended for research and evaluation.


    OpenAI notes that this model is not suited for production use-cases as it may
    be removed or redirected to another model in the future.'
  context_length: 128000
  pricing:
    prompt: 5.0e-06
    completion: 1.5e-05
    image: 0.007225
    request: 0.0
    currency: USD
  capabilities:
    supports_vision: true
    supports_function_calling: false
    supports_streaming: true
    modalities:
    - text
    - image->text
  metadata:
    architecture: GPT
  updated_at: 2025-12-19 00:46:07.741098+00:00
- model_id: sao10k/l3-lunaris-8b
  name: 'Sao10K: Llama 3 8B Lunaris'
  provider: openrouter
  description: 'Lunaris 8B is a versatile generalist and roleplaying model based on
    Llama 3. It''s a strategic merge of multiple models, designed to balance creativity
    with improved logic and general knowledge.


    Created by [Sao10k](https://huggingface.co/Sao10k), this model aims to offer an
    improved experience over Stheno v3.2, with enhanced creativity and logical reasoning.


    For best results, use with Llama 3 Instruct context template, temperature 1.4,
    and min_p 0.1.'
  context_length: 8192
  pricing:
    prompt: 4.0e-08
    completion: 5.0e-08
    image: 0.0
    request: 0.0
    currency: USD
  capabilities:
    supports_vision: false
    supports_function_calling: false
    supports_streaming: true
    modalities:
    - text
    - text->text
  metadata:
    architecture: Llama3
  updated_at: 2025-12-19 00:46:07.741137+00:00
- model_id: openai/gpt-4o-2024-08-06
  name: 'OpenAI: GPT-4o (2024-08-06)'
  provider: openrouter
  description: 'The 2024-08-06 version of GPT-4o offers improved performance in structured
    outputs, with the ability to supply a JSON schema in the respone_format. Read
    more [here](https://openai.com/index/introducing-structured-outputs-in-the-api/).


    GPT-4o ("o" for "omni") is OpenAI''s latest AI model, supporting both text and
    image inputs with text outputs. It maintains the intelligence level of [GPT-4
    Turbo](/models/openai/gpt-4-turbo) while being twice as fast and 50% more cost-effective.
    GPT-4o also offers improved performance in processing non-English languages and
    enhanced visual capabilities.


    For benchmarking against other models, it was briefly called ["im-also-a-good-gpt2-chatbot"](https://twitter.com/LiamFedus/status/1790064963966370209)'
  context_length: 128000
  pricing:
    prompt: 2.5e-06
    completion: 1.0e-05
    image: 0.003613
    request: 0.0
    currency: USD
  capabilities:
    supports_vision: true
    supports_function_calling: true
    supports_streaming: true
    modalities:
    - text
    - image->text
  metadata:
    architecture: GPT
  updated_at: 2025-12-19 00:46:07.741150+00:00
- model_id: meta-llama/llama-3.1-405b
  name: 'Meta: Llama 3.1 405B (base)'
  provider: openrouter
  description: 'Meta''s latest class of model (Llama 3.1) launched with a variety
    of sizes & flavors. This is the base 405B pre-trained version.


    It has demonstrated strong performance compared to leading closed-source models
    in human evaluations.


    To read more about the model release, [click here](https://ai.meta.com/blog/meta-llama-3/).
    Usage of this model is subject to [Meta''s Acceptable Use Policy](https://llama.meta.com/llama3/use-policy/).'
  context_length: 32768
  pricing:
    prompt: 4.0e-06
    completion: 4.0e-06
    image: 0.0
    request: 0.0
    currency: USD
  capabilities:
    supports_vision: false
    supports_function_calling: false
    supports_streaming: true
    modalities:
    - text
    - text->text
  metadata:
    architecture: Llama3
  updated_at: 2025-12-19 00:46:07.741159+00:00
- model_id: meta-llama/llama-3.1-8b-instruct
  name: 'Meta: Llama 3.1 8B Instruct'
  provider: openrouter
  description: 'Meta''s latest class of model (Llama 3.1) launched with a variety
    of sizes & flavors. This 8B instruct-tuned version is fast and efficient.


    It has demonstrated strong performance compared to leading closed-source models
    in human evaluations.


    To read more about the model release, [click here](https://ai.meta.com/blog/meta-llama-3-1/).
    Usage of this model is subject to [Meta''s Acceptable Use Policy](https://llama.meta.com/llama3/use-policy/).'
  context_length: 131072
  pricing:
    prompt: 2.0e-08
    completion: 3.0e-08
    image: 0.0
    request: 0.0
    currency: USD
  capabilities:
    supports_vision: false
    supports_function_calling: true
    supports_streaming: true
    modalities:
    - text
    - text->text
  metadata:
    architecture: Llama3
  updated_at: 2025-12-19 00:46:07.741167+00:00
- model_id: meta-llama/llama-3.1-405b-instruct:free
  name: 'Meta: Llama 3.1 405B Instruct (free)'
  provider: openrouter
  description: 'The highly anticipated 400B class of Llama3 is here! Clocking in at
    128k context with impressive eval scores, the Meta AI team continues to push the
    frontier of open-source LLMs.


    Meta''s latest class of model (Llama 3.1) launched with a variety of sizes & flavors.
    This 405B instruct-tuned version is optimized for high quality dialogue usecases.


    It has demonstrated strong performance compared to leading closed-source models
    including GPT-4o and Claude 3.5 Sonnet in evaluations.


    To read more about the model release, [click here](https://ai.meta.com/blog/meta-llama-3-1/).
    Usage of this model is subject to [Meta''s Acceptable Use Policy](https://llama.meta.com/llama3/use-policy/).'
  context_length: 131072
  pricing:
    prompt: 0.0
    completion: 0.0
    image: 0.0
    request: 0.0
    currency: USD
  capabilities:
    supports_vision: false
    supports_function_calling: false
    supports_streaming: true
    modalities:
    - text
    - text->text
  metadata:
    architecture: Llama3
  updated_at: 2025-12-19 00:46:07.741181+00:00
- model_id: meta-llama/llama-3.1-405b-instruct
  name: 'Meta: Llama 3.1 405B Instruct'
  provider: openrouter
  description: 'The highly anticipated 400B class of Llama3 is here! Clocking in at
    128k context with impressive eval scores, the Meta AI team continues to push the
    frontier of open-source LLMs.


    Meta''s latest class of model (Llama 3.1) launched with a variety of sizes & flavors.
    This 405B instruct-tuned version is optimized for high quality dialogue usecases.


    It has demonstrated strong performance compared to leading closed-source models
    including GPT-4o and Claude 3.5 Sonnet in evaluations.


    To read more about the model release, [click here](https://ai.meta.com/blog/meta-llama-3-1/).
    Usage of this model is subject to [Meta''s Acceptable Use Policy](https://llama.meta.com/llama3/use-policy/).'
  context_length: 130815
  pricing:
    prompt: 3.5e-06
    completion: 3.5e-06
    image: 0.0
    request: 0.0
    currency: USD
  capabilities:
    supports_vision: false
    supports_function_calling: true
    supports_streaming: true
    modalities:
    - text
    - text->text
  metadata:
    architecture: Llama3
  updated_at: 2025-12-19 00:46:07.741189+00:00
- model_id: meta-llama/llama-3.1-70b-instruct
  name: 'Meta: Llama 3.1 70B Instruct'
  provider: openrouter
  description: 'Meta''s latest class of model (Llama 3.1) launched with a variety
    of sizes & flavors. This 70B instruct-tuned version is optimized for high quality
    dialogue usecases.


    It has demonstrated strong performance compared to leading closed-source models
    in human evaluations.


    To read more about the model release, [click here](https://ai.meta.com/blog/meta-llama-3-1/).
    Usage of this model is subject to [Meta''s Acceptable Use Policy](https://llama.meta.com/llama3/use-policy/).'
  context_length: 131072
  pricing:
    prompt: 4.0e-07
    completion: 4.0e-07
    image: 0.0
    request: 0.0
    currency: USD
  capabilities:
    supports_vision: false
    supports_function_calling: true
    supports_streaming: true
    modalities:
    - text
    - text->text
  metadata:
    architecture: Llama3
  updated_at: 2025-12-19 00:46:07.741197+00:00
- model_id: mistralai/mistral-nemo
  name: 'Mistral: Mistral Nemo'
  provider: openrouter
  description: 'A 12B parameter model with a 128k token context length built by Mistral
    in collaboration with NVIDIA.


    The model is multilingual, supporting English, French, German, Spanish, Italian,
    Portuguese, Chinese, Japanese, Korean, Arabic, and Hindi.


    It supports function calling and is released under the Apache 2.0 license.'
  context_length: 131072
  pricing:
    prompt: 2.0e-08
    completion: 4.0e-08
    image: 0.0
    request: 0.0
    currency: USD
  capabilities:
    supports_vision: false
    supports_function_calling: true
    supports_streaming: true
    modalities:
    - text
    - text->text
  metadata:
    architecture: Mistral
  updated_at: 2025-12-19 00:46:07.741205+00:00
- model_id: openai/gpt-4o-mini-2024-07-18
  name: 'OpenAI: GPT-4o-mini (2024-07-18)'
  provider: openrouter
  description: 'GPT-4o mini is OpenAI''s newest model after [GPT-4 Omni](/models/openai/gpt-4o),
    supporting both text and image inputs with text outputs.


    As their most advanced small model, it is many multiples more affordable than
    other recent frontier models, and more than 60% cheaper than [GPT-3.5 Turbo](/models/openai/gpt-3.5-turbo).
    It maintains SOTA intelligence, while being significantly more cost-effective.


    GPT-4o mini achieves an 82% score on MMLU and presently ranks higher than GPT-4
    on chat preferences [common leaderboards](https://arena.lmsys.org/).


    Check out the [launch announcement](https://openai.com/index/gpt-4o-mini-advancing-cost-efficient-intelligence/)
    to learn more.


    #multimodal'
  context_length: 128000
  pricing:
    prompt: 1.5e-07
    completion: 6.0e-07
    image: 0.007225
    request: 0.0
    currency: USD
  capabilities:
    supports_vision: true
    supports_function_calling: true
    supports_streaming: true
    modalities:
    - text
    - image->text
  metadata:
    architecture: GPT
  updated_at: 2025-12-19 00:46:07.741220+00:00
- model_id: openai/gpt-4o-mini
  name: 'OpenAI: GPT-4o-mini'
  provider: openrouter
  description: 'GPT-4o mini is OpenAI''s newest model after [GPT-4 Omni](/models/openai/gpt-4o),
    supporting both text and image inputs with text outputs.


    As their most advanced small model, it is many multiples more affordable than
    other recent frontier models, and more than 60% cheaper than [GPT-3.5 Turbo](/models/openai/gpt-3.5-turbo).
    It maintains SOTA intelligence, while being significantly more cost-effective.


    GPT-4o mini achieves an 82% score on MMLU and presently ranks higher than GPT-4
    on chat preferences [common leaderboards](https://arena.lmsys.org/).


    Check out the [launch announcement](https://openai.com/index/gpt-4o-mini-advancing-cost-efficient-intelligence/)
    to learn more.


    #multimodal'
  context_length: 128000
  pricing:
    prompt: 1.5e-07
    completion: 6.0e-07
    image: 0.000217
    request: 0.0
    currency: USD
  capabilities:
    supports_vision: true
    supports_function_calling: true
    supports_streaming: true
    modalities:
    - text
    - image->text
  metadata:
    architecture: GPT
  updated_at: 2025-12-19 00:46:07.741228+00:00
- model_id: google/gemma-2-27b-it
  name: 'Google: Gemma 2 27B'
  provider: openrouter
  description: 'Gemma 2 27B by Google is an open model built from the same research
    and technology used to create the [Gemini models](/models?q=gemini).


    Gemma models are well-suited for a variety of text generation tasks, including
    question answering, summarization, and reasoning.


    See the [launch announcement](https://blog.google/technology/developers/google-gemma-2/)
    for more details. Usage of Gemma is subject to Google''s [Gemma Terms of Use](https://ai.google.dev/gemma/terms).'
  context_length: 8192
  pricing:
    prompt: 6.5e-07
    completion: 6.5e-07
    image: 0.0
    request: 0.0
    currency: USD
  capabilities:
    supports_vision: false
    supports_function_calling: false
    supports_streaming: true
    modalities:
    - text
    - text->text
  metadata:
    architecture: Gemini
  updated_at: 2025-12-19 00:46:07.741241+00:00
- model_id: google/gemma-2-9b-it
  name: 'Google: Gemma 2 9B'
  provider: openrouter
  description: 'Gemma 2 9B by Google is an advanced, open-source language model that
    sets a new standard for efficiency and performance in its size class.


    Designed for a wide variety of tasks, it empowers developers and researchers to
    build innovative applications, while maintaining accessibility, safety, and cost-effectiveness.


    See the [launch announcement](https://blog.google/technology/developers/google-gemma-2/)
    for more details. Usage of Gemma is subject to Google''s [Gemma Terms of Use](https://ai.google.dev/gemma/terms).'
  context_length: 8192
  pricing:
    prompt: 3.0e-08
    completion: 9.0e-08
    image: 0.0
    request: 0.0
    currency: USD
  capabilities:
    supports_vision: false
    supports_function_calling: false
    supports_streaming: true
    modalities:
    - text
    - text->text
  metadata:
    architecture: Gemini
  updated_at: 2025-12-19 00:46:07.741249+00:00
- model_id: sao10k/l3-euryale-70b
  name: 'Sao10k: Llama 3 Euryale 70B v2.1'
  provider: openrouter
  description: 'Euryale 70B v2.1 is a model focused on creative roleplay from [Sao10k](https://ko-fi.com/sao10k).


    - Better prompt adherence.

    - Better anatomy / spatial awareness.

    - Adapts much better to unique and custom formatting / reply formats.

    - Very creative, lots of unique swipes.

    - Is not restrictive during roleplays.'
  context_length: 8192
  pricing:
    prompt: 1.48e-06
    completion: 1.48e-06
    image: 0.0
    request: 0.0
    currency: USD
  capabilities:
    supports_vision: false
    supports_function_calling: true
    supports_streaming: true
    modalities:
    - text
    - text->text
  metadata:
    architecture: Llama3
  updated_at: 2025-12-19 00:46:07.741259+00:00
- model_id: nousresearch/hermes-2-pro-llama-3-8b
  name: 'NousResearch: Hermes 2 Pro - Llama-3 8B'
  provider: openrouter
  description: Hermes 2 Pro is an upgraded, retrained version of Nous Hermes 2, consisting
    of an updated and cleaned version of the OpenHermes 2.5 Dataset, as well as a
    newly introduced Function Calling and JSON Mode dataset developed in-house.
  context_length: 8192
  pricing:
    prompt: 2.5e-08
    completion: 8.0e-08
    image: 0.0
    request: 0.0
    currency: USD
  capabilities:
    supports_vision: false
    supports_function_calling: false
    supports_streaming: true
    modalities:
    - text
    - text->text
  metadata:
    architecture: Llama3
  updated_at: 2025-12-19 00:46:07.741268+00:00
- model_id: mistralai/mistral-7b-instruct:free
  name: 'Mistral: Mistral 7B Instruct (free)'
  provider: openrouter
  description: 'A high-performing, industry-standard 7.3B parameter model, with optimizations
    for speed and context length.


    *Mistral 7B Instruct has multiple version variants, and this is intended to be
    the latest version.*'
  context_length: 32768
  pricing:
    prompt: 0.0
    completion: 0.0
    image: 0.0
    request: 0.0
    currency: USD
  capabilities:
    supports_vision: false
    supports_function_calling: true
    supports_streaming: true
    modalities:
    - text
    - text->text
  metadata:
    architecture: Mistral
  updated_at: 2025-12-19 00:46:07.741276+00:00
- model_id: mistralai/mistral-7b-instruct
  name: 'Mistral: Mistral 7B Instruct'
  provider: openrouter
  description: 'A high-performing, industry-standard 7.3B parameter model, with optimizations
    for speed and context length.


    *Mistral 7B Instruct has multiple version variants, and this is intended to be
    the latest version.*'
  context_length: 32768
  pricing:
    prompt: 2.8e-08
    completion: 5.4e-08
    image: 0.0
    request: 0.0
    currency: USD
  capabilities:
    supports_vision: false
    supports_function_calling: true
    supports_streaming: true
    modalities:
    - text
    - text->text
  metadata:
    architecture: Mistral
  updated_at: 2025-12-19 00:46:07.741288+00:00
- model_id: mistralai/mistral-7b-instruct-v0.3
  name: 'Mistral: Mistral 7B Instruct v0.3'
  provider: openrouter
  description: 'A high-performing, industry-standard 7.3B parameter model, with optimizations
    for speed and context length.


    An improved version of [Mistral 7B Instruct v0.2](/models/mistralai/mistral-7b-instruct-v0.2),
    with the following changes:


    - Extended vocabulary to 32768

    - Supports v3 Tokenizer

    - Supports function calling


    NOTE: Support for function calling depends on the provider.'
  context_length: 32768
  pricing:
    prompt: 2.0e-07
    completion: 2.0e-07
    image: 0.0
    request: 0.0
    currency: USD
  capabilities:
    supports_vision: false
    supports_function_calling: false
    supports_streaming: true
    modalities:
    - text
    - text->text
  metadata:
    architecture: Mistral
  updated_at: 2025-12-19 00:46:07.741306+00:00
- model_id: microsoft/phi-3-mini-128k-instruct
  name: 'Microsoft: Phi-3 Mini 128K Instruct'
  provider: openrouter
  description: 'Phi-3 Mini is a powerful 3.8B parameter model designed for advanced
    language understanding, reasoning, and instruction following. Optimized through
    supervised fine-tuning and preference adjustments, it excels in tasks involving
    common sense, mathematics, logical reasoning, and code processing.


    At time of release, Phi-3 Medium demonstrated state-of-the-art performance among
    lightweight models. This model is static, trained on an offline dataset with an
    October 2023 cutoff date.'
  context_length: 128000
  pricing:
    prompt: 1.0e-07
    completion: 1.0e-07
    image: 0.0
    request: 0.0
    currency: USD
  capabilities:
    supports_vision: false
    supports_function_calling: true
    supports_streaming: true
    modalities:
    - text
    - text->text
  metadata:
    architecture: Other
  updated_at: 2025-12-19 00:46:07.741315+00:00
- model_id: microsoft/phi-3-medium-128k-instruct
  name: 'Microsoft: Phi-3 Medium 128K Instruct'
  provider: openrouter
  description: 'Phi-3 128K Medium is a powerful 14-billion parameter model designed
    for advanced language understanding, reasoning, and instruction following. Optimized
    through supervised fine-tuning and preference adjustments, it excels in tasks
    involving common sense, mathematics, logical reasoning, and code processing.


    At time of release, Phi-3 Medium demonstrated state-of-the-art performance among
    lightweight models. In the MMLU-Pro eval, the model even comes close to a Llama3
    70B level of performance.


    For 4k context length, try [Phi-3 Medium 4K](/models/microsoft/phi-3-medium-4k-instruct).'
  context_length: 128000
  pricing:
    prompt: 1.0e-06
    completion: 1.0e-06
    image: 0.0
    request: 0.0
    currency: USD
  capabilities:
    supports_vision: false
    supports_function_calling: true
    supports_streaming: true
    modalities:
    - text
    - text->text
  metadata:
    architecture: Other
  updated_at: 2025-12-19 00:46:07.741325+00:00
- model_id: meta-llama/llama-guard-2-8b
  name: 'Meta: LlamaGuard 2 8B'
  provider: openrouter
  description: 'This safeguard model has 8B parameters and is based on the Llama 3
    family. Just like is predecessor, [LlamaGuard 1](https://huggingface.co/meta-llama/LlamaGuard-7b),
    it can do both prompt and response classification.


    LlamaGuard 2 acts as a normal LLM would, generating text that indicates whether
    the given input/output is safe/unsafe. If deemed unsafe, it will also share the
    content categories violated.


    For best results, please use raw prompt input or the `/completions` endpoint,
    instead of the chat API.


    It has demonstrated strong performance compared to leading closed-source models
    in human evaluations.


    To read more about the model release, [click here](https://ai.meta.com/blog/meta-llama-3/).
    Usage of this model is subject to [Meta''s Acceptable Use Policy](https://llama.meta.com/llama3/use-policy/).'
  context_length: 8192
  pricing:
    prompt: 2.0e-07
    completion: 2.0e-07
    image: 0.0
    request: 0.0
    currency: USD
  capabilities:
    supports_vision: false
    supports_function_calling: false
    supports_streaming: true
    modalities:
    - text
    - text->text
  metadata:
    architecture: Llama3
  updated_at: 2025-12-19 00:46:07.741333+00:00
- model_id: openai/gpt-4o-2024-05-13
  name: 'OpenAI: GPT-4o (2024-05-13)'
  provider: openrouter
  description: 'GPT-4o ("o" for "omni") is OpenAI''s latest AI model, supporting both
    text and image inputs with text outputs. It maintains the intelligence level of
    [GPT-4 Turbo](/models/openai/gpt-4-turbo) while being twice as fast and 50% more
    cost-effective. GPT-4o also offers improved performance in processing non-English
    languages and enhanced visual capabilities.


    For benchmarking against other models, it was briefly called ["im-also-a-good-gpt2-chatbot"](https://twitter.com/LiamFedus/status/1790064963966370209)


    #multimodal'
  context_length: 128000
  pricing:
    prompt: 5.0e-06
    completion: 1.5e-05
    image: 0.007225
    request: 0.0
    currency: USD
  capabilities:
    supports_vision: true
    supports_function_calling: true
    supports_streaming: true
    modalities:
    - text
    - image->text
  metadata:
    architecture: GPT
  updated_at: 2025-12-19 00:46:07.741344+00:00
- model_id: openai/gpt-4o
  name: 'OpenAI: GPT-4o'
  provider: openrouter
  description: 'GPT-4o ("o" for "omni") is OpenAI''s latest AI model, supporting both
    text and image inputs with text outputs. It maintains the intelligence level of
    [GPT-4 Turbo](/models/openai/gpt-4-turbo) while being twice as fast and 50% more
    cost-effective. GPT-4o also offers improved performance in processing non-English
    languages and enhanced visual capabilities.


    For benchmarking against other models, it was briefly called ["im-also-a-good-gpt2-chatbot"](https://twitter.com/LiamFedus/status/1790064963966370209)


    #multimodal'
  context_length: 128000
  pricing:
    prompt: 2.5e-06
    completion: 1.0e-05
    image: 0.003613
    request: 0.0
    currency: USD
  capabilities:
    supports_vision: true
    supports_function_calling: true
    supports_streaming: true
    modalities:
    - text
    - image->text
  metadata:
    architecture: GPT
  updated_at: 2025-12-19 00:46:07.741358+00:00
- model_id: openai/gpt-4o:extended
  name: 'OpenAI: GPT-4o (extended)'
  provider: openrouter
  description: 'GPT-4o ("o" for "omni") is OpenAI''s latest AI model, supporting both
    text and image inputs with text outputs. It maintains the intelligence level of
    [GPT-4 Turbo](/models/openai/gpt-4-turbo) while being twice as fast and 50% more
    cost-effective. GPT-4o also offers improved performance in processing non-English
    languages and enhanced visual capabilities.


    For benchmarking against other models, it was briefly called ["im-also-a-good-gpt2-chatbot"](https://twitter.com/LiamFedus/status/1790064963966370209)


    #multimodal'
  context_length: 128000
  pricing:
    prompt: 6.0e-06
    completion: 1.8e-05
    image: 0.007225
    request: 0.0
    currency: USD
  capabilities:
    supports_vision: true
    supports_function_calling: true
    supports_streaming: true
    modalities:
    - text
    - image->text
  metadata:
    architecture: GPT
  updated_at: 2025-12-19 00:46:07.741368+00:00
- model_id: meta-llama/llama-3-70b-instruct
  name: 'Meta: Llama 3 70B Instruct'
  provider: openrouter
  description: 'Meta''s latest class of model (Llama 3) launched with a variety of
    sizes & flavors. This 70B instruct-tuned version was optimized for high quality
    dialogue usecases.


    It has demonstrated strong performance compared to leading closed-source models
    in human evaluations.


    To read more about the model release, [click here](https://ai.meta.com/blog/meta-llama-3/).
    Usage of this model is subject to [Meta''s Acceptable Use Policy](https://llama.meta.com/llama3/use-policy/).'
  context_length: 8192
  pricing:
    prompt: 3.0e-07
    completion: 4.0e-07
    image: 0.0
    request: 0.0
    currency: USD
  capabilities:
    supports_vision: false
    supports_function_calling: true
    supports_streaming: true
    modalities:
    - text
    - text->text
  metadata:
    architecture: Llama3
  updated_at: 2025-12-19 00:46:07.741376+00:00
- model_id: meta-llama/llama-3-8b-instruct
  name: 'Meta: Llama 3 8B Instruct'
  provider: openrouter
  description: 'Meta''s latest class of model (Llama 3) launched with a variety of
    sizes & flavors. This 8B instruct-tuned version was optimized for high quality
    dialogue usecases.


    It has demonstrated strong performance compared to leading closed-source models
    in human evaluations.


    To read more about the model release, [click here](https://ai.meta.com/blog/meta-llama-3/).
    Usage of this model is subject to [Meta''s Acceptable Use Policy](https://llama.meta.com/llama3/use-policy/).'
  context_length: 8192
  pricing:
    prompt: 3.0e-08
    completion: 6.0e-08
    image: 0.0
    request: 0.0
    currency: USD
  capabilities:
    supports_vision: false
    supports_function_calling: true
    supports_streaming: true
    modalities:
    - text
    - text->text
  metadata:
    architecture: Llama3
  updated_at: 2025-12-19 00:46:07.741387+00:00
- model_id: mistralai/mixtral-8x22b-instruct
  name: 'Mistral: Mixtral 8x22B Instruct'
  provider: openrouter
  description: 'Mistral''s official instruct fine-tuned version of [Mixtral 8x22B](/models/mistralai/mixtral-8x22b).
    It uses 39B active parameters out of 141B, offering unparalleled cost efficiency
    for its size. Its strengths include:

    - strong math, coding, and reasoning

    - large context length (64k)

    - fluency in English, French, Italian, German, and Spanish


    See benchmarks on the launch announcement [here](https://mistral.ai/news/mixtral-8x22b/).

    #moe'
  context_length: 65536
  pricing:
    prompt: 2.0e-06
    completion: 6.0e-06
    image: 0.0
    request: 0.0
    currency: USD
  capabilities:
    supports_vision: false
    supports_function_calling: true
    supports_streaming: true
    modalities:
    - text
    - text->text
  metadata:
    architecture: Mistral
  updated_at: 2025-12-19 00:46:07.741398+00:00
- model_id: microsoft/wizardlm-2-8x22b
  name: WizardLM-2 8x22B
  provider: openrouter
  description: 'WizardLM-2 8x22B is Microsoft AI''s most advanced Wizard model. It
    demonstrates highly competitive performance compared to leading proprietary models,
    and it consistently outperforms all existing state-of-the-art opensource models.


    It is an instruct finetune of [Mixtral 8x22B](/models/mistralai/mixtral-8x22b).


    To read more about the model release, [click here](https://wizardlm.github.io/WizardLM2/).


    #moe'
  context_length: 65536
  pricing:
    prompt: 4.8e-07
    completion: 4.8e-07
    image: 0.0
    request: 0.0
    currency: USD
  capabilities:
    supports_vision: false
    supports_function_calling: false
    supports_streaming: true
    modalities:
    - text
    - text->text
  metadata:
    architecture: Mistral
  updated_at: 2025-12-19 00:46:07.741407+00:00
- model_id: openai/gpt-4-turbo
  name: 'OpenAI: GPT-4 Turbo'
  provider: openrouter
  description: 'The latest GPT-4 Turbo model with vision capabilities. Vision requests
    can now use JSON mode and function calling.


    Training data: up to December 2023.'
  context_length: 128000
  pricing:
    prompt: 1.0e-05
    completion: 3.0e-05
    image: 0.01445
    request: 0.0
    currency: USD
  capabilities:
    supports_vision: true
    supports_function_calling: true
    supports_streaming: true
    modalities:
    - text
    - image->text
  metadata:
    architecture: GPT
  updated_at: 2025-12-19 00:46:07.741415+00:00
- model_id: anthropic/claude-3-haiku
  name: 'Anthropic: Claude 3 Haiku'
  provider: openrouter
  description: 'Claude 3 Haiku is Anthropic''s fastest and most compact model for

    near-instant responsiveness. Quick and accurate targeted performance.


    See the launch announcement and benchmark results [here](https://www.anthropic.com/news/claude-3-haiku)


    #multimodal'
  context_length: 200000
  pricing:
    prompt: 2.5e-07
    completion: 1.25e-06
    image: 0.0004
    request: 0.0
    currency: USD
  capabilities:
    supports_vision: true
    supports_function_calling: true
    supports_streaming: true
    modalities:
    - text
    - image->text
  metadata:
    architecture: Claude
  updated_at: 2025-12-19 00:46:07.741429+00:00
- model_id: anthropic/claude-3-opus
  name: 'Anthropic: Claude 3 Opus'
  provider: openrouter
  description: 'Claude 3 Opus is Anthropic''s most powerful model for highly complex
    tasks. It boasts top-level performance, intelligence, fluency, and understanding.


    See the launch announcement and benchmark results [here](https://www.anthropic.com/news/claude-3-family)


    #multimodal'
  context_length: 200000
  pricing:
    prompt: 1.5e-05
    completion: 7.5e-05
    image: 0.024
    request: 0.0
    currency: USD
  capabilities:
    supports_vision: true
    supports_function_calling: true
    supports_streaming: true
    modalities:
    - text
    - image->text
  metadata:
    architecture: Claude
  updated_at: 2025-12-19 00:46:07.741438+00:00
- model_id: mistralai/mistral-large
  name: Mistral Large
  provider: openrouter
  description: 'This is Mistral AI''s flagship model, Mistral Large 2 (version `mistral-large-2407`).
    It''s a proprietary weights-available model and excels at reasoning, code, JSON,
    chat, and more. Read the launch announcement [here](https://mistral.ai/news/mistral-large-2407/).


    It supports dozens of languages including French, German, Spanish, Italian, Portuguese,
    Arabic, Hindi, Russian, Chinese, Japanese, and Korean, along with 80+ coding languages
    including Python, Java, C, C++, JavaScript, and Bash. Its long context window
    allows precise information recall from large documents.'
  context_length: 128000
  pricing:
    prompt: 2.0e-06
    completion: 6.0e-06
    image: 0.0
    request: 0.0
    currency: USD
  capabilities:
    supports_vision: false
    supports_function_calling: true
    supports_streaming: true
    modalities:
    - text
    - text->text
  metadata:
    architecture: Mistral
  updated_at: 2025-12-19 00:46:07.741446+00:00
- model_id: openai/gpt-3.5-turbo-0613
  name: 'OpenAI: GPT-3.5 Turbo (older v0613)'
  provider: openrouter
  description: 'GPT-3.5 Turbo is OpenAI''s fastest model. It can understand and generate
    natural language or code, and is optimized for chat and traditional completion
    tasks.


    Training data up to Sep 2021.'
  context_length: 4095
  pricing:
    prompt: 1.0e-06
    completion: 2.0e-06
    image: 0.0
    request: 0.0
    currency: USD
  capabilities:
    supports_vision: false
    supports_function_calling: true
    supports_streaming: true
    modalities:
    - text
    - text->text
  metadata:
    architecture: GPT
  updated_at: 2025-12-19 00:46:07.741454+00:00
- model_id: openai/gpt-4-turbo-preview
  name: 'OpenAI: GPT-4 Turbo Preview'
  provider: openrouter
  description: 'The preview GPT-4 model with improved instruction following, JSON
    mode, reproducible outputs, parallel function calling, and more. Training data:
    up to Dec 2023.


    **Note:** heavily rate limited by OpenAI while in preview.'
  context_length: 128000
  pricing:
    prompt: 1.0e-05
    completion: 3.0e-05
    image: 0.0
    request: 0.0
    currency: USD
  capabilities:
    supports_vision: false
    supports_function_calling: true
    supports_streaming: true
    modalities:
    - text
    - text->text
  metadata:
    architecture: GPT
  updated_at: 2025-12-19 00:46:07.741464+00:00
- model_id: mistralai/mistral-tiny
  name: Mistral Tiny
  provider: openrouter
  description: 'Note: This model is being deprecated. Recommended replacement is the
    newer [Ministral 8B](/mistral/ministral-8b)


    This model is currently powered by Mistral-7B-v0.2, and incorporates a "better"
    fine-tuning than [Mistral 7B](/models/mistralai/mistral-7b-instruct-v0.1), inspired
    by community work. It''s best used for large batch processing tasks where cost
    is a significant factor but reasoning capabilities are not crucial.'
  context_length: 32768
  pricing:
    prompt: 2.5e-07
    completion: 2.5e-07
    image: 0.0
    request: 0.0
    currency: USD
  capabilities:
    supports_vision: false
    supports_function_calling: true
    supports_streaming: true
    modalities:
    - text
    - text->text
  metadata:
    architecture: Mistral
  updated_at: 2025-12-19 00:46:07.741473+00:00
- model_id: mistralai/mistral-7b-instruct-v0.2
  name: 'Mistral: Mistral 7B Instruct v0.2'
  provider: openrouter
  description: 'A high-performing, industry-standard 7.3B parameter model, with optimizations
    for speed and context length.


    An improved version of [Mistral 7B Instruct](/modelsmistralai/mistral-7b-instruct-v0.1),
    with the following changes:


    - 32k context window (vs 8k context in v0.1)

    - Rope-theta = 1e6

    - No Sliding-Window Attention'
  context_length: 32768
  pricing:
    prompt: 2.0e-07
    completion: 2.0e-07
    image: 0.0
    request: 0.0
    currency: USD
  capabilities:
    supports_vision: false
    supports_function_calling: false
    supports_streaming: true
    modalities:
    - text
    - text->text
  metadata:
    architecture: Mistral
  updated_at: 2025-12-19 00:46:07.741485+00:00
- model_id: mistralai/mixtral-8x7b-instruct
  name: 'Mistral: Mixtral 8x7B Instruct'
  provider: openrouter
  description: 'Mixtral 8x7B Instruct is a pretrained generative Sparse Mixture of
    Experts, by Mistral AI, for chat and instruction use. Incorporates 8 experts (feed-forward
    networks) for a total of 47 billion parameters.


    Instruct model fine-tuned by Mistral. #moe'
  context_length: 32768
  pricing:
    prompt: 5.4e-07
    completion: 5.4e-07
    image: 0.0
    request: 0.0
    currency: USD
  capabilities:
    supports_vision: false
    supports_function_calling: true
    supports_streaming: true
    modalities:
    - text
    - text->text
  metadata:
    architecture: Mistral
  updated_at: 2025-12-19 00:46:07.741495+00:00
- model_id: neversleep/noromaid-20b
  name: Noromaid 20B
  provider: openrouter
  description: 'A collab between IkariDev and Undi. This merge is suitable for RP,
    ERP, and general knowledge.


    #merge #uncensored'
  context_length: 4096
  pricing:
    prompt: 1.0e-06
    completion: 1.75e-06
    image: 0.0
    request: 0.0
    currency: USD
  capabilities:
    supports_vision: false
    supports_function_calling: false
    supports_streaming: true
    modalities:
    - text
    - text->text
  metadata:
    architecture: Llama2
  updated_at: 2025-12-19 00:46:07.741506+00:00
- model_id: alpindale/goliath-120b
  name: Goliath 120B
  provider: openrouter
  description: 'A large LLM created by combining two fine-tuned Llama 70B models into
    one 120B model. Combines Xwin and Euryale.


    Credits to

    - [@chargoddard](https://huggingface.co/chargoddard) for developing the framework
    used to merge the model - [mergekit](https://github.com/cg123/mergekit).

    - [@Undi95](https://huggingface.co/Undi95) for helping with the merge ratios.


    #merge'
  context_length: 6144
  pricing:
    prompt: 6.0e-06
    completion: 8.0e-06
    image: 0.0
    request: 0.0
    currency: USD
  capabilities:
    supports_vision: false
    supports_function_calling: false
    supports_streaming: true
    modalities:
    - text
    - text->text
  metadata:
    architecture: Llama2
  updated_at: 2025-12-19 00:46:07.741515+00:00
- model_id: openrouter/auto
  name: Auto Router
  provider: openrouter
  description: 'Your prompt will be processed by a meta-model and routed to one of
    dozens of models (see below), optimizing for the best possible output.


    To see which model was used, visit [Activity](/activity), or read the `model`
    attribute of the response. Your response will be priced at the same rate as the
    routed model.


    The meta-model is powered by [Not Diamond](https://docs.notdiamond.ai/docs/how-not-diamond-works).
    Learn more in our [docs](/docs/model-routing).


    Requests will be routed to the following models:

    - [openai/gpt-5](/openai/gpt-5)

    - [openai/gpt-5-mini](/openai/gpt-5-mini)

    - [openai/gpt-5-nano](/openai/gpt-5-nano)

    - [openai/gpt-4.1-nano](/openai/gpt-4.1-nano)

    - [openai/gpt-4.1](/openai/gpt-4.1)

    - [openai/gpt-4.1-mini](/openai/gpt-4.1-mini)

    - [openai/gpt-4.1](/openai/gpt-4.1)

    - [openai/gpt-4o-mini](/openai/gpt-4o-mini)

    - [openai/chatgpt-4o-latest](/openai/chatgpt-4o-latest)

    - [anthropic/claude-3.5-haiku](/anthropic/claude-3.5-haiku)

    - [anthropic/claude-opus-4-1](/anthropic/claude-opus-4-1)

    - [anthropic/claude-sonnet-4-0](/anthropic/claude-sonnet-4-0)

    - [anthropic/claude-3-7-sonnet-latest](/anthropic/claude-3-7-sonnet-latest)

    - [google/gemini-2.5-pro](/google/gemini-2.5-pro)

    - [google/gemini-2.5-flash](/google/gemini-2.5-flash)

    - [mistral/mistral-large-latest](/mistral/mistral-large-latest)

    - [mistral/mistral-medium-latest](/mistral/mistral-medium-latest)

    - [mistral/mistral-small-latest](/mistral/mistral-small-latest)

    - [mistralai/mistral-nemo](/mistralai/mistral-nemo)

    - [x-ai/grok-3](/x-ai/grok-3)

    - [x-ai/grok-3-mini](/x-ai/grok-3-mini)

    - [x-ai/grok-4](/x-ai/grok-4)

    - [deepseek/deepseek-r1](/deepseek/deepseek-r1)

    - [meta-llama/llama-3.1-70b-instruct](/meta-llama/llama-3.1-70b-instruct)

    - [meta-llama/llama-3.1-405b-instruct](/meta-llama/llama-3.1-405b-instruct)

    - [mistralai/mixtral-8x22b-instruct](/mistralai/mixtral-8x22b-instruct)

    - [perplexity/sonar](/perplexity/sonar)

    - [cohere/command-r-plus](/cohere/command-r-plus)

    - [cohere/command-r](/cohere/command-r)'
  context_length: 2000000
  pricing:
    prompt: -1.0
    completion: -1.0
    image: null
    request: null
    currency: USD
  capabilities:
    supports_vision: false
    supports_function_calling: false
    supports_streaming: true
    modalities:
    - text
    - text->text
  metadata:
    architecture: Router
  updated_at: 2025-12-19 00:46:07.741525+00:00
- model_id: openai/gpt-4-1106-preview
  name: 'OpenAI: GPT-4 Turbo (older v1106)'
  provider: openrouter
  description: 'The latest GPT-4 Turbo model with vision capabilities. Vision requests
    can now use JSON mode and function calling.


    Training data: up to April 2023.'
  context_length: 128000
  pricing:
    prompt: 1.0e-05
    completion: 3.0e-05
    image: 0.0
    request: 0.0
    currency: USD
  capabilities:
    supports_vision: false
    supports_function_calling: true
    supports_streaming: true
    modalities:
    - text
    - text->text
  metadata:
    architecture: GPT
  updated_at: 2025-12-19 00:46:07.741536+00:00
- model_id: openai/gpt-3.5-turbo-instruct
  name: 'OpenAI: GPT-3.5 Turbo Instruct'
  provider: openrouter
  description: 'This model is a variant of GPT-3.5 Turbo tuned for instructional prompts
    and omitting chat-related optimizations. Training data: up to Sep 2021.'
  context_length: 4095
  pricing:
    prompt: 1.5e-06
    completion: 2.0e-06
    image: 0.0
    request: 0.0
    currency: USD
  capabilities:
    supports_vision: false
    supports_function_calling: false
    supports_streaming: true
    modalities:
    - text
    - text->text
  metadata:
    architecture: GPT
  updated_at: 2025-12-19 00:46:07.741547+00:00
- model_id: mistralai/mistral-7b-instruct-v0.1
  name: 'Mistral: Mistral 7B Instruct v0.1'
  provider: openrouter
  description: A 7.3B parameter model that outperforms Llama 2 13B on all benchmarks,
    with optimizations for speed and context length.
  context_length: 2824
  pricing:
    prompt: 1.1e-07
    completion: 1.9e-07
    image: 0.0
    request: 0.0
    currency: USD
  capabilities:
    supports_vision: false
    supports_function_calling: false
    supports_streaming: true
    modalities:
    - text
    - text->text
  metadata:
    architecture: Mistral
  updated_at: 2025-12-19 00:46:07.741556+00:00
- model_id: openai/gpt-3.5-turbo-16k
  name: 'OpenAI: GPT-3.5 Turbo 16k'
  provider: openrouter
  description: 'This model offers four times the context length of gpt-3.5-turbo,
    allowing it to support approximately 20 pages of text in a single request at a
    higher cost. Training data: up to Sep 2021.'
  context_length: 16385
  pricing:
    prompt: 3.0e-06
    completion: 4.0e-06
    image: 0.0
    request: 0.0
    currency: USD
  capabilities:
    supports_vision: false
    supports_function_calling: true
    supports_streaming: true
    modalities:
    - text
    - text->text
  metadata:
    architecture: GPT
  updated_at: 2025-12-19 00:46:07.741566+00:00
- model_id: mancer/weaver
  name: 'Mancer: Weaver (alpha)'
  provider: openrouter
  description: An attempt to recreate Claude-style verbosity, but don't expect the
    same level of coherence or memory. Meant for use in roleplay/narrative situations.
  context_length: 8000
  pricing:
    prompt: 7.5e-07
    completion: 1.0e-06
    image: 0.0
    request: 0.0
    currency: USD
  capabilities:
    supports_vision: false
    supports_function_calling: false
    supports_streaming: true
    modalities:
    - text
    - text->text
  metadata:
    architecture: Llama2
  updated_at: 2025-12-19 00:46:07.741577+00:00
- model_id: undi95/remm-slerp-l2-13b
  name: ReMM SLERP 13B
  provider: openrouter
  description: 'A recreation trial of the original MythoMax-L2-B13 but with updated
    models. #merge'
  context_length: 6144
  pricing:
    prompt: 4.5e-07
    completion: 6.5e-07
    image: 0.0
    request: 0.0
    currency: USD
  capabilities:
    supports_vision: false
    supports_function_calling: false
    supports_streaming: true
    modalities:
    - text
    - text->text
  metadata:
    architecture: Llama2
  updated_at: 2025-12-19 00:46:07.741585+00:00
- model_id: gryphe/mythomax-l2-13b
  name: MythoMax 13B
  provider: openrouter
  description: 'One of the highest performing and most popular fine-tunes of Llama
    2 13B, with rich descriptions and roleplay. #merge'
  context_length: 4096
  pricing:
    prompt: 6.0e-08
    completion: 6.0e-08
    image: 0.0
    request: 0.0
    currency: USD
  capabilities:
    supports_vision: false
    supports_function_calling: false
    supports_streaming: true
    modalities:
    - text
    - text->text
  metadata:
    architecture: Llama2
  updated_at: 2025-12-19 00:46:07.741593+00:00
- model_id: openai/gpt-4-0314
  name: 'OpenAI: GPT-4 (older v0314)'
  provider: openrouter
  description: 'GPT-4-0314 is the first version of GPT-4 released, with a context
    length of 8,192 tokens, and was supported until June 14. Training data: up to
    Sep 2021.'
  context_length: 8191
  pricing:
    prompt: 3.0e-05
    completion: 6.0e-05
    image: 0.0
    request: 0.0
    currency: USD
  capabilities:
    supports_vision: false
    supports_function_calling: true
    supports_streaming: true
    modalities:
    - text
    - text->text
  metadata:
    architecture: GPT
  updated_at: 2025-12-19 00:46:07.741605+00:00
- model_id: openai/gpt-4
  name: 'OpenAI: GPT-4'
  provider: openrouter
  description: 'OpenAI''s flagship model, GPT-4 is a large-scale multimodal language
    model capable of solving difficult problems with greater accuracy than previous
    models due to its broader general knowledge and advanced reasoning capabilities.
    Training data: up to Sep 2021.'
  context_length: 8191
  pricing:
    prompt: 3.0e-05
    completion: 6.0e-05
    image: 0.0
    request: 0.0
    currency: USD
  capabilities:
    supports_vision: false
    supports_function_calling: true
    supports_streaming: true
    modalities:
    - text
    - text->text
  metadata:
    architecture: GPT
  updated_at: 2025-12-19 00:46:07.741616+00:00
- model_id: openai/gpt-3.5-turbo
  name: 'OpenAI: GPT-3.5 Turbo'
  provider: openrouter
  description: 'GPT-3.5 Turbo is OpenAI''s fastest model. It can understand and generate
    natural language or code, and is optimized for chat and traditional completion
    tasks.


    Training data up to Sep 2021.'
  context_length: 16385
  pricing:
    prompt: 5.0e-07
    completion: 1.5e-06
    image: 0.0
    request: 0.0
    currency: USD
  capabilities:
    supports_vision: false
    supports_function_calling: true
    supports_streaming: true
    modalities:
    - text
    - text->text
  metadata:
    architecture: GPT
  updated_at: 2025-12-19 00:46:07.741624+00:00
- model_id: claude-opus-4-5-20251101
  name: Claude Opus 4.5
  provider: anthropic
  description: 'Anthropic Claude model: Claude Opus 4.5'
  context_length: null
  pricing: null
  capabilities:
    supports_vision: false
    supports_function_calling: true
    supports_streaming: true
    modalities:
    - text
  metadata:
    type: model
    created_at: '2025-11-24T00:00:00Z'
  updated_at: 2025-12-19 00:46:07.950571+00:00
- model_id: claude-haiku-4-5-20251001
  name: Claude Haiku 4.5
  provider: anthropic
  description: 'Anthropic Claude model: Claude Haiku 4.5'
  context_length: null
  pricing: null
  capabilities:
    supports_vision: false
    supports_function_calling: true
    supports_streaming: true
    modalities:
    - text
  metadata:
    type: model
    created_at: '2025-10-15T00:00:00Z'
  updated_at: 2025-12-19 00:46:07.950591+00:00
- model_id: claude-sonnet-4-5-20250929
  name: Claude Sonnet 4.5
  provider: anthropic
  description: 'Anthropic Claude model: Claude Sonnet 4.5'
  context_length: 200000
  pricing:
    prompt: 3.0e-06
    completion: 1.5e-05
    image: null
    request: null
    currency: USD
  capabilities:
    supports_vision: true
    supports_function_calling: true
    supports_streaming: true
    modalities:
    - text
    - image
  metadata:
    type: model
    created_at: '2025-09-29T00:00:00Z'
  updated_at: 2025-12-19 00:46:07.950607+00:00
- model_id: claude-opus-4-1-20250805
  name: Claude Opus 4.1
  provider: anthropic
  description: 'Anthropic Claude model: Claude Opus 4.1'
  context_length: 200000
  pricing:
    prompt: 1.5e-05
    completion: 7.5e-05
    image: null
    request: null
    currency: USD
  capabilities:
    supports_vision: true
    supports_function_calling: true
    supports_streaming: true
    modalities:
    - text
    - image
  metadata:
    type: model
    created_at: '2025-08-05T00:00:00Z'
  updated_at: 2025-12-19 00:46:07.950618+00:00
- model_id: claude-opus-4-20250514
  name: Claude Opus 4
  provider: anthropic
  description: 'Anthropic Claude model: Claude Opus 4'
  context_length: 200000
  pricing:
    prompt: 1.5e-05
    completion: 7.5e-05
    image: null
    request: null
    currency: USD
  capabilities:
    supports_vision: true
    supports_function_calling: true
    supports_streaming: true
    modalities:
    - text
    - image
  metadata:
    type: model
    created_at: '2025-05-22T00:00:00Z'
  updated_at: 2025-12-19 00:46:07.950632+00:00
- model_id: claude-sonnet-4-20250514
  name: Claude Sonnet 4
  provider: anthropic
  description: 'Anthropic Claude model: Claude Sonnet 4'
  context_length: 200000
  pricing:
    prompt: 3.0e-06
    completion: 1.5e-05
    image: null
    request: null
    currency: USD
  capabilities:
    supports_vision: true
    supports_function_calling: true
    supports_streaming: true
    modalities:
    - text
    - image
  metadata:
    type: model
    created_at: '2025-05-22T00:00:00Z'
  updated_at: 2025-12-19 00:46:07.950642+00:00
- model_id: claude-3-7-sonnet-20250219
  name: Claude Sonnet 3.7
  provider: anthropic
  description: 'Anthropic Claude model: Claude Sonnet 3.7'
  context_length: 200000
  pricing:
    prompt: 3.0e-06
    completion: 1.5e-05
    image: null
    request: null
    currency: USD
  capabilities:
    supports_vision: true
    supports_function_calling: true
    supports_streaming: true
    modalities:
    - text
    - image
  metadata:
    type: model
    created_at: '2025-02-24T00:00:00Z'
  updated_at: 2025-12-19 00:46:07.950650+00:00
- model_id: claude-3-5-haiku-20241022
  name: Claude Haiku 3.5
  provider: anthropic
  description: 'Anthropic Claude model: Claude Haiku 3.5'
  context_length: 200000
  pricing:
    prompt: 8.000000000000001e-07
    completion: 4.0e-06
    image: null
    request: null
    currency: USD
  capabilities:
    supports_vision: false
    supports_function_calling: true
    supports_streaming: true
    modalities:
    - text
  metadata:
    type: model
    created_at: '2024-10-22T00:00:00Z'
  updated_at: 2025-12-19 00:46:07.950663+00:00
- model_id: claude-3-haiku-20240307
  name: Claude Haiku 3
  provider: anthropic
  description: 'Anthropic Claude model: Claude Haiku 3'
  context_length: 200000
  pricing:
    prompt: 2.5e-07
    completion: 1.25e-06
    image: null
    request: null
    currency: USD
  capabilities:
    supports_vision: true
    supports_function_calling: true
    supports_streaming: true
    modalities:
    - text
    - image
  metadata:
    type: model
    created_at: '2024-03-07T00:00:00Z'
  updated_at: 2025-12-19 00:46:07.950674+00:00
- model_id: claude-3-opus-20240229
  name: Claude Opus 3
  provider: anthropic
  description: 'Anthropic Claude model: Claude Opus 3'
  context_length: 200000
  pricing:
    prompt: 1.5e-05
    completion: 7.5e-05
    image: null
    request: null
    currency: USD
  capabilities:
    supports_vision: true
    supports_function_calling: true
    supports_streaming: true
    modalities:
    - text
    - image
  metadata:
    type: model
    created_at: '2024-02-29T00:00:00Z'
  updated_at: 2025-12-19 00:46:07.950686+00:00
- model_id: gpt-3.5-turbo
  name: gpt-3.5-turbo
  provider: openai
  description: OpenAI GPT-3.5 Turbo - fast and cost-effective
  context_length: 16385
  pricing:
    prompt: 5.0e-07
    completion: 1.5e-06
    image: null
    request: null
    currency: USD
  capabilities:
    supports_vision: false
    supports_function_calling: true
    supports_streaming: true
    modalities:
    - text
  metadata:
    object: model
    created: 1677610602
    owned_by: openai
  updated_at: 2025-12-19 00:46:08.659161+00:00
- model_id: chatgpt-image-latest
  name: chatgpt-image-latest
  provider: openai
  description: 'OpenAI model: chatgpt-image-latest'
  context_length: null
  pricing: null
  capabilities:
    supports_vision: false
    supports_function_calling: false
    supports_streaming: false
    modalities:
    - text
  metadata:
    object: model
    created: 1765925279
    owned_by: system
  updated_at: 2025-12-19 00:46:08.659183+00:00
- model_id: gpt-4o-mini-tts-2025-03-20
  name: gpt-4o-mini-tts-2025-03-20
  provider: openai
  description: OpenAI GPT-4o - flagship model with vision and function calling
  context_length: null
  pricing: null
  capabilities:
    supports_vision: false
    supports_function_calling: false
    supports_streaming: false
    modalities:
    - text
  metadata:
    object: model
    created: 1765610731
    owned_by: system
  updated_at: 2025-12-19 00:46:08.659193+00:00
- model_id: gpt-4o-mini-tts-2025-12-15
  name: gpt-4o-mini-tts-2025-12-15
  provider: openai
  description: OpenAI GPT-4o - flagship model with vision and function calling
  context_length: null
  pricing: null
  capabilities:
    supports_vision: false
    supports_function_calling: false
    supports_streaming: false
    modalities:
    - text
  metadata:
    object: model
    created: 1765610837
    owned_by: system
  updated_at: 2025-12-19 00:46:08.659201+00:00
- model_id: gpt-realtime-mini-2025-12-15
  name: gpt-realtime-mini-2025-12-15
  provider: openai
  description: 'OpenAI model: gpt-realtime-mini-2025-12-15'
  context_length: null
  pricing: null
  capabilities:
    supports_vision: false
    supports_function_calling: false
    supports_streaming: false
    modalities:
    - text
  metadata:
    object: model
    created: 1765612007
    owned_by: system
  updated_at: 2025-12-19 00:46:08.659210+00:00
- model_id: gpt-audio-mini-2025-12-15
  name: gpt-audio-mini-2025-12-15
  provider: openai
  description: 'OpenAI model: gpt-audio-mini-2025-12-15'
  context_length: null
  pricing: null
  capabilities:
    supports_vision: false
    supports_function_calling: false
    supports_streaming: false
    modalities:
    - text
  metadata:
    object: model
    created: 1765760008
    owned_by: system
  updated_at: 2025-12-19 00:46:08.659217+00:00
- model_id: davinci-002
  name: davinci-002
  provider: openai
  description: 'OpenAI model: davinci-002'
  context_length: null
  pricing: null
  capabilities:
    supports_vision: false
    supports_function_calling: false
    supports_streaming: false
    modalities:
    - text
  metadata:
    object: model
    created: 1692634301
    owned_by: system
  updated_at: 2025-12-19 00:46:08.659225+00:00
- model_id: babbage-002
  name: babbage-002
  provider: openai
  description: 'OpenAI model: babbage-002'
  context_length: null
  pricing: null
  capabilities:
    supports_vision: false
    supports_function_calling: false
    supports_streaming: false
    modalities:
    - text
  metadata:
    object: model
    created: 1692634615
    owned_by: system
  updated_at: 2025-12-19 00:46:08.659237+00:00
- model_id: gpt-3.5-turbo-instruct
  name: gpt-3.5-turbo-instruct
  provider: openai
  description: OpenAI GPT-3.5 Turbo - fast and cost-effective
  context_length: null
  pricing: null
  capabilities:
    supports_vision: false
    supports_function_calling: false
    supports_streaming: false
    modalities:
    - text
  metadata:
    object: model
    created: 1692901427
    owned_by: system
  updated_at: 2025-12-19 00:46:08.659245+00:00
- model_id: gpt-3.5-turbo-instruct-0914
  name: gpt-3.5-turbo-instruct-0914
  provider: openai
  description: OpenAI GPT-3.5 Turbo - fast and cost-effective
  context_length: null
  pricing: null
  capabilities:
    supports_vision: false
    supports_function_calling: false
    supports_streaming: false
    modalities:
    - text
  metadata:
    object: model
    created: 1694122472
    owned_by: system
  updated_at: 2025-12-19 00:46:08.659258+00:00
- model_id: dall-e-3
  name: dall-e-3
  provider: openai
  description: 'OpenAI model: dall-e-3'
  context_length: null
  pricing: null
  capabilities:
    supports_vision: false
    supports_function_calling: false
    supports_streaming: false
    modalities:
    - text
  metadata:
    object: model
    created: 1698785189
    owned_by: system
  updated_at: 2025-12-19 00:46:08.659265+00:00
- model_id: dall-e-2
  name: dall-e-2
  provider: openai
  description: 'OpenAI model: dall-e-2'
  context_length: null
  pricing: null
  capabilities:
    supports_vision: false
    supports_function_calling: false
    supports_streaming: false
    modalities:
    - text
  metadata:
    object: model
    created: 1698798177
    owned_by: system
  updated_at: 2025-12-19 00:46:08.659273+00:00
- model_id: gpt-3.5-turbo-1106
  name: gpt-3.5-turbo-1106
  provider: openai
  description: OpenAI GPT-3.5 Turbo - fast and cost-effective
  context_length: 16385
  pricing:
    prompt: 1.0e-06
    completion: 2.0e-06
    image: null
    request: null
    currency: USD
  capabilities:
    supports_vision: false
    supports_function_calling: true
    supports_streaming: true
    modalities:
    - text
  metadata:
    object: model
    created: 1698959748
    owned_by: system
  updated_at: 2025-12-19 00:46:08.659283+00:00
- model_id: tts-1-hd
  name: tts-1-hd
  provider: openai
  description: 'OpenAI model: tts-1-hd'
  context_length: null
  pricing: null
  capabilities:
    supports_vision: false
    supports_function_calling: false
    supports_streaming: false
    modalities:
    - text
  metadata:
    object: model
    created: 1699046015
    owned_by: system
  updated_at: 2025-12-19 00:46:08.659291+00:00
- model_id: tts-1-1106
  name: tts-1-1106
  provider: openai
  description: 'OpenAI model: tts-1-1106'
  context_length: null
  pricing: null
  capabilities:
    supports_vision: false
    supports_function_calling: false
    supports_streaming: false
    modalities:
    - text
  metadata:
    object: model
    created: 1699053241
    owned_by: system
  updated_at: 2025-12-19 00:46:08.659297+00:00
- model_id: tts-1-hd-1106
  name: tts-1-hd-1106
  provider: openai
  description: 'OpenAI model: tts-1-hd-1106'
  context_length: null
  pricing: null
  capabilities:
    supports_vision: false
    supports_function_calling: false
    supports_streaming: false
    modalities:
    - text
  metadata:
    object: model
    created: 1699053533
    owned_by: system
  updated_at: 2025-12-19 00:46:08.659304+00:00
- model_id: text-embedding-3-small
  name: text-embedding-3-small
  provider: openai
  description: 'OpenAI embedding model: text-embedding-3-small'
  context_length: 8191
  pricing:
    prompt: 2.0e-08
    completion: 0.0
    image: null
    request: null
    currency: USD
  capabilities:
    supports_vision: false
    supports_function_calling: false
    supports_streaming: false
    modalities:
    - text
  metadata:
    object: model
    created: 1705948997
    owned_by: system
  updated_at: 2025-12-19 00:46:08.659314+00:00
- model_id: text-embedding-3-large
  name: text-embedding-3-large
  provider: openai
  description: 'OpenAI embedding model: text-embedding-3-large'
  context_length: 8191
  pricing:
    prompt: 1.3e-07
    completion: 0.0
    image: null
    request: null
    currency: USD
  capabilities:
    supports_vision: false
    supports_function_calling: false
    supports_streaming: false
    modalities:
    - text
  metadata:
    object: model
    created: 1705953180
    owned_by: system
  updated_at: 2025-12-19 00:46:08.659323+00:00
- model_id: gpt-3.5-turbo-0125
  name: gpt-3.5-turbo-0125
  provider: openai
  description: OpenAI GPT-3.5 Turbo - fast and cost-effective
  context_length: 16385
  pricing:
    prompt: 5.0e-07
    completion: 1.5e-06
    image: null
    request: null
    currency: USD
  capabilities:
    supports_vision: false
    supports_function_calling: true
    supports_streaming: true
    modalities:
    - text
  metadata:
    object: model
    created: 1706048358
    owned_by: system
  updated_at: 2025-12-19 00:46:08.659332+00:00
- model_id: gpt-4o
  name: gpt-4o
  provider: openai
  description: OpenAI GPT-4o - flagship model with vision and function calling
  context_length: 128000
  pricing:
    prompt: 2.5e-06
    completion: 1.0e-05
    image: null
    request: null
    currency: USD
  capabilities:
    supports_vision: true
    supports_function_calling: true
    supports_streaming: true
    modalities:
    - text
    - image
  metadata:
    object: model
    created: 1715367049
    owned_by: system
  updated_at: 2025-12-19 00:46:08.659341+00:00
- model_id: gpt-4o-2024-05-13
  name: gpt-4o-2024-05-13
  provider: openai
  description: OpenAI GPT-4o - flagship model with vision and function calling
  context_length: 128000
  pricing:
    prompt: 5.0e-06
    completion: 1.5e-05
    image: null
    request: null
    currency: USD
  capabilities:
    supports_vision: true
    supports_function_calling: true
    supports_streaming: true
    modalities:
    - text
    - image
  metadata:
    object: model
    created: 1715368132
    owned_by: system
  updated_at: 2025-12-19 00:46:08.659352+00:00
- model_id: gpt-4o-mini-2024-07-18
  name: gpt-4o-mini-2024-07-18
  provider: openai
  description: OpenAI GPT-4o - flagship model with vision and function calling
  context_length: 128000
  pricing:
    prompt: 1.5e-07
    completion: 6.0e-07
    image: null
    request: null
    currency: USD
  capabilities:
    supports_vision: true
    supports_function_calling: true
    supports_streaming: true
    modalities:
    - text
    - image
  metadata:
    object: model
    created: 1721172717
    owned_by: system
  updated_at: 2025-12-19 00:46:08.659360+00:00
- model_id: gpt-4o-mini
  name: gpt-4o-mini
  provider: openai
  description: OpenAI GPT-4o - flagship model with vision and function calling
  context_length: 128000
  pricing:
    prompt: 1.5e-07
    completion: 6.0e-07
    image: null
    request: null
    currency: USD
  capabilities:
    supports_vision: true
    supports_function_calling: true
    supports_streaming: true
    modalities:
    - text
    - image
  metadata:
    object: model
    created: 1721172741
    owned_by: system
  updated_at: 2025-12-19 00:46:08.659368+00:00
- model_id: gpt-4o-2024-08-06
  name: gpt-4o-2024-08-06
  provider: openai
  description: OpenAI GPT-4o - flagship model with vision and function calling
  context_length: 128000
  pricing:
    prompt: 2.5e-06
    completion: 1.0e-05
    image: null
    request: null
    currency: USD
  capabilities:
    supports_vision: true
    supports_function_calling: true
    supports_streaming: true
    modalities:
    - text
    - image
  metadata:
    object: model
    created: 1722814719
    owned_by: system
  updated_at: 2025-12-19 00:46:08.659376+00:00
- model_id: gpt-4o-audio-preview
  name: gpt-4o-audio-preview
  provider: openai
  description: OpenAI GPT-4o - flagship model with vision and function calling
  context_length: null
  pricing: null
  capabilities:
    supports_vision: false
    supports_function_calling: false
    supports_streaming: false
    modalities:
    - text
  metadata:
    object: model
    created: 1727460443
    owned_by: system
  updated_at: 2025-12-19 00:46:08.659382+00:00
- model_id: omni-moderation-latest
  name: omni-moderation-latest
  provider: openai
  description: 'OpenAI model: omni-moderation-latest'
  context_length: null
  pricing: null
  capabilities:
    supports_vision: false
    supports_function_calling: false
    supports_streaming: false
    modalities:
    - text
  metadata:
    object: model
    created: 1731689265
    owned_by: system
  updated_at: 2025-12-19 00:46:08.659389+00:00
- model_id: omni-moderation-2024-09-26
  name: omni-moderation-2024-09-26
  provider: openai
  description: 'OpenAI model: omni-moderation-2024-09-26'
  context_length: null
  pricing: null
  capabilities:
    supports_vision: false
    supports_function_calling: false
    supports_streaming: false
    modalities:
    - text
  metadata:
    object: model
    created: 1732734466
    owned_by: system
  updated_at: 2025-12-19 00:46:08.659396+00:00
- model_id: gpt-4o-audio-preview-2024-12-17
  name: gpt-4o-audio-preview-2024-12-17
  provider: openai
  description: OpenAI GPT-4o - flagship model with vision and function calling
  context_length: null
  pricing: null
  capabilities:
    supports_vision: false
    supports_function_calling: false
    supports_streaming: false
    modalities:
    - text
  metadata:
    object: model
    created: 1734034239
    owned_by: system
  updated_at: 2025-12-19 00:46:08.659402+00:00
- model_id: gpt-4o-mini-audio-preview-2024-12-17
  name: gpt-4o-mini-audio-preview-2024-12-17
  provider: openai
  description: OpenAI GPT-4o - flagship model with vision and function calling
  context_length: null
  pricing: null
  capabilities:
    supports_vision: false
    supports_function_calling: false
    supports_streaming: false
    modalities:
    - text
  metadata:
    object: model
    created: 1734115920
    owned_by: system
  updated_at: 2025-12-19 00:46:08.659408+00:00
- model_id: o1-2024-12-17
  name: o1-2024-12-17
  provider: openai
  description: OpenAI o1 - advanced reasoning model
  context_length: 200000
  pricing:
    prompt: 1.5e-05
    completion: 6.0e-05
    image: null
    request: null
    currency: USD
  capabilities:
    supports_vision: false
    supports_function_calling: false
    supports_streaming: false
    modalities:
    - text
  metadata:
    object: model
    created: 1734326976
    owned_by: system
  updated_at: 2025-12-19 00:46:08.659417+00:00
- model_id: o1
  name: o1
  provider: openai
  description: OpenAI o1 - advanced reasoning model
  context_length: 200000
  pricing:
    prompt: 1.5e-05
    completion: 6.0e-05
    image: null
    request: null
    currency: USD
  capabilities:
    supports_vision: false
    supports_function_calling: false
    supports_streaming: false
    modalities:
    - text
  metadata:
    object: model
    created: 1734375816
    owned_by: system
  updated_at: 2025-12-19 00:46:08.659427+00:00
- model_id: gpt-4o-mini-audio-preview
  name: gpt-4o-mini-audio-preview
  provider: openai
  description: OpenAI GPT-4o - flagship model with vision and function calling
  context_length: null
  pricing: null
  capabilities:
    supports_vision: false
    supports_function_calling: false
    supports_streaming: false
    modalities:
    - text
  metadata:
    object: model
    created: 1734387424
    owned_by: system
  updated_at: 2025-12-19 00:46:08.659433+00:00
- model_id: o3-mini
  name: o3-mini
  provider: openai
  description: OpenAI o3/o4 - next-generation reasoning model with vision and multimodal
    capabilities
  context_length: null
  pricing: null
  capabilities:
    supports_vision: false
    supports_function_calling: false
    supports_streaming: false
    modalities:
    - text
  metadata:
    object: model
    created: 1737146383
    owned_by: system
  updated_at: 2025-12-19 00:46:08.659440+00:00
- model_id: o3-mini-2025-01-31
  name: o3-mini-2025-01-31
  provider: openai
  description: OpenAI o3/o4 - next-generation reasoning model with vision and multimodal
    capabilities
  context_length: null
  pricing: null
  capabilities:
    supports_vision: false
    supports_function_calling: false
    supports_streaming: false
    modalities:
    - text
  metadata:
    object: model
    created: 1738010200
    owned_by: system
  updated_at: 2025-12-19 00:46:08.659447+00:00
- model_id: gpt-4o-2024-11-20
  name: gpt-4o-2024-11-20
  provider: openai
  description: OpenAI GPT-4o - flagship model with vision and function calling
  context_length: 128000
  pricing:
    prompt: 2.5e-06
    completion: 1.0e-05
    image: null
    request: null
    currency: USD
  capabilities:
    supports_vision: true
    supports_function_calling: true
    supports_streaming: true
    modalities:
    - text
    - image
  metadata:
    object: model
    created: 1739331543
    owned_by: system
  updated_at: 2025-12-19 00:46:08.659455+00:00
- model_id: gpt-4o-search-preview-2025-03-11
  name: gpt-4o-search-preview-2025-03-11
  provider: openai
  description: OpenAI GPT-4o - flagship model with vision and function calling
  context_length: null
  pricing: null
  capabilities:
    supports_vision: false
    supports_function_calling: false
    supports_streaming: false
    modalities:
    - text
  metadata:
    object: model
    created: 1741388170
    owned_by: system
  updated_at: 2025-12-19 00:46:08.659461+00:00
- model_id: gpt-4o-search-preview
  name: gpt-4o-search-preview
  provider: openai
  description: OpenAI GPT-4o - flagship model with vision and function calling
  context_length: null
  pricing: null
  capabilities:
    supports_vision: false
    supports_function_calling: false
    supports_streaming: false
    modalities:
    - text
  metadata:
    object: model
    created: 1741388720
    owned_by: system
  updated_at: 2025-12-19 00:46:08.659467+00:00
- model_id: gpt-4o-mini-search-preview-2025-03-11
  name: gpt-4o-mini-search-preview-2025-03-11
  provider: openai
  description: OpenAI GPT-4o - flagship model with vision and function calling
  context_length: null
  pricing: null
  capabilities:
    supports_vision: false
    supports_function_calling: false
    supports_streaming: false
    modalities:
    - text
  metadata:
    object: model
    created: 1741390858
    owned_by: system
  updated_at: 2025-12-19 00:46:08.659473+00:00
- model_id: gpt-4o-mini-search-preview
  name: gpt-4o-mini-search-preview
  provider: openai
  description: OpenAI GPT-4o - flagship model with vision and function calling
  context_length: null
  pricing: null
  capabilities:
    supports_vision: false
    supports_function_calling: false
    supports_streaming: false
    modalities:
    - text
  metadata:
    object: model
    created: 1741391161
    owned_by: system
  updated_at: 2025-12-19 00:46:08.659479+00:00
- model_id: gpt-4o-transcribe
  name: gpt-4o-transcribe
  provider: openai
  description: OpenAI GPT-4o - flagship model with vision and function calling
  context_length: null
  pricing: null
  capabilities:
    supports_vision: false
    supports_function_calling: false
    supports_streaming: false
    modalities:
    - text
  metadata:
    object: model
    created: 1742068463
    owned_by: system
  updated_at: 2025-12-19 00:46:08.659485+00:00
- model_id: gpt-4o-mini-transcribe
  name: gpt-4o-mini-transcribe
  provider: openai
  description: OpenAI GPT-4o - flagship model with vision and function calling
  context_length: null
  pricing: null
  capabilities:
    supports_vision: false
    supports_function_calling: false
    supports_streaming: false
    modalities:
    - text
  metadata:
    object: model
    created: 1742068596
    owned_by: system
  updated_at: 2025-12-19 00:46:08.659491+00:00
- model_id: gpt-4o-mini-tts
  name: gpt-4o-mini-tts
  provider: openai
  description: OpenAI GPT-4o - flagship model with vision and function calling
  context_length: null
  pricing: null
  capabilities:
    supports_vision: false
    supports_function_calling: false
    supports_streaming: false
    modalities:
    - text
  metadata:
    object: model
    created: 1742403959
    owned_by: system
  updated_at: 2025-12-19 00:46:08.659497+00:00
- model_id: o3-2025-04-16
  name: o3-2025-04-16
  provider: openai
  description: OpenAI o3/o4 - next-generation reasoning model with vision and multimodal
    capabilities
  context_length: null
  pricing: null
  capabilities:
    supports_vision: false
    supports_function_calling: false
    supports_streaming: false
    modalities:
    - text
  metadata:
    object: model
    created: 1744133301
    owned_by: system
  updated_at: 2025-12-19 00:46:08.659503+00:00
- model_id: o4-mini-2025-04-16
  name: o4-mini-2025-04-16
  provider: openai
  description: OpenAI o3/o4 - next-generation reasoning model with vision and multimodal
    capabilities
  context_length: null
  pricing: null
  capabilities:
    supports_vision: false
    supports_function_calling: false
    supports_streaming: false
    modalities:
    - text
  metadata:
    object: model
    created: 1744133506
    owned_by: system
  updated_at: 2025-12-19 00:46:08.659509+00:00
- model_id: o3
  name: o3
  provider: openai
  description: OpenAI o3/o4 - next-generation reasoning model with vision and multimodal
    capabilities
  context_length: 200000
  pricing:
    prompt: 2.0e-06
    completion: 8.0e-06
    image: null
    request: null
    currency: USD
  capabilities:
    supports_vision: true
    supports_function_calling: true
    supports_streaming: true
    modalities:
    - text
    - image
  metadata:
    object: model
    created: 1744225308
    owned_by: system
  updated_at: 2025-12-19 00:46:08.659516+00:00
- model_id: o4-mini
  name: o4-mini
  provider: openai
  description: OpenAI o3/o4 - next-generation reasoning model with vision and multimodal
    capabilities
  context_length: 200000
  pricing:
    prompt: 1.1e-06
    completion: 4.4e-06
    image: null
    request: null
    currency: USD
  capabilities:
    supports_vision: true
    supports_function_calling: true
    supports_streaming: true
    modalities:
    - text
    - image
  metadata:
    object: model
    created: 1744225351
    owned_by: system
  updated_at: 2025-12-19 00:46:08.660457+00:00
- model_id: gpt-4.1-2025-04-14
  name: gpt-4.1-2025-04-14
  provider: openai
  description: OpenAI GPT-4.1 - advanced model with 1M token context window
  context_length: null
  pricing: null
  capabilities:
    supports_vision: false
    supports_function_calling: false
    supports_streaming: false
    modalities:
    - text
  metadata:
    object: model
    created: 1744315746
    owned_by: system
  updated_at: 2025-12-19 00:46:08.660668+00:00
- model_id: gpt-4.1
  name: gpt-4.1
  provider: openai
  description: OpenAI GPT-4.1 - advanced model with 1M token context window
  context_length: 1000000
  pricing:
    prompt: 2.0e-06
    completion: 8.0e-06
    image: null
    request: null
    currency: USD
  capabilities:
    supports_vision: true
    supports_function_calling: true
    supports_streaming: true
    modalities:
    - text
    - image
  metadata:
    object: model
    created: 1744316542
    owned_by: system
  updated_at: 2025-12-19 00:46:08.660685+00:00
- model_id: gpt-4.1-mini-2025-04-14
  name: gpt-4.1-mini-2025-04-14
  provider: openai
  description: OpenAI GPT-4.1 - advanced model with 1M token context window
  context_length: null
  pricing: null
  capabilities:
    supports_vision: false
    supports_function_calling: false
    supports_streaming: false
    modalities:
    - text
  metadata:
    object: model
    created: 1744317547
    owned_by: system
  updated_at: 2025-12-19 00:46:08.660694+00:00
- model_id: gpt-4.1-mini
  name: gpt-4.1-mini
  provider: openai
  description: OpenAI GPT-4.1 - advanced model with 1M token context window
  context_length: 1000000
  pricing:
    prompt: 4.0000000000000003e-07
    completion: 1.6000000000000001e-06
    image: null
    request: null
    currency: USD
  capabilities:
    supports_vision: true
    supports_function_calling: true
    supports_streaming: true
    modalities:
    - text
    - image
  metadata:
    object: model
    created: 1744318173
    owned_by: system
  updated_at: 2025-12-19 00:46:08.660703+00:00
- model_id: gpt-4.1-nano-2025-04-14
  name: gpt-4.1-nano-2025-04-14
  provider: openai
  description: OpenAI GPT-4.1 - advanced model with 1M token context window
  context_length: null
  pricing: null
  capabilities:
    supports_vision: false
    supports_function_calling: false
    supports_streaming: false
    modalities:
    - text
  metadata:
    object: model
    created: 1744321025
    owned_by: system
  updated_at: 2025-12-19 00:46:08.660710+00:00
- model_id: gpt-4.1-nano
  name: gpt-4.1-nano
  provider: openai
  description: OpenAI GPT-4.1 - advanced model with 1M token context window
  context_length: 1000000
  pricing:
    prompt: 1.0000000000000001e-07
    completion: 4.0000000000000003e-07
    image: null
    request: null
    currency: USD
  capabilities:
    supports_vision: true
    supports_function_calling: true
    supports_streaming: true
    modalities:
    - text
    - image
  metadata:
    object: model
    created: 1744321707
    owned_by: system
  updated_at: 2025-12-19 00:46:08.660718+00:00
- model_id: gpt-image-1
  name: gpt-image-1
  provider: openai
  description: 'OpenAI model: gpt-image-1'
  context_length: null
  pricing: null
  capabilities:
    supports_vision: false
    supports_function_calling: false
    supports_streaming: false
    modalities:
    - text
  metadata:
    object: model
    created: 1745517030
    owned_by: system
  updated_at: 2025-12-19 00:46:08.660726+00:00
- model_id: gpt-4o-audio-preview-2025-06-03
  name: gpt-4o-audio-preview-2025-06-03
  provider: openai
  description: OpenAI GPT-4o - flagship model with vision and function calling
  context_length: null
  pricing: null
  capabilities:
    supports_vision: false
    supports_function_calling: false
    supports_streaming: false
    modalities:
    - text
  metadata:
    object: model
    created: 1748908498
    owned_by: system
  updated_at: 2025-12-19 00:46:08.660733+00:00
- model_id: gpt-4o-transcribe-diarize
  name: gpt-4o-transcribe-diarize
  provider: openai
  description: OpenAI GPT-4o - flagship model with vision and function calling
  context_length: null
  pricing: null
  capabilities:
    supports_vision: false
    supports_function_calling: false
    supports_streaming: false
    modalities:
    - text
  metadata:
    object: model
    created: 1750798887
    owned_by: system
  updated_at: 2025-12-19 00:46:08.660739+00:00
- model_id: gpt-5-chat-latest
  name: gpt-5-chat-latest
  provider: openai
  description: OpenAI GPT-5 - next-generation model with advanced reasoning and multimodal
    capabilities
  context_length: null
  pricing: null
  capabilities:
    supports_vision: false
    supports_function_calling: false
    supports_streaming: false
    modalities:
    - text
  metadata:
    object: model
    created: 1754073306
    owned_by: system
  updated_at: 2025-12-19 00:46:08.660745+00:00
- model_id: gpt-5-2025-08-07
  name: gpt-5-2025-08-07
  provider: openai
  description: OpenAI GPT-5 - next-generation model with advanced reasoning and multimodal
    capabilities
  context_length: null
  pricing: null
  capabilities:
    supports_vision: false
    supports_function_calling: false
    supports_streaming: false
    modalities:
    - text
  metadata:
    object: model
    created: 1754075360
    owned_by: system
  updated_at: 2025-12-19 00:46:08.660750+00:00
- model_id: gpt-5
  name: gpt-5
  provider: openai
  description: OpenAI GPT-5 - next-generation model with advanced reasoning and multimodal
    capabilities
  context_length: 272000
  pricing:
    prompt: 1.25e-06
    completion: 1.0e-05
    image: null
    request: null
    currency: USD
  capabilities:
    supports_vision: true
    supports_function_calling: true
    supports_streaming: true
    modalities:
    - text
    - image
  metadata:
    object: model
    created: 1754425777
    owned_by: system
  updated_at: 2025-12-19 00:46:08.660779+00:00
- model_id: gpt-5-mini-2025-08-07
  name: gpt-5-mini-2025-08-07
  provider: openai
  description: OpenAI GPT-5 - next-generation model with advanced reasoning and multimodal
    capabilities
  context_length: null
  pricing: null
  capabilities:
    supports_vision: false
    supports_function_calling: false
    supports_streaming: false
    modalities:
    - text
  metadata:
    object: model
    created: 1754425867
    owned_by: system
  updated_at: 2025-12-19 00:46:08.660786+00:00
- model_id: gpt-5-mini
  name: gpt-5-mini
  provider: openai
  description: OpenAI GPT-5 - next-generation model with advanced reasoning and multimodal
    capabilities
  context_length: 272000
  pricing:
    prompt: 2.5e-07
    completion: 2.0e-06
    image: null
    request: null
    currency: USD
  capabilities:
    supports_vision: true
    supports_function_calling: true
    supports_streaming: true
    modalities:
    - text
    - image
  metadata:
    object: model
    created: 1754425928
    owned_by: system
  updated_at: 2025-12-19 00:46:08.660794+00:00
- model_id: gpt-5-nano-2025-08-07
  name: gpt-5-nano-2025-08-07
  provider: openai
  description: OpenAI GPT-5 - next-generation model with advanced reasoning and multimodal
    capabilities
  context_length: null
  pricing: null
  capabilities:
    supports_vision: false
    supports_function_calling: false
    supports_streaming: false
    modalities:
    - text
  metadata:
    object: model
    created: 1754426303
    owned_by: system
  updated_at: 2025-12-19 00:46:08.660800+00:00
- model_id: gpt-5-nano
  name: gpt-5-nano
  provider: openai
  description: OpenAI GPT-5 - next-generation model with advanced reasoning and multimodal
    capabilities
  context_length: 272000
  pricing:
    prompt: 1.0000000000000001e-07
    completion: 5.0e-07
    image: null
    request: null
    currency: USD
  capabilities:
    supports_vision: true
    supports_function_calling: true
    supports_streaming: true
    modalities:
    - text
    - image
  metadata:
    object: model
    created: 1754426384
    owned_by: system
  updated_at: 2025-12-19 00:46:08.660808+00:00
- model_id: gpt-audio-2025-08-28
  name: gpt-audio-2025-08-28
  provider: openai
  description: 'OpenAI model: gpt-audio-2025-08-28'
  context_length: null
  pricing: null
  capabilities:
    supports_vision: false
    supports_function_calling: false
    supports_streaming: false
    modalities:
    - text
  metadata:
    object: model
    created: 1756256146
    owned_by: system
  updated_at: 2025-12-19 00:46:08.660816+00:00
- model_id: gpt-audio
  name: gpt-audio
  provider: openai
  description: 'OpenAI model: gpt-audio'
  context_length: null
  pricing: null
  capabilities:
    supports_vision: false
    supports_function_calling: false
    supports_streaming: false
    modalities:
    - text
  metadata:
    object: model
    created: 1756339249
    owned_by: system
  updated_at: 2025-12-19 00:46:08.660823+00:00
- model_id: gpt-5-codex
  name: gpt-5-codex
  provider: openai
  description: OpenAI GPT-5 Codex - specialized coding model with multimodal capabilities
  context_length: 400000
  pricing:
    prompt: 1.25e-06
    completion: 1.0e-05
    image: null
    request: null
    currency: USD
  capabilities:
    supports_vision: true
    supports_function_calling: true
    supports_streaming: true
    modalities:
    - text
    - image
  metadata:
    object: model
    created: 1757527818
    owned_by: system
  updated_at: 2025-12-19 00:46:08.660832+00:00
- model_id: gpt-image-1-mini
  name: gpt-image-1-mini
  provider: openai
  description: 'OpenAI model: gpt-image-1-mini'
  context_length: null
  pricing: null
  capabilities:
    supports_vision: false
    supports_function_calling: false
    supports_streaming: false
    modalities:
    - text
  metadata:
    object: model
    created: 1758845821
    owned_by: system
  updated_at: 2025-12-19 00:46:08.660840+00:00
- model_id: gpt-5-pro-2025-10-06
  name: gpt-5-pro-2025-10-06
  provider: openai
  description: OpenAI GPT-5 - next-generation model with advanced reasoning and multimodal
    capabilities
  context_length: null
  pricing: null
  capabilities:
    supports_vision: false
    supports_function_calling: false
    supports_streaming: false
    modalities:
    - text
  metadata:
    object: model
    created: 1759469707
    owned_by: system
  updated_at: 2025-12-19 00:46:08.660846+00:00
- model_id: gpt-5-pro
  name: gpt-5-pro
  provider: openai
  description: OpenAI GPT-5 - next-generation model with advanced reasoning and multimodal
    capabilities
  context_length: null
  pricing: null
  capabilities:
    supports_vision: false
    supports_function_calling: false
    supports_streaming: false
    modalities:
    - text
  metadata:
    object: model
    created: 1759469822
    owned_by: system
  updated_at: 2025-12-19 00:46:08.660852+00:00
- model_id: gpt-audio-mini
  name: gpt-audio-mini
  provider: openai
  description: 'OpenAI model: gpt-audio-mini'
  context_length: null
  pricing: null
  capabilities:
    supports_vision: false
    supports_function_calling: false
    supports_streaming: false
    modalities:
    - text
  metadata:
    object: model
    created: 1759512027
    owned_by: system
  updated_at: 2025-12-19 00:46:08.660858+00:00
- model_id: gpt-audio-mini-2025-10-06
  name: gpt-audio-mini-2025-10-06
  provider: openai
  description: 'OpenAI model: gpt-audio-mini-2025-10-06'
  context_length: null
  pricing: null
  capabilities:
    supports_vision: false
    supports_function_calling: false
    supports_streaming: false
    modalities:
    - text
  metadata:
    object: model
    created: 1759512137
    owned_by: system
  updated_at: 2025-12-19 00:46:08.660865+00:00
- model_id: gpt-5-search-api
  name: gpt-5-search-api
  provider: openai
  description: OpenAI GPT-5 - next-generation model with advanced reasoning and multimodal
    capabilities
  context_length: null
  pricing: null
  capabilities:
    supports_vision: false
    supports_function_calling: false
    supports_streaming: false
    modalities:
    - text
  metadata:
    object: model
    created: 1759514629
    owned_by: system
  updated_at: 2025-12-19 00:46:08.660871+00:00
- model_id: sora-2
  name: sora-2
  provider: openai
  description: 'OpenAI model: sora-2'
  context_length: null
  pricing: null
  capabilities:
    supports_vision: false
    supports_function_calling: false
    supports_streaming: false
    modalities:
    - text
  metadata:
    object: model
    created: 1759708615
    owned_by: system
  updated_at: 2025-12-19 00:46:08.660877+00:00
- model_id: sora-2-pro
  name: sora-2-pro
  provider: openai
  description: 'OpenAI model: sora-2-pro'
  context_length: null
  pricing: null
  capabilities:
    supports_vision: false
    supports_function_calling: false
    supports_streaming: false
    modalities:
    - text
  metadata:
    object: model
    created: 1759708663
    owned_by: system
  updated_at: 2025-12-19 00:46:08.660883+00:00
- model_id: gpt-5-search-api-2025-10-14
  name: gpt-5-search-api-2025-10-14
  provider: openai
  description: OpenAI GPT-5 - next-generation model with advanced reasoning and multimodal
    capabilities
  context_length: null
  pricing: null
  capabilities:
    supports_vision: false
    supports_function_calling: false
    supports_streaming: false
    modalities:
    - text
  metadata:
    object: model
    created: 1760043960
    owned_by: system
  updated_at: 2025-12-19 00:46:08.660889+00:00
- model_id: gpt-5.1-chat-latest
  name: gpt-5.1-chat-latest
  provider: openai
  description: OpenAI GPT-5 - next-generation model with advanced reasoning and multimodal
    capabilities
  context_length: null
  pricing: null
  capabilities:
    supports_vision: false
    supports_function_calling: false
    supports_streaming: false
    modalities:
    - text
  metadata:
    object: model
    created: 1762547951
    owned_by: system
  updated_at: 2025-12-19 00:46:08.660894+00:00
- model_id: gpt-5.1-2025-11-13
  name: gpt-5.1-2025-11-13
  provider: openai
  description: OpenAI GPT-5 - next-generation model with advanced reasoning and multimodal
    capabilities
  context_length: null
  pricing: null
  capabilities:
    supports_vision: false
    supports_function_calling: false
    supports_streaming: false
    modalities:
    - text
  metadata:
    object: model
    created: 1762800353
    owned_by: system
  updated_at: 2025-12-19 00:46:08.660900+00:00
- model_id: gpt-5.1
  name: gpt-5.1
  provider: openai
  description: OpenAI GPT-5 - next-generation model with advanced reasoning and multimodal
    capabilities
  context_length: null
  pricing: null
  capabilities:
    supports_vision: false
    supports_function_calling: false
    supports_streaming: false
    modalities:
    - text
  metadata:
    object: model
    created: 1762800673
    owned_by: system
  updated_at: 2025-12-19 00:46:08.660905+00:00
- model_id: gpt-5.1-codex
  name: gpt-5.1-codex
  provider: openai
  description: OpenAI GPT-5 - next-generation model with advanced reasoning and multimodal
    capabilities
  context_length: null
  pricing: null
  capabilities:
    supports_vision: false
    supports_function_calling: false
    supports_streaming: false
    modalities:
    - text
  metadata:
    object: model
    created: 1762988221
    owned_by: system
  updated_at: 2025-12-19 00:46:08.660912+00:00
- model_id: gpt-5.1-codex-mini
  name: gpt-5.1-codex-mini
  provider: openai
  description: OpenAI GPT-5 - next-generation model with advanced reasoning and multimodal
    capabilities
  context_length: null
  pricing: null
  capabilities:
    supports_vision: false
    supports_function_calling: false
    supports_streaming: false
    modalities:
    - text
  metadata:
    object: model
    created: 1763007109
    owned_by: system
  updated_at: 2025-12-19 00:46:08.660917+00:00
- model_id: gpt-5.1-codex-max
  name: gpt-5.1-codex-max
  provider: openai
  description: OpenAI GPT-5 - next-generation model with advanced reasoning and multimodal
    capabilities
  context_length: null
  pricing: null
  capabilities:
    supports_vision: false
    supports_function_calling: false
    supports_streaming: false
    modalities:
    - text
  metadata:
    object: model
    created: 1763671532
    owned_by: system
  updated_at: 2025-12-19 00:46:08.660923+00:00
- model_id: gpt-image-1.5
  name: gpt-image-1.5
  provider: openai
  description: 'OpenAI model: gpt-image-1.5'
  context_length: null
  pricing: null
  capabilities:
    supports_vision: false
    supports_function_calling: false
    supports_streaming: false
    modalities:
    - text
  metadata:
    object: model
    created: 1764030620
    owned_by: system
  updated_at: 2025-12-19 00:46:08.660929+00:00
- model_id: gpt-5.2-2025-12-11
  name: gpt-5.2-2025-12-11
  provider: openai
  description: OpenAI GPT-5 - next-generation model with advanced reasoning and multimodal
    capabilities
  context_length: null
  pricing: null
  capabilities:
    supports_vision: false
    supports_function_calling: false
    supports_streaming: false
    modalities:
    - text
  metadata:
    object: model
    created: 1765313028
    owned_by: system
  updated_at: 2025-12-19 00:46:08.660935+00:00
- model_id: gpt-5.2
  name: gpt-5.2
  provider: openai
  description: OpenAI GPT-5 - next-generation model with advanced reasoning and multimodal
    capabilities
  context_length: null
  pricing: null
  capabilities:
    supports_vision: false
    supports_function_calling: false
    supports_streaming: false
    modalities:
    - text
  metadata:
    object: model
    created: 1765313051
    owned_by: system
  updated_at: 2025-12-19 00:46:08.660940+00:00
- model_id: gpt-5.2-pro-2025-12-11
  name: gpt-5.2-pro-2025-12-11
  provider: openai
  description: OpenAI GPT-5 - next-generation model with advanced reasoning and multimodal
    capabilities
  context_length: null
  pricing: null
  capabilities:
    supports_vision: false
    supports_function_calling: false
    supports_streaming: false
    modalities:
    - text
  metadata:
    object: model
    created: 1765343959
    owned_by: system
  updated_at: 2025-12-19 00:46:08.660945+00:00
- model_id: gpt-5.2-pro
  name: gpt-5.2-pro
  provider: openai
  description: OpenAI GPT-5 - next-generation model with advanced reasoning and multimodal
    capabilities
  context_length: null
  pricing: null
  capabilities:
    supports_vision: false
    supports_function_calling: false
    supports_streaming: false
    modalities:
    - text
  metadata:
    object: model
    created: 1765343983
    owned_by: system
  updated_at: 2025-12-19 00:46:08.660951+00:00
- model_id: gpt-5.2-chat-latest
  name: gpt-5.2-chat-latest
  provider: openai
  description: OpenAI GPT-5 - next-generation model with advanced reasoning and multimodal
    capabilities
  context_length: null
  pricing: null
  capabilities:
    supports_vision: false
    supports_function_calling: false
    supports_streaming: false
    modalities:
    - text
  metadata:
    object: model
    created: 1765344352
    owned_by: system
  updated_at: 2025-12-19 00:46:08.660957+00:00
- model_id: gpt-4o-mini-transcribe-2025-12-15
  name: gpt-4o-mini-transcribe-2025-12-15
  provider: openai
  description: OpenAI GPT-4o - flagship model with vision and function calling
  context_length: null
  pricing: null
  capabilities:
    supports_vision: false
    supports_function_calling: false
    supports_streaming: false
    modalities:
    - text
  metadata:
    object: model
    created: 1765610407
    owned_by: system
  updated_at: 2025-12-19 00:46:08.660963+00:00
- model_id: gpt-4o-mini-transcribe-2025-03-20
  name: gpt-4o-mini-transcribe-2025-03-20
  provider: openai
  description: OpenAI GPT-4o - flagship model with vision and function calling
  context_length: null
  pricing: null
  capabilities:
    supports_vision: false
    supports_function_calling: false
    supports_streaming: false
    modalities:
    - text
  metadata:
    object: model
    created: 1765610545
    owned_by: system
  updated_at: 2025-12-19 00:46:08.660969+00:00
- model_id: whisper-1
  name: whisper-1
  provider: openai
  description: 'OpenAI model: whisper-1'
  context_length: null
  pricing: null
  capabilities:
    supports_vision: false
    supports_function_calling: false
    supports_streaming: false
    modalities:
    - text
  metadata:
    object: model
    created: 1677532384
    owned_by: openai-internal
  updated_at: 2025-12-19 00:46:08.660975+00:00
- model_id: tts-1
  name: tts-1
  provider: openai
  description: 'OpenAI model: tts-1'
  context_length: null
  pricing: null
  capabilities:
    supports_vision: false
    supports_function_calling: false
    supports_streaming: false
    modalities:
    - text
  metadata:
    object: model
    created: 1681940951
    owned_by: openai-internal
  updated_at: 2025-12-19 00:46:08.660982+00:00
- model_id: gpt-3.5-turbo-16k
  name: gpt-3.5-turbo-16k
  provider: openai
  description: OpenAI GPT-3.5 Turbo - fast and cost-effective
  context_length: 16385
  pricing:
    prompt: 3.0e-06
    completion: 4.0e-06
    image: null
    request: null
    currency: USD
  capabilities:
    supports_vision: false
    supports_function_calling: true
    supports_streaming: true
    modalities:
    - text
  metadata:
    object: model
    created: 1683758102
    owned_by: openai-internal
  updated_at: 2025-12-19 00:46:08.660990+00:00
- model_id: text-embedding-ada-002
  name: text-embedding-ada-002
  provider: openai
  description: 'OpenAI embedding model: text-embedding-ada-002'
  context_length: 8191
  pricing:
    prompt: 1.0000000000000001e-07
    completion: 0.0
    image: null
    request: null
    currency: USD
  capabilities:
    supports_vision: false
    supports_function_calling: false
    supports_streaming: false
    modalities:
    - text
  metadata:
    object: model
    created: 1671217299
    owned_by: openai-internal
  updated_at: 2025-12-19 00:46:08.660999+00:00
- model_id: embedding-gecko-001
  name: Embedding Gecko
  provider: google
  description: Obtain a distributed representation of a text.
  context_length: 1024
  pricing: null
  capabilities:
    supports_vision: false
    supports_function_calling: true
    supports_streaming: true
    modalities:
    - text
  metadata:
    full_name: models/embedding-gecko-001
    output_token_limit: 1
    supported_methods:
    - embedText
    - countTextTokens
    version: '001'
  updated_at: 2025-12-19 00:46:08.791850+00:00
- model_id: gemini-2.5-flash
  name: Gemini 2.5 Flash
  provider: google
  description: Stable version of Gemini 2.5 Flash, our mid-size multimodal model that
    supports up to 1 million tokens, released in June of 2025.
  context_length: 1048576
  pricing:
    prompt: 7.5e-08
    completion: 3.0e-07
    image: null
    request: null
    currency: USD
  capabilities:
    supports_vision: true
    supports_function_calling: true
    supports_streaming: true
    modalities:
    - text
    - image
    - video
    - audio
  metadata:
    full_name: models/gemini-2.5-flash
    output_token_limit: 65536
    supported_methods:
    - generateContent
    - countTokens
    - createCachedContent
    - batchGenerateContent
    version: '001'
  updated_at: 2025-12-19 00:46:08.791870+00:00
- model_id: gemini-2.5-pro
  name: Gemini 2.5 Pro
  provider: google
  description: Stable release (June 17th, 2025) of Gemini 2.5 Pro
  context_length: 1048576
  pricing:
    prompt: 1.25e-06
    completion: 5.0e-06
    image: null
    request: null
    currency: USD
  capabilities:
    supports_vision: true
    supports_function_calling: true
    supports_streaming: true
    modalities:
    - text
    - image
    - video
    - audio
  metadata:
    full_name: models/gemini-2.5-pro
    output_token_limit: 65536
    supported_methods:
    - generateContent
    - countTokens
    - createCachedContent
    - batchGenerateContent
    version: '2.5'
  updated_at: 2025-12-19 00:46:08.791882+00:00
- model_id: gemini-2.0-flash-exp
  name: Gemini 2.0 Flash Experimental
  provider: google
  description: Gemini 2.0 Flash Experimental
  context_length: 1048576
  pricing:
    prompt: 1.0000000000000001e-07
    completion: 4.0000000000000003e-07
    image: null
    request: null
    currency: USD
  capabilities:
    supports_vision: true
    supports_function_calling: true
    supports_streaming: true
    modalities:
    - text
    - image
    - video
    - audio
  metadata:
    full_name: models/gemini-2.0-flash-exp
    output_token_limit: 8192
    supported_methods:
    - generateContent
    - countTokens
    - bidiGenerateContent
    version: '2.0'
  updated_at: 2025-12-19 00:46:08.791892+00:00
- model_id: gemini-2.0-flash
  name: Gemini 2.0 Flash
  provider: google
  description: Gemini 2.0 Flash
  context_length: 1048576
  pricing:
    prompt: 1.0000000000000001e-07
    completion: 4.0000000000000003e-07
    image: null
    request: null
    currency: USD
  capabilities:
    supports_vision: true
    supports_function_calling: true
    supports_streaming: true
    modalities:
    - text
    - image
    - video
    - audio
  metadata:
    full_name: models/gemini-2.0-flash
    output_token_limit: 8192
    supported_methods:
    - generateContent
    - countTokens
    - createCachedContent
    - batchGenerateContent
    version: '2.0'
  updated_at: 2025-12-19 00:46:08.791901+00:00
- model_id: gemini-2.0-flash-001
  name: Gemini 2.0 Flash 001
  provider: google
  description: Stable version of Gemini 2.0 Flash, our fast and versatile multimodal
    model for scaling across diverse tasks, released in January of 2025.
  context_length: 1048576
  pricing: null
  capabilities:
    supports_vision: false
    supports_function_calling: true
    supports_streaming: true
    modalities:
    - text
  metadata:
    full_name: models/gemini-2.0-flash-001
    output_token_limit: 8192
    supported_methods:
    - generateContent
    - countTokens
    - createCachedContent
    - batchGenerateContent
    version: '2.0'
  updated_at: 2025-12-19 00:46:08.791908+00:00
- model_id: gemini-2.0-flash-exp-image-generation
  name: Gemini 2.0 Flash (Image Generation) Experimental
  provider: google
  description: Gemini 2.0 Flash (Image Generation) Experimental
  context_length: 1048576
  pricing: null
  capabilities:
    supports_vision: false
    supports_function_calling: true
    supports_streaming: true
    modalities:
    - text
  metadata:
    full_name: models/gemini-2.0-flash-exp-image-generation
    output_token_limit: 8192
    supported_methods:
    - generateContent
    - countTokens
    - bidiGenerateContent
    version: '2.0'
  updated_at: 2025-12-19 00:46:08.791915+00:00
- model_id: gemini-2.0-flash-lite-001
  name: Gemini 2.0 Flash-Lite 001
  provider: google
  description: Stable version of Gemini 2.0 Flash-Lite
  context_length: 1048576
  pricing: null
  capabilities:
    supports_vision: false
    supports_function_calling: true
    supports_streaming: true
    modalities:
    - text
  metadata:
    full_name: models/gemini-2.0-flash-lite-001
    output_token_limit: 8192
    supported_methods:
    - generateContent
    - countTokens
    - createCachedContent
    - batchGenerateContent
    version: '2.0'
  updated_at: 2025-12-19 00:46:08.791926+00:00
- model_id: gemini-2.0-flash-lite
  name: Gemini 2.0 Flash-Lite
  provider: google
  description: Gemini 2.0 Flash-Lite
  context_length: 1048576
  pricing: null
  capabilities:
    supports_vision: false
    supports_function_calling: true
    supports_streaming: true
    modalities:
    - text
  metadata:
    full_name: models/gemini-2.0-flash-lite
    output_token_limit: 8192
    supported_methods:
    - generateContent
    - countTokens
    - createCachedContent
    - batchGenerateContent
    version: '2.0'
  updated_at: 2025-12-19 00:46:08.791934+00:00
- model_id: gemini-2.0-flash-lite-preview-02-05
  name: Gemini 2.0 Flash-Lite Preview 02-05
  provider: google
  description: Preview release (February 5th, 2025) of Gemini 2.0 Flash-Lite
  context_length: 1048576
  pricing: null
  capabilities:
    supports_vision: false
    supports_function_calling: true
    supports_streaming: true
    modalities:
    - text
  metadata:
    full_name: models/gemini-2.0-flash-lite-preview-02-05
    output_token_limit: 8192
    supported_methods:
    - generateContent
    - countTokens
    - createCachedContent
    - batchGenerateContent
    version: preview-02-05
  updated_at: 2025-12-19 00:46:08.791941+00:00
- model_id: gemini-2.0-flash-lite-preview
  name: Gemini 2.0 Flash-Lite Preview
  provider: google
  description: Preview release (February 5th, 2025) of Gemini 2.0 Flash-Lite
  context_length: 1048576
  pricing: null
  capabilities:
    supports_vision: false
    supports_function_calling: true
    supports_streaming: true
    modalities:
    - text
  metadata:
    full_name: models/gemini-2.0-flash-lite-preview
    output_token_limit: 8192
    supported_methods:
    - generateContent
    - countTokens
    - createCachedContent
    - batchGenerateContent
    version: preview-02-05
  updated_at: 2025-12-19 00:46:08.791947+00:00
- model_id: gemini-exp-1206
  name: Gemini Experimental 1206
  provider: google
  description: Experimental release (March 25th, 2025) of Gemini 2.5 Pro
  context_length: 1048576
  pricing: null
  capabilities:
    supports_vision: false
    supports_function_calling: true
    supports_streaming: true
    modalities:
    - text
  metadata:
    full_name: models/gemini-exp-1206
    output_token_limit: 65536
    supported_methods:
    - generateContent
    - countTokens
    - createCachedContent
    - batchGenerateContent
    version: 2.5-exp-03-25
  updated_at: 2025-12-19 00:46:08.791957+00:00
- model_id: gemini-2.5-flash-preview-tts
  name: Gemini 2.5 Flash Preview TTS
  provider: google
  description: Gemini 2.5 Flash Preview TTS
  context_length: 8192
  pricing: null
  capabilities:
    supports_vision: false
    supports_function_calling: true
    supports_streaming: true
    modalities:
    - text
  metadata:
    full_name: models/gemini-2.5-flash-preview-tts
    output_token_limit: 16384
    supported_methods:
    - countTokens
    - generateContent
    version: gemini-2.5-flash-exp-tts-2025-05-19
  updated_at: 2025-12-19 00:46:08.791964+00:00
- model_id: gemini-2.5-pro-preview-tts
  name: Gemini 2.5 Pro Preview TTS
  provider: google
  description: Gemini 2.5 Pro Preview TTS
  context_length: 8192
  pricing: null
  capabilities:
    supports_vision: false
    supports_function_calling: true
    supports_streaming: true
    modalities:
    - text
  metadata:
    full_name: models/gemini-2.5-pro-preview-tts
    output_token_limit: 16384
    supported_methods:
    - countTokens
    - generateContent
    version: gemini-2.5-pro-preview-tts-2025-05-19
  updated_at: 2025-12-19 00:46:08.791970+00:00
- model_id: gemma-3-1b-it
  name: Gemma 3 1B
  provider: google
  description: 'Google Gemini model: Gemma 3 1B'
  context_length: 32768
  pricing: null
  capabilities:
    supports_vision: false
    supports_function_calling: true
    supports_streaming: true
    modalities:
    - text
  metadata:
    full_name: models/gemma-3-1b-it
    output_token_limit: 8192
    supported_methods:
    - generateContent
    - countTokens
    version: '001'
  updated_at: 2025-12-19 00:46:08.791976+00:00
- model_id: gemma-3-4b-it
  name: Gemma 3 4B
  provider: google
  description: 'Google Gemini model: Gemma 3 4B'
  context_length: 32768
  pricing: null
  capabilities:
    supports_vision: false
    supports_function_calling: true
    supports_streaming: true
    modalities:
    - text
  metadata:
    full_name: models/gemma-3-4b-it
    output_token_limit: 8192
    supported_methods:
    - generateContent
    - countTokens
    version: '001'
  updated_at: 2025-12-19 00:46:08.791982+00:00
- model_id: gemma-3-12b-it
  name: Gemma 3 12B
  provider: google
  description: 'Google Gemini model: Gemma 3 12B'
  context_length: 32768
  pricing: null
  capabilities:
    supports_vision: false
    supports_function_calling: true
    supports_streaming: true
    modalities:
    - text
  metadata:
    full_name: models/gemma-3-12b-it
    output_token_limit: 8192
    supported_methods:
    - generateContent
    - countTokens
    version: '001'
  updated_at: 2025-12-19 00:46:08.791988+00:00
- model_id: gemma-3-27b-it
  name: Gemma 3 27B
  provider: google
  description: 'Google Gemini model: Gemma 3 27B'
  context_length: 131072
  pricing: null
  capabilities:
    supports_vision: false
    supports_function_calling: true
    supports_streaming: true
    modalities:
    - text
  metadata:
    full_name: models/gemma-3-27b-it
    output_token_limit: 8192
    supported_methods:
    - generateContent
    - countTokens
    version: '001'
  updated_at: 2025-12-19 00:46:08.791994+00:00
- model_id: gemma-3n-e4b-it
  name: Gemma 3n E4B
  provider: google
  description: 'Google Gemini model: Gemma 3n E4B'
  context_length: 8192
  pricing: null
  capabilities:
    supports_vision: false
    supports_function_calling: true
    supports_streaming: true
    modalities:
    - text
  metadata:
    full_name: models/gemma-3n-e4b-it
    output_token_limit: 2048
    supported_methods:
    - generateContent
    - countTokens
    version: '001'
  updated_at: 2025-12-19 00:46:08.792000+00:00
- model_id: gemma-3n-e2b-it
  name: Gemma 3n E2B
  provider: google
  description: 'Google Gemini model: Gemma 3n E2B'
  context_length: 8192
  pricing: null
  capabilities:
    supports_vision: false
    supports_function_calling: true
    supports_streaming: true
    modalities:
    - text
  metadata:
    full_name: models/gemma-3n-e2b-it
    output_token_limit: 2048
    supported_methods:
    - generateContent
    - countTokens
    version: '001'
  updated_at: 2025-12-19 00:46:08.792006+00:00
- model_id: gemini-flash-latest
  name: Gemini Flash Latest
  provider: google
  description: Latest release of Gemini Flash
  context_length: 1048576
  pricing: null
  capabilities:
    supports_vision: false
    supports_function_calling: true
    supports_streaming: true
    modalities:
    - text
  metadata:
    full_name: models/gemini-flash-latest
    output_token_limit: 65536
    supported_methods:
    - generateContent
    - countTokens
    - createCachedContent
    - batchGenerateContent
    version: Gemini Flash Latest
  updated_at: 2025-12-19 00:46:08.792012+00:00
- model_id: gemini-flash-lite-latest
  name: Gemini Flash-Lite Latest
  provider: google
  description: Latest release of Gemini Flash-Lite
  context_length: 1048576
  pricing: null
  capabilities:
    supports_vision: false
    supports_function_calling: true
    supports_streaming: true
    modalities:
    - text
  metadata:
    full_name: models/gemini-flash-lite-latest
    output_token_limit: 65536
    supported_methods:
    - generateContent
    - countTokens
    - createCachedContent
    - batchGenerateContent
    version: Gemini Flash-Lite Latest
  updated_at: 2025-12-19 00:46:08.792018+00:00
- model_id: gemini-pro-latest
  name: Gemini Pro Latest
  provider: google
  description: Latest release of Gemini Pro
  context_length: 1048576
  pricing: null
  capabilities:
    supports_vision: false
    supports_function_calling: true
    supports_streaming: true
    modalities:
    - text
  metadata:
    full_name: models/gemini-pro-latest
    output_token_limit: 65536
    supported_methods:
    - generateContent
    - countTokens
    - createCachedContent
    - batchGenerateContent
    version: Gemini Pro Latest
  updated_at: 2025-12-19 00:46:08.792024+00:00
- model_id: gemini-2.5-flash-lite
  name: Gemini 2.5 Flash-Lite
  provider: google
  description: Stable version of Gemini 2.5 Flash-Lite, released in July of 2025
  context_length: 1048576
  pricing: null
  capabilities:
    supports_vision: false
    supports_function_calling: true
    supports_streaming: true
    modalities:
    - text
  metadata:
    full_name: models/gemini-2.5-flash-lite
    output_token_limit: 65536
    supported_methods:
    - generateContent
    - countTokens
    - createCachedContent
    - batchGenerateContent
    version: '001'
  updated_at: 2025-12-19 00:46:08.792029+00:00
- model_id: gemini-2.5-flash-image-preview
  name: Nano Banana
  provider: google
  description: Gemini 2.5 Flash Preview Image
  context_length: 32768
  pricing: null
  capabilities:
    supports_vision: false
    supports_function_calling: true
    supports_streaming: true
    modalities:
    - text
  metadata:
    full_name: models/gemini-2.5-flash-image-preview
    output_token_limit: 32768
    supported_methods:
    - generateContent
    - countTokens
    - batchGenerateContent
    version: '2.0'
  updated_at: 2025-12-19 00:46:08.792035+00:00
- model_id: gemini-2.5-flash-image
  name: Nano Banana
  provider: google
  description: Gemini 2.5 Flash Preview Image
  context_length: 32768
  pricing: null
  capabilities:
    supports_vision: false
    supports_function_calling: true
    supports_streaming: true
    modalities:
    - text
  metadata:
    full_name: models/gemini-2.5-flash-image
    output_token_limit: 32768
    supported_methods:
    - generateContent
    - countTokens
    - batchGenerateContent
    version: '2.0'
  updated_at: 2025-12-19 00:46:08.792041+00:00
- model_id: gemini-2.5-flash-preview-09-2025
  name: Gemini 2.5 Flash Preview Sep 2025
  provider: google
  description: Gemini 2.5 Flash Preview Sep 2025
  context_length: 1048576
  pricing: null
  capabilities:
    supports_vision: false
    supports_function_calling: true
    supports_streaming: true
    modalities:
    - text
  metadata:
    full_name: models/gemini-2.5-flash-preview-09-2025
    output_token_limit: 65536
    supported_methods:
    - generateContent
    - countTokens
    - createCachedContent
    - batchGenerateContent
    version: Gemini 2.5 Flash Preview 09-2025
  updated_at: 2025-12-19 00:46:08.792047+00:00
- model_id: gemini-2.5-flash-lite-preview-09-2025
  name: Gemini 2.5 Flash-Lite Preview Sep 2025
  provider: google
  description: Preview release (Septempber 25th, 2025) of Gemini 2.5 Flash-Lite
  context_length: 1048576
  pricing: null
  capabilities:
    supports_vision: false
    supports_function_calling: true
    supports_streaming: true
    modalities:
    - text
  metadata:
    full_name: models/gemini-2.5-flash-lite-preview-09-2025
    output_token_limit: 65536
    supported_methods:
    - generateContent
    - countTokens
    - createCachedContent
    - batchGenerateContent
    version: 2.5-preview-09-25
  updated_at: 2025-12-19 00:46:08.792053+00:00
- model_id: gemini-3-pro-preview
  name: Gemini 3 Pro Preview
  provider: google
  description: Gemini 3 Pro Preview
  context_length: 1048576
  pricing: null
  capabilities:
    supports_vision: false
    supports_function_calling: true
    supports_streaming: true
    modalities:
    - text
  metadata:
    full_name: models/gemini-3-pro-preview
    output_token_limit: 65536
    supported_methods:
    - generateContent
    - countTokens
    - createCachedContent
    - batchGenerateContent
    version: 3-pro-preview-11-2025
  updated_at: 2025-12-19 00:46:08.792131+00:00
- model_id: gemini-3-flash-preview
  name: Gemini 3 Flash Preview
  provider: google
  description: Gemini 3 Flash Preview
  context_length: 1048576
  pricing: null
  capabilities:
    supports_vision: false
    supports_function_calling: true
    supports_streaming: true
    modalities:
    - text
  metadata:
    full_name: models/gemini-3-flash-preview
    output_token_limit: 65536
    supported_methods:
    - generateContent
    - countTokens
    - createCachedContent
    - batchGenerateContent
    version: 3-flash-preview-12-2025
  updated_at: 2025-12-19 00:46:08.792140+00:00
- model_id: gemini-3-pro-image-preview
  name: Nano Banana Pro
  provider: google
  description: Gemini 3 Pro Image Preview
  context_length: 131072
  pricing: null
  capabilities:
    supports_vision: false
    supports_function_calling: true
    supports_streaming: true
    modalities:
    - text
  metadata:
    full_name: models/gemini-3-pro-image-preview
    output_token_limit: 32768
    supported_methods:
    - generateContent
    - countTokens
    - batchGenerateContent
    version: '3.0'
  updated_at: 2025-12-19 00:46:08.792146+00:00
- model_id: nano-banana-pro-preview
  name: Nano Banana Pro
  provider: google
  description: Gemini 3 Pro Image Preview
  context_length: 131072
  pricing: null
  capabilities:
    supports_vision: false
    supports_function_calling: true
    supports_streaming: true
    modalities:
    - text
  metadata:
    full_name: models/nano-banana-pro-preview
    output_token_limit: 32768
    supported_methods:
    - generateContent
    - countTokens
    - batchGenerateContent
    version: '3.0'
  updated_at: 2025-12-19 00:46:08.792152+00:00
- model_id: gemini-robotics-er-1.5-preview
  name: Gemini Robotics-ER 1.5 Preview
  provider: google
  description: Gemini Robotics-ER 1.5 Preview
  context_length: 1048576
  pricing: null
  capabilities:
    supports_vision: false
    supports_function_calling: true
    supports_streaming: true
    modalities:
    - text
  metadata:
    full_name: models/gemini-robotics-er-1.5-preview
    output_token_limit: 65536
    supported_methods:
    - generateContent
    - countTokens
    version: 1.5-preview
  updated_at: 2025-12-19 00:46:08.792158+00:00
- model_id: gemini-2.5-computer-use-preview-10-2025
  name: Gemini 2.5 Computer Use Preview 10-2025
  provider: google
  description: Gemini 2.5 Computer Use Preview 10-2025
  context_length: 131072
  pricing: null
  capabilities:
    supports_vision: false
    supports_function_calling: true
    supports_streaming: true
    modalities:
    - text
  metadata:
    full_name: models/gemini-2.5-computer-use-preview-10-2025
    output_token_limit: 65536
    supported_methods:
    - generateContent
    - countTokens
    version: Gemini 2.5 Computer Use Preview 10-2025
  updated_at: 2025-12-19 00:46:08.792165+00:00
- model_id: deep-research-pro-preview-12-2025
  name: Deep Research Pro Preview (Dec-12-2025)
  provider: google
  description: Preview release (December 12th, 2025) of Deep Research Pro
  context_length: 131072
  pricing: null
  capabilities:
    supports_vision: false
    supports_function_calling: true
    supports_streaming: true
    modalities:
    - text
  metadata:
    full_name: models/deep-research-pro-preview-12-2025
    output_token_limit: 65536
    supported_methods:
    - generateContent
    - countTokens
    version: deepthink-exp-05-20
  updated_at: 2025-12-19 00:46:08.792171+00:00
- model_id: embedding-001
  name: Embedding 001
  provider: google
  description: Obtain a distributed representation of a text.
  context_length: 2048
  pricing: null
  capabilities:
    supports_vision: false
    supports_function_calling: true
    supports_streaming: true
    modalities:
    - text
  metadata:
    full_name: models/embedding-001
    output_token_limit: 1
    supported_methods:
    - embedContent
    version: '001'
  updated_at: 2025-12-19 00:46:08.792177+00:00
- model_id: text-embedding-004
  name: Text Embedding 004
  provider: google
  description: Obtain a distributed representation of a text.
  context_length: 2048
  pricing: null
  capabilities:
    supports_vision: false
    supports_function_calling: true
    supports_streaming: true
    modalities:
    - text
  metadata:
    full_name: models/text-embedding-004
    output_token_limit: 1
    supported_methods:
    - embedContent
    version: '004'
  updated_at: 2025-12-19 00:46:08.792182+00:00
- model_id: gemini-embedding-exp-03-07
  name: Gemini Embedding Experimental 03-07
  provider: google
  description: Obtain a distributed representation of a text.
  context_length: 8192
  pricing: null
  capabilities:
    supports_vision: false
    supports_function_calling: true
    supports_streaming: true
    modalities:
    - text
  metadata:
    full_name: models/gemini-embedding-exp-03-07
    output_token_limit: 1
    supported_methods:
    - embedContent
    - countTextTokens
    - countTokens
    version: exp-03-07
  updated_at: 2025-12-19 00:46:08.792188+00:00
- model_id: gemini-embedding-exp
  name: Gemini Embedding Experimental
  provider: google
  description: Obtain a distributed representation of a text.
  context_length: 8192
  pricing: null
  capabilities:
    supports_vision: false
    supports_function_calling: true
    supports_streaming: true
    modalities:
    - text
  metadata:
    full_name: models/gemini-embedding-exp
    output_token_limit: 1
    supported_methods:
    - embedContent
    - countTextTokens
    - countTokens
    version: exp-03-07
  updated_at: 2025-12-19 00:46:08.792194+00:00
- model_id: gemini-embedding-001
  name: Gemini Embedding 001
  provider: google
  description: Obtain a distributed representation of a text.
  context_length: 2048
  pricing: null
  capabilities:
    supports_vision: false
    supports_function_calling: true
    supports_streaming: true
    modalities:
    - text
  metadata:
    full_name: models/gemini-embedding-001
    output_token_limit: 1
    supported_methods:
    - embedContent
    - countTextTokens
    - countTokens
    - asyncBatchEmbedContent
    version: '001'
  updated_at: 2025-12-19 00:46:08.792203+00:00
- model_id: aqa
  name: Model that performs Attributed Question Answering.
  provider: google
  description: Model trained to return answers to questions that are grounded in provided
    sources, along with estimating answerable probability.
  context_length: 7168
  pricing: null
  capabilities:
    supports_vision: false
    supports_function_calling: true
    supports_streaming: true
    modalities:
    - text
  metadata:
    full_name: models/aqa
    output_token_limit: 1024
    supported_methods:
    - generateAnswer
    version: '001'
  updated_at: 2025-12-19 00:46:08.792209+00:00
- model_id: imagen-4.0-generate-preview-06-06
  name: Imagen 4 (Preview)
  provider: google
  description: Vertex served Imagen 4.0 model
  context_length: 480
  pricing: null
  capabilities:
    supports_vision: false
    supports_function_calling: true
    supports_streaming: true
    modalities:
    - text
  metadata:
    full_name: models/imagen-4.0-generate-preview-06-06
    output_token_limit: 8192
    supported_methods:
    - predict
    version: '01'
  updated_at: 2025-12-19 00:46:08.792215+00:00
- model_id: imagen-4.0-ultra-generate-preview-06-06
  name: Imagen 4 Ultra (Preview)
  provider: google
  description: Vertex served Imagen 4.0 ultra model
  context_length: 480
  pricing: null
  capabilities:
    supports_vision: false
    supports_function_calling: true
    supports_streaming: true
    modalities:
    - text
  metadata:
    full_name: models/imagen-4.0-ultra-generate-preview-06-06
    output_token_limit: 8192
    supported_methods:
    - predict
    version: '01'
  updated_at: 2025-12-19 00:46:08.792222+00:00
- model_id: imagen-4.0-generate-001
  name: Imagen 4
  provider: google
  description: Vertex served Imagen 4.0 model
  context_length: 480
  pricing: null
  capabilities:
    supports_vision: false
    supports_function_calling: true
    supports_streaming: true
    modalities:
    - text
  metadata:
    full_name: models/imagen-4.0-generate-001
    output_token_limit: 8192
    supported_methods:
    - predict
    version: '001'
  updated_at: 2025-12-19 00:46:08.792227+00:00
- model_id: imagen-4.0-ultra-generate-001
  name: Imagen 4 Ultra
  provider: google
  description: Vertex served Imagen 4.0 ultra model
  context_length: 480
  pricing: null
  capabilities:
    supports_vision: false
    supports_function_calling: true
    supports_streaming: true
    modalities:
    - text
  metadata:
    full_name: models/imagen-4.0-ultra-generate-001
    output_token_limit: 8192
    supported_methods:
    - predict
    version: '001'
  updated_at: 2025-12-19 00:46:08.792233+00:00
- model_id: imagen-4.0-fast-generate-001
  name: Imagen 4 Fast
  provider: google
  description: Vertex served Imagen 4.0 Fast model
  context_length: 480
  pricing: null
  capabilities:
    supports_vision: false
    supports_function_calling: true
    supports_streaming: true
    modalities:
    - text
  metadata:
    full_name: models/imagen-4.0-fast-generate-001
    output_token_limit: 8192
    supported_methods:
    - predict
    version: '001'
  updated_at: 2025-12-19 00:46:08.792244+00:00
- model_id: veo-2.0-generate-001
  name: Veo 2
  provider: google
  description: Vertex served Veo 2 model. Access to this model requires billing to
    be enabled on the associated Google Cloud Platform account. Please visit https://console.cloud.google.com/billing
    to enable it.
  context_length: 480
  pricing: null
  capabilities:
    supports_vision: false
    supports_function_calling: true
    supports_streaming: true
    modalities:
    - text
  metadata:
    full_name: models/veo-2.0-generate-001
    output_token_limit: 8192
    supported_methods:
    - predictLongRunning
    version: '2.0'
  updated_at: 2025-12-19 00:46:08.792250+00:00
- model_id: veo-3.0-generate-001
  name: Veo 3
  provider: google
  description: Veo 3
  context_length: 480
  pricing: null
  capabilities:
    supports_vision: false
    supports_function_calling: true
    supports_streaming: true
    modalities:
    - text
  metadata:
    full_name: models/veo-3.0-generate-001
    output_token_limit: 8192
    supported_methods:
    - predictLongRunning
    version: '3.0'
  updated_at: 2025-12-19 00:46:08.792256+00:00
- model_id: veo-3.0-fast-generate-001
  name: Veo 3 fast
  provider: google
  description: Veo 3 fast
  context_length: 480
  pricing: null
  capabilities:
    supports_vision: false
    supports_function_calling: true
    supports_streaming: true
    modalities:
    - text
  metadata:
    full_name: models/veo-3.0-fast-generate-001
    output_token_limit: 8192
    supported_methods:
    - predictLongRunning
    version: '3.0'
  updated_at: 2025-12-19 00:46:08.792261+00:00
- model_id: veo-3.1-generate-preview
  name: Veo 3.1
  provider: google
  description: Veo 3.1
  context_length: 480
  pricing: null
  capabilities:
    supports_vision: false
    supports_function_calling: true
    supports_streaming: true
    modalities:
    - text
  metadata:
    full_name: models/veo-3.1-generate-preview
    output_token_limit: 8192
    supported_methods:
    - predictLongRunning
    version: '3.1'
  updated_at: 2025-12-19 00:46:08.792267+00:00
- model_id: veo-3.1-fast-generate-preview
  name: Veo 3.1 fast
  provider: google
  description: Veo 3.1 fast
  context_length: 480
  pricing: null
  capabilities:
    supports_vision: false
    supports_function_calling: true
    supports_streaming: true
    modalities:
    - text
  metadata:
    full_name: models/veo-3.1-fast-generate-preview
    output_token_limit: 8192
    supported_methods:
    - predictLongRunning
    version: '3.1'
  updated_at: 2025-12-19 00:46:08.956925+00:00
- model_id: gemini-2.5-flash-native-audio-latest
  name: Gemini 2.5 Flash Native Audio Latest
  provider: google
  description: Latest release of Gemini 2.5 Flash Native Audio
  context_length: 131072
  pricing: null
  capabilities:
    supports_vision: false
    supports_function_calling: true
    supports_streaming: true
    modalities:
    - text
  metadata:
    full_name: models/gemini-2.5-flash-native-audio-latest
    output_token_limit: 8192
    supported_methods:
    - countTokens
    - bidiGenerateContent
    version: Gemini 2.5 Flash Native Audio Latest
  updated_at: 2025-12-19 00:46:08.956944+00:00
- model_id: gemini-2.5-flash-native-audio-preview-09-2025
  name: Gemini 2.5 Flash Native Audio Preview 09-2025
  provider: google
  description: Gemini 2.5 Flash Native Audio Preview 09-2025
  context_length: 131072
  pricing: null
  capabilities:
    supports_vision: false
    supports_function_calling: true
    supports_streaming: true
    modalities:
    - text
  metadata:
    full_name: models/gemini-2.5-flash-native-audio-preview-09-2025
    output_token_limit: 8192
    supported_methods:
    - countTokens
    - bidiGenerateContent
    version: gemini-2.5-flash-preview-native-audio-dialog-2025-05-19
  updated_at: 2025-12-19 00:46:08.956952+00:00
- model_id: gemini-2.5-flash-native-audio-preview-12-2025
  name: Gemini 2.5 Flash Native Audio Preview 12-2025
  provider: google
  description: Gemini 2.5 Flash Native Audio Preview 12-2025
  context_length: 131072
  pricing: null
  capabilities:
    supports_vision: false
    supports_function_calling: true
    supports_streaming: true
    modalities:
    - text
  metadata:
    full_name: models/gemini-2.5-flash-native-audio-preview-12-2025
    output_token_limit: 8192
    supported_methods:
    - countTokens
    - bidiGenerateContent
    version: 12-2025
  updated_at: 2025-12-19 00:46:08.956959+00:00
providers:
  openrouter:
    name: openrouter
    model_count: 350
    last_updated: 2025-12-19 00:46:08.958077+00:00
  anthropic:
    name: anthropic
    model_count: 10
    last_updated: 2025-12-19 00:46:08.958105+00:00
  openai:
    name: openai
    model_count: 92
    last_updated: 2025-12-19 00:46:08.958295+00:00
  google:
    name: google
    model_count: 54
    last_updated: 2025-12-19 00:46:08.958407+00:00
last_updated: 2025-12-19 00:46:08.958407+00:00
